args[0] = -l
args[1] = -refine
args[3] = -train
args[5] = -target
args[7] = -trees

% Starting a LEARNING run of bRDN.

% Calling SETUP.
% Running on host: C02DX2QHML7H

% Switching to VarIndicator = uppercase.

% Unset'ing VarIndicator.

Resetting the LazyGroundNthArgumentClauseIndex.

% Calling ILPouterLoop from createRegressionOuterLooper.

% getInputArgWithDefaultValue: args=[train/train_pos.txt, train/train_neg.txt, train/train_bk.txt, train/train_facts.txt]
%  for N=0: args[N]=train/train_pos.txt

% getInputArgWithDefaultValue: args=[train/train_pos.txt, train/train_neg.txt, train/train_bk.txt, train/train_facts.txt]
%  for N=1: args[N]=train/train_neg.txt

% getInputArgWithDefaultValue: args=[train/train_pos.txt, train/train_neg.txt, train/train_bk.txt, train/train_facts.txt]
%  for N=2: args[N]=train/train_bk.txt

% getInputArgWithDefaultValue: args=[train/train_pos.txt, train/train_neg.txt, train/train_bk.txt, train/train_facts.txt]
%  for N=3: args[N]=train/train_facts.txt

% Welcome to the WILL ILP/SRL systems.


% Switching to VarIndicator = uppercase.

% Unset'ing VarIndicator.
% Reading background theory from dir: null
% Load '../background.txt'.

% Switching to VarIndicator = uppercase.

***** Warning: % Since this is the first setting of the notation for variables, will keep:
%   variableIndicator = uppercase *****


***** Warning: % Since this is the first setting of the notation for variables, will keep:
%   variableIndicator = uppercase *****

% [ LazyGroundClauseIndex ]  Building full index for mode/1 with 1 assertions.
% LoadAllModes() called.  Currently loaded modes: []
% [ LazyGroundClauseIndex ]  Building full index for sameAs/2 with 2 assertions.
% [ LazyGroundNthArgumentClauseIndex ]  Argument 1:  Building full index for exp/3.
% [ LazyGroundNthArgumentClauseIndex ]  Argument 0:  Building full index for log/3.
% LoadAllLibraries() called.  Currently loaded libraries: [listsInLogic, differentInLogic, modes_arithmeticInLogic, inlines_comparisonInLogic, modes_listsInLogic, inlines_differentInLogic, modes_differentInLogic, arithmeticInLogic, inlines_listsInLogic, modes_comparisonInLogic, comparisonInLogic, inlines_arithmeticInLogic]

%  Read the facts.
%  Have read 414 facts.
% Have read 16 examples from 'train' [train/train*].
% Have read 32 examples from 'train' [train/train*].

%  LearnOneClause initialized.

% The outer looper has been created.

% Initializing the ILP inner looper.

% NEW target:                 advisedby(D, E)
%  targetPred:                advisedby/2
%  targetArgTypes:            signature = [const, const], types = [+person, +person]
%  targets:                   [advisedby(D, E)]
%  targetPredicates:          [advisedby/2]
%  targetArgSpecs:            [[D[+person], E[+person]]]
%  variablesInTargets:        [[D, E]]

% Started collecting constants

% Collecting the types of constants.

% Looking at the training examples to see if any types of new constants can be inferred.
% Time to collect constants: 9 milliseconds
% Time to collect examples: 0 seconds

% Read 16 pos examples and 32 neg examples.
% Time to init learnOneClause: 15 milliseconds
% Old dirnull
Setting model dir

% Have 16 'raw' positive examples and kept 16.
% Have 32 'raw' negative examples and kept 32.

% processing backup's for advisedby
%  POS EX = 16
%  NEG EX = 32

% Memory usage by WILLSetup (just counts # targets?):
%  |backupPosExamples| = 1
%  |backupNegExamples| = 1
%  |predicatesAsFacts| = 0
%  |addedToFactBase|   = 0
train/models/
File: train/advice.txt doesnt exist.Hence no advice loaded
% Learning 10 trees in this iteration for advisedby

% Learn model for: advisedby
% Kept 16 of the 16 positive examples.
% Kept 32 of the 32 negative examples.
%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.2222222222222222
Set score:0.0025
% Dataset size: 48
Computing probabilities
prob time:1 milliseconds
No hidden examples for : advisedby
Time to build dataset: 2 milliseconds
%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.22222222222222174
Set score:0.0025
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% Have these 10 positive seeds: 11 12 13 18 19 30 31 33 35 36

% The best node found: null

% target           = advisedby(D, E)
%     Score = -Infinity (regressionFit = Infinity, penalties=2.2E-7) for clause:  advisedby(_, _).  [covers 48,0/48,0 pos, 0,0/0,0 neg]
% [ LazyGroundClauseIndex ]  Building full index for professor/1 with 13 assertions.
%     Score = -5,333334 (regressionFit = 5,333333, penalties=1.12E-6) for clause:  advisedby(_, A) :- professor(A).  [covers 24,0/48,0 pos, 0,0/0,0 neg]
% [ LazyGroundClauseIndex ]  Building full index for student/1 with 36 assertions.
%     Score = -5,333335 (regressionFit = 5,333333, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- professor(B), student(A).  [covers 24,0/48,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- professor(B), student(A).  [covers 24,0/48,0 pos, 0,0/0,0 neg]

% Expanding node at Level 0 with score = 1,797693e+308.
% Will extend: advisedby(A, B) :- professor(B), student(A).  [covers 24,0/48,0 pos, 0,0/0,0 neg]
% Path: 0;
Comparing variance: 0.2222222222222218 to score=0.0025 #egs=24.0
Comparing variance: 9.25185853854297E-18 to score=0.0025 #egs=24.0
%   Creating a TRUE-branch interior node with wgtedCountTrueBranchPos = 24,0
%      addToQueueOfTreeStructuredLearningTasks (level=1; score=-0,222222)
%         ILP node to extend: advisedby(A, B) :- professor(B), student(A).  [covers 24,0/48,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 1 and with score = -0,222222) into the LAST position (#1) in the search queue.
%   Creating a FALSE-branch leaf because good enough fit since score < 0.0025

% Time for loop #1: 22 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #1, the best clause found is:
%      advisedby(A, B) :- professor(B), student(A).  [covers 24,0/48,0 pos, 0,0/0,0 neg]
% This clause covers 24 positive examples, of which 24 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- professor(B), student(A).  [covers 24,0/24,0 pos, 0,0/0,0 neg]'
%     Score = -5,333335 (regressionFit = 5,333333, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- professor(B), student(A).  [covers 24,0/24,0 pos, 0,0/0,0 neg]

% Have these 10 positive seeds: 0 1 4 5 6 9 11 14 16 19

% The best node found: null
% [ LazyGroundNthArgumentClauseIndex ]  Argument 1:  Building full index for publication/2.
%     Score = -4,800003 (regressionFit = 4,800000, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, A).  [covers 4,0/24,0 pos, 0,0/0,0 neg]
% [ LazyGroundClauseIndex ]  Building full index for publication/2 with 112 assertions.
%     Score = -4,800004 (regressionFit = 4,800000, penalties=3.9300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(C, A), publication(C, B).  [covers 4,0/24,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- professor(B), student(A), publication(C, A), publication(C, B).  [covers 4,0/24,0 pos, 0,0/0,0 neg]

% Expanding node at Level 1 with score = -0,222.
% Will extend: advisedby(A, B) :- professor(B), student(A), publication(C, A), publication(C, B).  [covers 4,0/24,0 pos, 0,0/0,0 neg]
% Path: 0;true
Comparing variance: 0.0 to score=0.0025 #egs=4.0
Comparing variance: 0.2399999999999996 to score=0.0025 #egs=20.0
%   Creating a TRUE-branch leaf because wgtedCountTrueBranchPos = 4,0 < 2.1 * minPosCov = 6,3
%   Creating a FALSE-branch interior node with wgtedCountFalseBranchPos = 20,0
%      addToQueueOfTreeStructuredLearningTasks (level=2; score=-0,240000)
%         ILP node to extend: advisedby(A, B) :- professor(B), student(A).  [covers 24,0/24,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 2 and with score = -0,240000) into the LAST position (#1) in the search queue.

% Time for loop #2: 18 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #2, the best clause found is:
%      advisedby(A, B) :- professor(B), student(A), publication(C, A), publication(C, B).  [covers 4,0/24,0 pos, 0,0/0,0 neg]
% This clause covers 4 positive examples, of which 4 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- professor(B), student(A).  [covers 24,0/20,0 pos, 0,0/0,0 neg]'
%     Score = -5,333335 (regressionFit = 5,333333, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- professor(B), student(A).  [covers 20,0/20,0 pos, 0,0/0,0 neg]

% Have these 10 positive seeds: 1 2 3 6 7 9 14 15 16 17

% The best node found: null
% [ LazyGroundNthArgumentClauseIndex ]  Argument 1:  Building full index for ta/3.
%     Score = -4,761908 (regressionFit = 4,761905, penalties=3.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -4,666671 (regressionFit = 4,666667, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B).  [covers 12,0/20,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B).  [covers 12,0/20,0 pos, 0,0/0,0 neg]

% Expanding node at Level 2 with score = -0,240.
% Will extend: advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B).  [covers 12,0/20,0 pos, 0,0/0,0 neg]
% Path: 0;true,false
Comparing variance: 0.2222222222222221 to score=0.0025 #egs=12.0
Comparing variance: 0.24999999999999994 to score=0.0025 #egs=8.0
%   Creating a TRUE-branch interior node with wgtedCountTrueBranchPos = 12,0
%      addToQueueOfTreeStructuredLearningTasks (level=3; score=-0,222222)
%         ILP node to extend: advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B).  [covers 12,0/20,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 3 and with score = -0,222222) into the LAST position (#1) in the search queue.
%   Creating a FALSE-branch interior node with wgtedCountFalseBranchPos = 8,0
%      addToQueueOfTreeStructuredLearningTasks (level=3; score=-0,250000)
%         ILP node to extend: advisedby(A, B) :- professor(B), student(A).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 3 and with score = -0,250000) into position #1 in the search queue (new size=2).

% Time for loop #3: 19 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #3, the best clause found is:
%      advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B).  [covers 12,0/20,0 pos, 0,0/0,0 neg]
% This clause covers 12 positive examples, of which 12 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- professor(B), student(A).  [covers 20,0/8,0 pos, 0,0/0,0 neg]'
%     Score = -5,333335 (regressionFit = 5,333333, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- professor(B), student(A).  [covers 8,0/8,0 pos, 0,0/0,0 neg]

***** Warning: % Have only 8 positive examples, so cannot choose 10 of them. *****


% Have these 8 positive seeds: 0 1 2 3 4 5 6 7
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% LearnOneClause Parameters:
%   Targets (3):
%    advisedby(+person, +person),
%    advisedby(+person, -person),
%    advisedby(-person, +person)
%  Modes (72):
%    professor(+person),
%    student(+person),
%    tempadvisedby(+person, +person),
%    tempadvisedby(+person, -person),
%    tempadvisedby(-person, +person),
%    ta(+course, +person, +quarter),
%    ta(-course, -person, +quarter),
%    ta(+course, -person, -quarter),
%    ta(-course, +person, -quarter),
%    hasposition(+person, +faculty),
%    hasposition(+person, -faculty),
%    hasposition(-person, +faculty),
%    publication(+title, +person),
%    publication(+title, -person),
%    publication(-title, +person),
%    inphase(+person, +prequals),
%    inphase(+person, -prequals),
%    inphase(-person, +prequals),
%    courselevel(+course, +level),
%    courselevel(+course, -level),
%    courselevel(-course, +level),
%    yearsinprogram(+person, +year),
%    yearsinprogram(-person, +year),
%    yearsinprogram(+person, -year),
%    projectmember(+project, +person),
%    projectmember(+project, -person),
%    projectmember(-project, +person),
%    sameproject(+project, +project),
%    sameproject(+project, -project),
%    sameproject(-project, +project),
%    samecourse(+course, +course),
%    samecourse(+course, -course),
%    samecourse(-course, +course),
%    sameperson(+person, +person),
%    sameperson(+person, -person),
%    sameperson(-person, +person),
%    addList(+willList, #willNumber),
%    multiplyList(+willList, #willNumber),
%    abs(+willNumber, &willNumber),
%    minus(+willNumber, &willNumber),
%    minus(+willNumber, +willNumber, &willNumber),
%    plus(+willNumber, +willNumber, &willNumber),
%    mult(+willNumber, +willNumber, &willNumber),
%    div(+willNumber, +willNumber, &willNumber),
%    allNumbers(+willList),
%    positiveNumber(+willNumber),
%    negativeNumber(+willNumber),
%    in0toDot001(+willNumber),
%    in0toDot01(+willNumber),
%    in0toDot1(+willNumber),
%    in0to1(+willNumber),
%    in0to10(+willNumber),
%    in0to100(+willNumber),
%    in0to1000(+willNumber),
%    equalWithTolerance(+willNumber, +willNumber, &willNumber),
%    greaterOrEqualDifference(+willNumber, +willNumber, &willNumber),
%    smallerOrEqualDifference(+willNumber, +willNumber, &willNumber),
%    isaEqualTolerance(+willNumber),
%    lessThan(+willNumber, +willNumber),
%    greaterThan(+willNumber, +willNumber),
%    lessThanOrEqual(+willNumber, +willNumber),
%    greaterThanOrEqual(+willNumber, +willNumber),
%    inBetweenOO(+willNumber, +willNumber, +willNumber),
%    inBetweenCO(+willNumber, +willNumber, +willNumber),
%    inBetweenOC(+willNumber, +willNumber, +willNumber),
%    inBetweenCC(+willNumber, +willNumber, +willNumber),
%    memberOfList(+willAnything, +willList),
%    firstInList(+willList, &willAnything),
%    restOfList(+willList, &willList),
%    positionInList(+willAnything, +willList, &willNumber),
%    nthInList(+willNumber, +willList, &willAnything),
%    lengthOfList(+willList, &willNumber)

% Consider expanding [#1 of outerLoop #4, bodyLen=2] 'advisedby(A, B) :- professor(B), student(A).  [covers 8,0/8,0 pos, 0,0/0,0 neg]' score=-5.333335353333323
% [ LazyGroundClauseIndex ]  Building full index for tempadvisedby/2 with 8 assertions.
% [ LazyGroundNthArgumentClauseIndex ]  Argument 0:  Building full index for tempadvisedby/2.
% [ LazyGroundNthArgumentClauseIndex ]  Argument 1:  Building full index for tempadvisedby/2.
% [ LazyGroundNthArgumentClauseIndex ]  Argument 0:  Building full index for hasposition/2.
% [ LazyGroundNthArgumentClauseIndex ]  Argument 0:  Building full index for inphase/2.
% [ LazyGroundNthArgumentClauseIndex ]  Argument 0:  Building full index for yearsinprogram/2.
% [ LazyGroundNthArgumentClauseIndex ]  Argument 1:  Building full index for projectmember/2.
% [ LazyGroundClauseIndex ]  Building full index for sameperson/2 with 49 assertions.
% [ LazyGroundNthArgumentClauseIndex ]  Argument 0:  Building full index for sameperson/2.
% [ LazyGroundNthArgumentClauseIndex ]  Argument 1:  Building full index for sameperson/2.
%  At # nodes expanded = 1, |OPEN| = 0.  Pruned 16 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -1,866670 (regressionFit = 1,866667, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
% Gleaner: New best node found (score = -1,866670): advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _).  [covers 2,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _).  [covers 6,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,866670 (regressionFit = 1,866667, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,500003 (regressionFit = 1,500000, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
% Gleaner: New best node found (score = -1,500003): advisedby(A, B) :- professor(B), student(A), projectmember(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.0200000000000007E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.0200000000000007E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(B, B).  [covers 8,0/8,0 pos, 0,0/0,0 neg]

% Consider expanding [#2 of outerLoop #4, bodyLen=3] 'advisedby(A, B) :- professor(B), student(A), projectmember(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]' score=-1.5000031300000005
% [ LazyGroundClauseIndex ]  Building full index for projectmember/2 with 4 assertions.
% [ LazyGroundNthArgumentClauseIndex ]  Argument 0:  Building full index for projectmember/2.
% [ LazyGroundClauseIndex ]  Building full index for sameproject/2 with 16 assertions.
% [ LazyGroundNthArgumentClauseIndex ]  Argument 0:  Building full index for sameproject/2.
% [ LazyGroundNthArgumentClauseIndex ]  Argument 1:  Building full index for sameproject/2.
%  At # nodes expanded = 2, |OPEN| = 8.  Pruned 20 variant children.  Sending 10 items to OPEN for evaluation and possible insertion.
% Have created 10 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -1,500004 (regressionFit = 1,500000, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), tempadvisedby(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), ta(_, A, _).  [covers 1,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,500004 (regressionFit = 1,500000, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), hasposition(B, _).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), publication(_, B).  [covers 1,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,500004 (regressionFit = 1,500000, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), inphase(A, _).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,500004 (regressionFit = 1,500000, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), yearsinprogram(A, _).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,500004 (regressionFit = 1,500000, penalties=4.140000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), projectmember(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,500004 (regressionFit = 1,500000, penalties=4.03E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(C, B), sameproject(C, C).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,500004 (regressionFit = 1,500000, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), sameperson(A, A).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,500004 (regressionFit = 1,500000, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), sameperson(B, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]

% Consider expanding [#3 of outerLoop #4, bodyLen=3] 'advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B).  [covers 5,0/8,0 pos, 0,0/0,0 neg]' score=-1.8666697966666665
%  At # nodes expanded = 3, |OPEN| = 7.  Pruned 34 variant children.  Sending 13 items to OPEN for evaluation and possible insertion.
% Have created 13 valid-on-seeds descendants and have picked up 26 bad extensions.
%     Score = -1,866671 (regressionFit = 1,866667, penalties=3.9300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(C, B), student(C).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B), ta(_, A, _).  [covers 1,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,866671 (regressionFit = 1,866667, penalties=4.250000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(C, B), ta(_, C, _).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,866671 (regressionFit = 1,866667, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B), hasposition(B, _).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B), publication(_, B).  [covers 2,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,866671 (regressionFit = 1,866667, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B), inphase(A, _).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,866671 (regressionFit = 1,866667, penalties=4.14E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(C, B), inphase(C, _).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,866671 (regressionFit = 1,866667, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B), yearsinprogram(A, _).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,866671 (regressionFit = 1,866667, penalties=4.14E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(C, B), yearsinprogram(C, _).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,500004 (regressionFit = 1,500000, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B), projectmember(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,866671 (regressionFit = 1,866667, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B), sameperson(A, A).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,866671 (regressionFit = 1,866667, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B), sameperson(B, B).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,866671 (regressionFit = 1,866667, penalties=4.03E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(C, B), sameperson(C, C).  [covers 5,0/8,0 pos, 0,0/0,0 neg]

% Consider expanding [#4 of outerLoop #4, bodyLen=3] 'advisedby(A, B) :- professor(B), student(A), publication(_, B).  [covers 3,0/8,0 pos, 0,0/0,0 neg]' score=-1.8666697966666665
% [ LazyGroundNthArgumentClauseIndex ]  Argument 0:  Building full index for publication/2.
%  At # nodes expanded = 4, |OPEN| = 6.  Pruned 18 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 15 bad extensions.
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B), tempadvisedby(_, B).  [covers 2,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,866671 (regressionFit = 1,866667, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B), hasposition(B, _).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,866671 (regressionFit = 1,866667, penalties=4.040000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(C, B), publication(C, _).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,866671 (regressionFit = 1,866667, penalties=4.140000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B), publication(_, B).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,866671 (regressionFit = 1,866667, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B), inphase(A, _).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,866671 (regressionFit = 1,866667, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B), yearsinprogram(A, _).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B), projectmember(_, B).  [covers 1,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,866671 (regressionFit = 1,866667, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B), sameperson(A, A).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,866671 (regressionFit = 1,866667, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B), sameperson(B, B).  [covers 3,0/8,0 pos, 0,0/0,0 neg]

% Consider expanding [#5 of outerLoop #4, bodyLen=3] 'advisedby(A, B) :- professor(B), student(A), ta(_, A, _).  [covers 2,0/8,0 pos, 0,0/0,0 neg]' score=-Infinity

% Consider expanding [#6 of outerLoop #4, bodyLen=3] 'advisedby(A, B) :- professor(B), student(A), hasposition(B, _).  [covers 6,0/8,0 pos, 0,0/0,0 neg]' score=-Infinity
% [ LazyGroundClauseIndex ]  Building full index for hasposition/2 with 9 assertions.
% [ LazyGroundNthArgumentClauseIndex ]  Argument 1:  Building full index for hasposition/2.
%  At # nodes expanded = 6, |OPEN| = 4.  Pruned 18 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -1,866671 (regressionFit = 1,866667, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _), tempadvisedby(_, B).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _), ta(_, A, _).  [covers 1,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.040000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, C), hasposition(_, C).  [covers 6,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,866671 (regressionFit = 1,866667, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _), publication(_, B).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _), inphase(A, _).  [covers 6,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _), yearsinprogram(A, _).  [covers 6,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,500004 (regressionFit = 1,500000, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _), projectmember(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _), sameperson(A, A).  [covers 6,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _), sameperson(B, B).  [covers 6,0/8,0 pos, 0,0/0,0 neg]

% Consider expanding [#7 of outerLoop #4, bodyLen=3] 'advisedby(A, B) :- professor(B), student(A), inphase(A, _).  [covers 8,0/8,0 pos, 0,0/0,0 neg]' score=-Infinity
% [ LazyGroundClauseIndex ]  Building full index for inphase/2 with 21 assertions.
% [ LazyGroundNthArgumentClauseIndex ]  Argument 1:  Building full index for inphase/2.
%  At # nodes expanded = 7, |OPEN| = 3.  Pruned 18 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -1,866671 (regressionFit = 1,866667, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _), tempadvisedby(_, B).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _), ta(_, A, _).  [covers 2,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _), hasposition(B, _).  [covers 6,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,866671 (regressionFit = 1,866667, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _), publication(_, B).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.040000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, C), inphase(_, C).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _), yearsinprogram(A, _).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,500004 (regressionFit = 1,500000, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _), projectmember(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _), sameperson(A, A).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _), sameperson(B, B).  [covers 8,0/8,0 pos, 0,0/0,0 neg]

% Consider expanding [#8 of outerLoop #4, bodyLen=3] 'advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _).  [covers 8,0/8,0 pos, 0,0/0,0 neg]' score=-Infinity
% [ LazyGroundClauseIndex ]  Building full index for yearsinprogram/2 with 21 assertions.
% [ LazyGroundNthArgumentClauseIndex ]  Argument 1:  Building full index for yearsinprogram/2.
%  At # nodes expanded = 8, |OPEN| = 2.  Pruned 18 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -1,866671 (regressionFit = 1,866667, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _), tempadvisedby(_, B).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _), ta(_, A, _).  [covers 2,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _), hasposition(B, _).  [covers 6,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,866671 (regressionFit = 1,866667, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _), publication(_, B).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _), inphase(A, _).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.040000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, C), yearsinprogram(_, C).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,500004 (regressionFit = 1,500000, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _), projectmember(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _), sameperson(A, A).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _), sameperson(B, B).  [covers 8,0/8,0 pos, 0,0/0,0 neg]

% Consider expanding [#9 of outerLoop #4, bodyLen=3] 'advisedby(A, B) :- professor(B), student(A), sameperson(A, A).  [covers 8,0/8,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 9, |OPEN| = 1.  Pruned 14 variant children.  Sending 8 items to OPEN for evaluation and possible insertion.
% Have created 8 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -1,866671 (regressionFit = 1,866667, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A), tempadvisedby(_, B).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A), ta(_, A, _).  [covers 2,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A), hasposition(B, _).  [covers 6,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,866671 (regressionFit = 1,866667, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A), publication(_, B).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A), inphase(A, _).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A), yearsinprogram(A, _).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,500004 (regressionFit = 1,500000, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A), projectmember(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.920000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A), sameperson(B, B).  [covers 8,0/8,0 pos, 0,0/0,0 neg]

***** Warning: #1 TOO MANY NODES CONSIDERED (i.e., 'expanded') for 'LearnOneClause': nodesConsidered = 10 and maxNodesToConsider = 10. *****


% The best node found: advisedby(A, B) :- professor(B), student(A), projectmember(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- professor(B), student(A), projectmember(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]

% Expanding node at Level 3 with score = -0,250.
% Will extend: advisedby(A, B) :- professor(B), student(A), projectmember(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
% Path: 0;true,false,false
Comparing variance: 0.18750000000000006 to score=0.0025 #egs=4.0
Comparing variance: 0.18750000000000003 to score=0.0025 #egs=4.0
%   Creating a TRUE-branch and FALSE-branch leaves because level = 3 >= 3

% Time for loop #4: 195 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #4, the best clause found is:
%      advisedby(A, B) :- professor(B), student(A), projectmember(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
% This clause covers 4 positive examples, of which 4 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B).  [covers 12,0/12,0 pos, 0,0/0,0 neg]'
%     Score = -4,666671 (regressionFit = 4,666667, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B).  [covers 12,0/12,0 pos, 0,0/0,0 neg]

% Have these 8 positive seeds: 1 3 5 6 7 8 10 11

% The best node found: null
%     Score = -Infinity (regressionFit = Infinity, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), ta(_, _, C).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,000006 (regressionFit = 2,000000, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), ta(_, D, C), publication(_, D).  [covers 4,0/12,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), ta(_, D, C), publication(_, D).  [covers 4,0/12,0 pos, 0,0/0,0 neg]

% Expanding node at Level 3 with score = -0,222.
% Will extend: advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), ta(_, D, C), publication(_, D).  [covers 4,0/12,0 pos, 0,0/0,0 neg]
% Path: 0;true,false,true
Comparing variance: 0.0 to score=0.0025 #egs=4.0
Comparing variance: 0.24999999999999986 to score=0.0025 #egs=8.0
%   Creating a TRUE-branch and FALSE-branch leaves because level = 3 >= 3

% Time for loop #5: 9 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #5, the best clause found is:
%      advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), ta(_, D, C), publication(_, D).  [covers 4,0/12,0 pos, 0,0/0,0 neg]
% This clause covers 4 positive examples, of which 4 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% ******************************************

%  Have stopped ILP's outer loop because the tree-structured queue is empty.

% ******************************************

%%%%%  WILL-Produced Tree #1 @ 17:27:14 5/29/21.  [Using 4.167.552 memory cells.]  %%%%%


% FOR advisedby(A, B):
%   if ( professor(B), student(A) )
%   then if ( publication(C, A), publication(C, B) )
%   | then return 0.8581489350995122;  // std dev = 0,000, 4,000 (wgt'ed) examples reached here.  /* #pos=4 */
%   | else if ( ta(D, A, E), publication(F, B) )
%   | | then if ( ta(G, H, E), publication(I, H) )
%   | | | then return 0.8581489350995122;  // std dev = 0,000, 4,000 (wgt'ed) examples reached here.  /* #pos=4 */
%   | | | else return 0.3581489350995123;  // std dev = 1,414, 8,000 (wgt'ed) examples reached here.  /* #neg=4 #pos=4 */
%   | | else if ( projectmember(J, B) )
%   | | | then return 0.6081489350995122;  // std dev = 0,866, 4,000 (wgt'ed) examples reached here.  /* #neg=1 #pos=3 */
%   | | | else return 0.10814893509951219;  // std dev = 0,866, 4,000 (wgt'ed) examples reached here.  /* #neg=3 #pos=1 */
%   else return -0.14185106490048774;  // std dev = 1,49e-08, 24,000 (wgt'ed) examples reached here.  /* #neg=24 */


% Clauses:

advisedby(A, B, 0.8581489350995122) :- 
     professor(B), 
     student(A), 
     publication(C, A), 
     publication(C, B), 
     !. // Clause #1.

advisedby(A, B, 0.8581489350995122) :- 
     professor(B), 
     student(A), 
     ta(C, A, D), 
     publication(E, B), 
     ta(F, G, D), 
     publication(H, G), 
     !. // Clause #2.

advisedby(A, B, 0.3581489350995123) :- 
     professor(B), 
     student(A), 
     ta(C, A, D), 
     publication(E, B), 
     !. // Clause #3.

advisedby(A, B, 0.6081489350995122) :- 
     professor(B), 
     student(A), 
     projectmember(C, B), 
     !. // Clause #4.

advisedby(A, B, 0.10814893509951219) :- 
     professor(B), 
     student(A), 
     !. // Clause #5.

advisedby(A, B, -0.14185106490048774) :- !. // Clause #6.


% The flattened versions of these clauses:

flattened_advisedby(a, b, 0.8581489350995122) :-  /* #pos=4 */ 
   professor(b),
   student(a),
   publication(uniqueVar1, a),
   publication(uniqueVar1, b),
   !. // Flattened version of clause #1.

flattened_advisedby(a, b, 0.8581489350995122) :-  /* #pos=4 */ 
   professor(b),
   student(a),
   ta(underscore, a, uniqueVar2),
   publication(underscore, b),
   ta(underscore, uniqueVar3, uniqueVar2),
   publication(underscore, uniqueVar3),
   !. // Flattened version of clause #2.

flattened_advisedby(a, b, 0.3581489350995123) :-  /* #neg=4 #pos=4 */ 
   professor(b),
   student(a),
   ta(underscore, a, underscore),
   publication(underscore, b),
   !. // Flattened version of clause #3.

flattened_advisedby(a, b, 0.6081489350995122) :-  /* #neg=1 #pos=3 */ 
   professor(b),
   student(a),
   projectmember(underscore, b),
   !. // Flattened version of clause #4.

flattened_advisedby(a, b, 0.10814893509951219) :-  /* #neg=3 #pos=1 */ 
   professor(b),
   student(a),
   !. // Flattened version of clause #5.

flattened_advisedby(underscore, underscore, -0.14185106490048774) :-  /* #neg=24 */ 
   !. // Flattened version of clause #6.


% The unique flattened literals:
%   ta(underscore, a, underscore)
%   publication(underscore, b)
%   professor(b)
%   publication(uniqueVar1, a)
%   projectmember(underscore, b)
%   ta(underscore, uniqueVar3, uniqueVar2)
%   ta(underscore, a, uniqueVar2)
%   student(a)
%   publication(underscore, uniqueVar3)
%   publication(uniqueVar1, b)

% Saving model in: train/models/bRDNs/advisedby.model.ckpt
% Time taken to learn 1 trees is 331 milliseconds.

%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.2222222222222221
Set score:0.0025
% Only 48 out of 48 converged.
% Kept 16 of the 16 positive examples.
% Kept 32 of the 32 negative examples.
% Dataset size: 48
Computing probabilities
prob time:10 milliseconds
No hidden examples for : advisedby
Time to build dataset: 10 milliseconds
%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.18049448012383462
Set score:0.0025
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% Have these 6 positive seeds: 3 7 11 23 28 31

% The best node found: null

% target           = advisedby(D, E)
%     Score = -Infinity (regressionFit = Infinity, penalties=2.2E-7) for clause:  advisedby(_, _).  [covers 48,0/48,0 pos, 0,0/0,0 neg]
%     Score = -4,763485 (regressionFit = 4,763484, penalties=1.12E-6) for clause:  advisedby(_, A) :- professor(A).  [covers 24,0/48,0 pos, 0,0/0,0 neg]
%     Score = -4,763486 (regressionFit = 4,763484, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- professor(B), student(A).  [covers 24,0/48,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- professor(B), student(A).  [covers 24,0/48,0 pos, 0,0/0,0 neg]

% Expanding node at Level 0 with score = 1,797693e+308.
% Will extend: advisedby(A, B) :- professor(B), student(A).  [covers 24,0/48,0 pos, 0,0/0,0 neg]
% Path: 1;
Comparing variance: 0.19847850353646715 to score=0.0025 #egs=24.0
Comparing variance: -4.625929269271485E-18 to score=0.0025 #egs=24.0
%   Creating a TRUE-branch interior node with wgtedCountTrueBranchPos = 24,0
%      addToQueueOfTreeStructuredLearningTasks (level=1; score=-0,198479)
%         ILP node to extend: advisedby(A, B) :- professor(B), student(A).  [covers 24,0/48,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 1 and with score = -0,198479) into the LAST position (#1) in the search queue.
%   Creating a FALSE-branch leaf because good enough fit since score < 0.0025

% Time for loop #1: 4 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #1, the best clause found is:
%      advisedby(A, B) :- professor(B), student(A).  [covers 24,0/48,0 pos, 0,0/0,0 neg]
% This clause covers 24 positive examples, of which 24 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- professor(B), student(A).  [covers 24,0/24,0 pos, 0,0/0,0 neg]'
%     Score = -4,763486 (regressionFit = 4,763484, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- professor(B), student(A).  [covers 24,0/24,0 pos, 0,0/0,0 neg]

% Have these 7 positive seeds: 4 7 12 13 14 17 20

% The best node found: null
%     Score = -4,400983 (regressionFit = 4,400980, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, A).  [covers 4,0/24,0 pos, 0,0/0,0 neg]
%     Score = -4,400984 (regressionFit = 4,400980, penalties=3.9300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(C, A), publication(C, B).  [covers 4,0/24,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- professor(B), student(A), publication(C, A), publication(C, B).  [covers 4,0/24,0 pos, 0,0/0,0 neg]

% Expanding node at Level 1 with score = -0,198.
% Will extend: advisedby(A, B) :- professor(B), student(A), publication(C, A), publication(C, B).  [covers 4,0/24,0 pos, 0,0/0,0 neg]
% Path: 1;true
Comparing variance: 0.0 to score=0.0025 #egs=4.0
Comparing variance: 0.22004901226245596 to score=0.0025 #egs=20.0
%   Creating a TRUE-branch leaf because wgtedCountTrueBranchPos = 4,0 < 2.1 * minPosCov = 6,3
%   Creating a FALSE-branch interior node with wgtedCountFalseBranchPos = 20,0
%      addToQueueOfTreeStructuredLearningTasks (level=2; score=-0,220049)
%         ILP node to extend: advisedby(A, B) :- professor(B), student(A).  [covers 24,0/24,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 2 and with score = -0,220049) into the LAST position (#1) in the search queue.

% Time for loop #2: 3 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #2, the best clause found is:
%      advisedby(A, B) :- professor(B), student(A), publication(C, A), publication(C, B).  [covers 4,0/24,0 pos, 0,0/0,0 neg]
% This clause covers 4 positive examples, of which 4 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- professor(B), student(A).  [covers 24,0/20,0 pos, 0,0/0,0 neg]'
%     Score = -4,763486 (regressionFit = 4,763484, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- professor(B), student(A).  [covers 20,0/20,0 pos, 0,0/0,0 neg]

% Have these 8 positive seeds: 0 1 2 4 6 9 14 19

% The best node found: null
%     Score = -4,372219 (regressionFit = 4,372216, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -4,159609 (regressionFit = 4,159605, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), ta(_, A, _).  [covers 3,0/20,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- professor(B), student(A), projectmember(_, B), ta(_, A, _).  [covers 3,0/20,0 pos, 0,0/0,0 neg]

% Expanding node at Level 2 with score = -0,220.
% Will extend: advisedby(A, B) :- professor(B), student(A), projectmember(_, B), ta(_, A, _).  [covers 3,0/20,0 pos, 0,0/0,0 neg]
% Path: 1;true,false
Comparing variance: 0.23186788746070283 to score=0.0025 #egs=3.0
Comparing variance: 0.2037647717504393 to score=0.0025 #egs=17.0
%   Creating a TRUE-branch leaf because wgtedCountTrueBranchPos = 3,0 < 2.1 * minPosCov = 6,3
%   Creating a FALSE-branch interior node with wgtedCountFalseBranchPos = 17,0
%      addToQueueOfTreeStructuredLearningTasks (level=3; score=-0,203765)
%         ILP node to extend: advisedby(A, B) :- professor(B), student(A).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 3 and with score = -0,203765) into the LAST position (#1) in the search queue.

% Time for loop #3: 3 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #3, the best clause found is:
%      advisedby(A, B) :- professor(B), student(A), projectmember(_, B), ta(_, A, _).  [covers 3,0/20,0 pos, 0,0/0,0 neg]
% This clause covers 3 positive examples, of which 3 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- professor(B), student(A).  [covers 20,0/17,0 pos, 0,0/0,0 neg]'
%     Score = -4,763486 (regressionFit = 4,763484, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- professor(B), student(A).  [covers 17,0/17,0 pos, 0,0/0,0 neg]

% Have these 4 positive seeds: 1 2 3 12

% The best node found: null
%     Score = -3,064350 (regressionFit = 3,064347, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B).  [covers 3,0/17,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- professor(B), student(A), projectmember(_, B).  [covers 3,0/17,0 pos, 0,0/0,0 neg]

% Expanding node at Level 3 with score = -0,204.
% Will extend: advisedby(A, B) :- professor(B), student(A), projectmember(_, B).  [covers 3,0/17,0 pos, 0,0/0,0 neg]
% Path: 1;true,false,false
Comparing variance: 1.4802973661668753E-16 to score=0.0025 #egs=3.0
Comparing variance: 0.21888194275923692 to score=0.0025 #egs=14.0
%   Creating a TRUE-branch and FALSE-branch leaves because level = 3 >= 3

% Time for loop #4: 2 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #4, the best clause found is:
%      advisedby(A, B) :- professor(B), student(A), projectmember(_, B).  [covers 3,0/17,0 pos, 0,0/0,0 neg]
% This clause covers 3 positive examples, of which 3 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% ******************************************

%  Have stopped ILP's outer loop because the tree-structured queue is empty.

% ******************************************

%%%%%  WILL-Produced Tree #2 @ 17:27:14 5/29/21.  [Using 4.195.544 memory cells.]  %%%%%


% FOR advisedby(A, B):
%   if ( professor(B), student(A) )
%   then if ( publication(C, A), publication(C, B) )
%   | then return 0.7194734122109545;  // std dev = 0,000, 4,000 (wgt'ed) examples reached here.  /* #pos=4 */
%   | else if ( projectmember(D, B), ta(E, A, F) )
%   | | then return 0.1281847446026639;  // std dev = 0,834, 3,000 (wgt'ed) examples reached here.  /* #neg=2 #pos=1 */
%   | | else if ( projectmember(G, B) )
%   | | | then return 0.7670719622367216;  // std dev = 2,11e-08, 3,000 (wgt'ed) examples reached here.  /* #pos=3 */
%   | | | else return 0.3648721582071893;  // std dev = 1,751, 14,000 (wgt'ed) examples reached here.  /* #neg=6 #pos=8 */
%   else return -0.12544463852839138;  // std dev = 0,000, 24,000 (wgt'ed) examples reached here.  /* #neg=24 */


% Clauses:

advisedby(A, B, 0.7194734122109545) :- 
     professor(B), 
     student(A), 
     publication(C, A), 
     publication(C, B), 
     !. // Clause #1.

advisedby(A, B, 0.1281847446026639) :- 
     professor(B), 
     student(A), 
     projectmember(C, B), 
     ta(D, A, E), 
     !. // Clause #2.

advisedby(A, B, 0.7670719622367216) :- 
     professor(B), 
     student(A), 
     projectmember(C, B), 
     !. // Clause #3.

advisedby(A, B, 0.3648721582071893) :- 
     professor(B), 
     student(A), 
     !. // Clause #4.

advisedby(A, B, -0.12544463852839138) :- !. // Clause #5.


% The flattened versions of these clauses:

flattened_advisedby(a, b, 0.7194734122109545) :-  /* #pos=4 */ 
   professor(b),
   student(a),
   publication(uniqueVar4, a),
   publication(uniqueVar4, b),
   !. // Flattened version of clause #1.

flattened_advisedby(a, b, 0.1281847446026639) :-  /* #neg=2 #pos=1 */ 
   professor(b),
   student(a),
   projectmember(underscore, b),
   ta(underscore, a, underscore),
   !. // Flattened version of clause #2.

flattened_advisedby(a, b, 0.7670719622367216) :-  /* #pos=3 */ 
   professor(b),
   student(a),
   projectmember(underscore, b),
   !. // Flattened version of clause #3.

flattened_advisedby(a, b, 0.3648721582071893) :-  /* #neg=6 #pos=8 */ 
   professor(b),
   student(a),
   !. // Flattened version of clause #4.

flattened_advisedby(underscore, underscore, -0.12544463852839138) :-  /* #neg=24 */ 
   !. // Flattened version of clause #5.


% The unique flattened literals:
%   ta(underscore, a, underscore)
%   professor(b)
%   student(a)
%   projectmember(underscore, b)
%   publication(uniqueVar4, a)
%   publication(uniqueVar4, b)

% Saving model in: train/models/bRDNs/advisedby.model.ckpt
% Time taken to learn 2 trees is 391 milliseconds.

%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.20376477175043933
Set score:0.0025
% Only 48 out of 48 converged.
% Kept 16 of the 16 positive examples.
% Kept 32 of the 32 negative examples.
% Dataset size: 48
Computing probabilities
prob time:8 milliseconds
No hidden examples for : advisedby
Time to build dataset: 8 milliseconds
%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.14395628668438998
Set score:0.0025
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% Have these 8 positive seeds: 2 6 13 14 21 23 24 29

% The best node found: null

% target           = advisedby(D, E)
%     Score = -Infinity (regressionFit = Infinity, penalties=2.2E-7) for clause:  advisedby(_, _).  [covers 48,0/48,0 pos, 0,0/0,0 neg]
%     Score = -4,273671 (regressionFit = 4,273670, penalties=1.12E-6) for clause:  advisedby(_, A) :- professor(A).  [covers 24,0/48,0 pos, 0,0/0,0 neg]
%     Score = -4,273672 (regressionFit = 4,273670, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- professor(B), student(A).  [covers 24,0/48,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- professor(B), student(A).  [covers 24,0/48,0 pos, 0,0/0,0 neg]

% Expanding node at Level 0 with score = 1,797693e+308.
% Will extend: advisedby(A, B) :- professor(B), student(A).  [covers 24,0/48,0 pos, 0,0/0,0 neg]
% Path: 2;
Comparing variance: 0.17806958348615218 to score=0.0025 #egs=24.0
Comparing variance: 2.3129646346357427E-18 to score=0.0025 #egs=24.0
%   Creating a TRUE-branch interior node with wgtedCountTrueBranchPos = 24,0
%      addToQueueOfTreeStructuredLearningTasks (level=1; score=-0,178070)
%         ILP node to extend: advisedby(A, B) :- professor(B), student(A).  [covers 24,0/48,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 1 and with score = -0,178070) into the LAST position (#1) in the search queue.
%   Creating a FALSE-branch leaf because good enough fit since score < 0.0025

% Time for loop #1: 3 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #1, the best clause found is:
%      advisedby(A, B) :- professor(B), student(A).  [covers 24,0/48,0 pos, 0,0/0,0 neg]
% This clause covers 24 positive examples, of which 24 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- professor(B), student(A).  [covers 24,0/24,0 pos, 0,0/0,0 neg]'
%     Score = -4,273672 (regressionFit = 4,273670, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- professor(B), student(A).  [covers 24,0/24,0 pos, 0,0/0,0 neg]

% Have these 8 positive seeds: 0 1 6 10 12 13 15 21

% The best node found: null
%     Score = -4,083634 (regressionFit = 4,083631, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, A).  [covers 4,0/24,0 pos, 0,0/0,0 neg]
%     Score = -4,083635 (regressionFit = 4,083631, penalties=3.9300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(C, A), publication(C, B).  [covers 4,0/24,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- professor(B), student(A), publication(C, A), publication(C, B).  [covers 4,0/24,0 pos, 0,0/0,0 neg]

% Expanding node at Level 1 with score = -0,178.
% Will extend: advisedby(A, B) :- professor(B), student(A), publication(C, A), publication(C, B).  [covers 4,0/24,0 pos, 0,0/0,0 neg]
% Path: 2;true
Comparing variance: 0.0 to score=0.0025 #egs=4.0
Comparing variance: 0.20418154247867326 to score=0.0025 #egs=20.0
%   Creating a TRUE-branch leaf because wgtedCountTrueBranchPos = 4,0 < 2.1 * minPosCov = 6,3
%   Creating a FALSE-branch interior node with wgtedCountFalseBranchPos = 20,0
%      addToQueueOfTreeStructuredLearningTasks (level=2; score=-0,204182)
%         ILP node to extend: advisedby(A, B) :- professor(B), student(A).  [covers 24,0/24,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 2 and with score = -0,204182) into the LAST position (#1) in the search queue.

% Time for loop #2: 4 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #2, the best clause found is:
%      advisedby(A, B) :- professor(B), student(A), publication(C, A), publication(C, B).  [covers 4,0/24,0 pos, 0,0/0,0 neg]
% This clause covers 4 positive examples, of which 4 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- professor(B), student(A).  [covers 24,0/20,0 pos, 0,0/0,0 neg]'
%     Score = -4,273672 (regressionFit = 4,273670, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- professor(B), student(A).  [covers 20,0/20,0 pos, 0,0/0,0 neg]

% Have these 5 positive seeds: 6 9 10 13 14

% The best node found: null
%     Score = -4,070602 (regressionFit = 4,070599, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,927918 (regressionFit = 3,927913, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), ta(_, A, _).  [covers 3,0/20,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- professor(B), student(A), projectmember(_, B), ta(_, A, _).  [covers 3,0/20,0 pos, 0,0/0,0 neg]

% Expanding node at Level 2 with score = -0,204.
% Will extend: advisedby(A, B) :- professor(B), student(A), projectmember(_, B), ta(_, A, _).  [covers 3,0/20,0 pos, 0,0/0,0 neg]
% Path: 2;true,false
Comparing variance: 0.232608159577307 to score=0.0025 #egs=3.0
Comparing variance: 0.19000522207120174 to score=0.0025 #egs=17.0
%   Creating a TRUE-branch leaf because wgtedCountTrueBranchPos = 3,0 < 2.1 * minPosCov = 6,3
%   Creating a FALSE-branch interior node with wgtedCountFalseBranchPos = 17,0
%      addToQueueOfTreeStructuredLearningTasks (level=3; score=-0,190005)
%         ILP node to extend: advisedby(A, B) :- professor(B), student(A).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 3 and with score = -0,190005) into the LAST position (#1) in the search queue.

% Time for loop #3: 3 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #3, the best clause found is:
%      advisedby(A, B) :- professor(B), student(A), projectmember(_, B), ta(_, A, _).  [covers 3,0/20,0 pos, 0,0/0,0 neg]
% This clause covers 3 positive examples, of which 3 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- professor(B), student(A).  [covers 20,0/17,0 pos, 0,0/0,0 neg]'
%     Score = -4,273672 (regressionFit = 4,273670, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- professor(B), student(A).  [covers 17,0/17,0 pos, 0,0/0,0 neg]

% Have these 5 positive seeds: 2 4 6 11 16

% The best node found: null
%     Score = -3,000654 (regressionFit = 3,000651, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B).  [covers 3,0/17,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- professor(B), student(A), projectmember(_, B).  [covers 3,0/17,0 pos, 0,0/0,0 neg]

% Expanding node at Level 3 with score = -0,190.
% Will extend: advisedby(A, B) :- professor(B), student(A), projectmember(_, B).  [covers 3,0/17,0 pos, 0,0/0,0 neg]
% Path: 2;true,false,false
Comparing variance: -7.401486830834377E-17 to score=0.0025 #egs=3.0
Comparing variance: 0.21433221813958175 to score=0.0025 #egs=14.0
%   Creating a TRUE-branch and FALSE-branch leaves because level = 3 >= 3

% Time for loop #4: 3 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #4, the best clause found is:
%      advisedby(A, B) :- professor(B), student(A), projectmember(_, B).  [covers 3,0/17,0 pos, 0,0/0,0 neg]
% This clause covers 3 positive examples, of which 3 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% ******************************************

%  Have stopped ILP's outer loop because the tree-structured queue is empty.

% ******************************************

%%%%%  WILL-Produced Tree #3 @ 17:27:14 5/29/21.  [Using 4.222.688 memory cells.]  %%%%%


% FOR advisedby(A, B):
%   if ( professor(B), student(A) )
%   then if ( publication(C, A), publication(C, B) )
%   | then return 0.5553664367462845;  // std dev = 0,000, 4,000 (wgt'ed) examples reached here.  /* #pos=4 */
%   | else if ( projectmember(D, B), ta(E, A, F) )
%   | | then return 0.10654753155474088;  // std dev = 0,835, 3,000 (wgt'ed) examples reached here.  /* #neg=2 #pos=1 */
%   | | else if ( projectmember(G, B) )
%   | | | then return 0.6046262796882593;  // std dev = 0,000, 3,000 (wgt'ed) examples reached here.  /* #pos=3 */
%   | | | else return 0.2998843411895928;  // std dev = 1,732, 14,000 (wgt'ed) examples reached here.  /* #neg=6 #pos=8 */
%   else return -0.11231637819360639;  // std dev = 7,45e-09, 24,000 (wgt'ed) examples reached here.  /* #neg=24 */


% Clauses:

advisedby(A, B, 0.5553664367462845) :- 
     professor(B), 
     student(A), 
     publication(C, A), 
     publication(C, B), 
     !. // Clause #1.

advisedby(A, B, 0.10654753155474088) :- 
     professor(B), 
     student(A), 
     projectmember(C, B), 
     ta(D, A, E), 
     !. // Clause #2.

advisedby(A, B, 0.6046262796882593) :- 
     professor(B), 
     student(A), 
     projectmember(C, B), 
     !. // Clause #3.

advisedby(A, B, 0.2998843411895928) :- 
     professor(B), 
     student(A), 
     !. // Clause #4.

advisedby(A, B, -0.11231637819360639) :- !. // Clause #5.


% The flattened versions of these clauses:

flattened_advisedby(a, b, 0.5553664367462845) :-  /* #pos=4 */ 
   professor(b),
   student(a),
   publication(uniqueVar5, a),
   publication(uniqueVar5, b),
   !. // Flattened version of clause #1.

flattened_advisedby(a, b, 0.10654753155474088) :-  /* #neg=2 #pos=1 */ 
   professor(b),
   student(a),
   projectmember(underscore, b),
   ta(underscore, a, underscore),
   !. // Flattened version of clause #2.

flattened_advisedby(a, b, 0.6046262796882593) :-  /* #pos=3 */ 
   professor(b),
   student(a),
   projectmember(underscore, b),
   !. // Flattened version of clause #3.

flattened_advisedby(a, b, 0.2998843411895928) :-  /* #neg=6 #pos=8 */ 
   professor(b),
   student(a),
   !. // Flattened version of clause #4.

flattened_advisedby(underscore, underscore, -0.11231637819360639) :-  /* #neg=24 */ 
   !. // Flattened version of clause #5.


% The unique flattened literals:
%   ta(underscore, a, underscore)
%   publication(uniqueVar5, a)
%   publication(uniqueVar5, b)
%   professor(b)
%   student(a)
%   projectmember(underscore, b)

% Saving model in: train/models/bRDNs/advisedby.model.ckpt
% Time taken to learn 3 trees is 453 milliseconds.

%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.19000522207120168
Set score:0.0025
% Only 48 out of 48 converged.
% Kept 16 of the 16 positive examples.
% Kept 32 of the 32 negative examples.
% Dataset size: 48
Computing probabilities
prob time:7 milliseconds
No hidden examples for : advisedby
Time to build dataset: 8 milliseconds
%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.11820280964883707
Set score:0.0025
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% Have these 8 positive seeds: 0 3 4 7 8 17 18 20

% The best node found: null

% target           = advisedby(D, E)
%     Score = -Infinity (regressionFit = Infinity, penalties=2.2E-7) for clause:  advisedby(_, _).  [covers 48,0/48,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=1.12E-6) for clause:  advisedby(A, _) :- student(A).  [covers 48,0/48,0 pos, 0,0/0,0 neg]
%     Score = -3,961007 (regressionFit = 3,961005, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- student(A), professor(B).  [covers 24,0/48,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- student(A), professor(B).  [covers 24,0/48,0 pos, 0,0/0,0 neg]

% Expanding node at Level 0 with score = 1,797693e+308.
% Will extend: advisedby(A, B) :- student(A), professor(B).  [covers 24,0/48,0 pos, 0,0/0,0 neg]
% Path: 3;
Comparing variance: 0.1650418613992137 to score=0.0025 #egs=24.0
Comparing variance: -2.3129646346357427E-18 to score=0.0025 #egs=24.0
%   Creating a TRUE-branch interior node with wgtedCountTrueBranchPos = 24,0
%      addToQueueOfTreeStructuredLearningTasks (level=1; score=-0,165042)
%         ILP node to extend: advisedby(A, B) :- student(A), professor(B).  [covers 24,0/48,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 1 and with score = -0,165042) into the LAST position (#1) in the search queue.
%   Creating a FALSE-branch leaf because good enough fit since score < 0.0025

% Time for loop #1: 3 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #1, the best clause found is:
%      advisedby(A, B) :- student(A), professor(B).  [covers 24,0/48,0 pos, 0,0/0,0 neg]
% This clause covers 24 positive examples, of which 24 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- student(A), professor(B).  [covers 24,0/24,0 pos, 0,0/0,0 neg]'
%     Score = -3,961007 (regressionFit = 3,961005, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- student(A), professor(B).  [covers 24,0/24,0 pos, 0,0/0,0 neg]

% Have these 8 positive seeds: 0 2 5 8 9 10 13 14

% The best node found: null
%     Score = -3,865149 (regressionFit = 3,865146, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, A).  [covers 4,0/24,0 pos, 0,0/0,0 neg]
%     Score = -3,865150 (regressionFit = 3,865146, penalties=3.9300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(C, A), publication(C, B).  [covers 4,0/24,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- student(A), professor(B), publication(C, A), publication(C, B).  [covers 4,0/24,0 pos, 0,0/0,0 neg]

% Expanding node at Level 1 with score = -0,165.
% Will extend: advisedby(A, B) :- student(A), professor(B), publication(C, A), publication(C, B).  [covers 4,0/24,0 pos, 0,0/0,0 neg]
% Path: 3;true
Comparing variance: 0.0 to score=0.0025 #egs=4.0
Comparing variance: 0.19325731771249052 to score=0.0025 #egs=20.0
%   Creating a TRUE-branch leaf because wgtedCountTrueBranchPos = 4,0 < 2.1 * minPosCov = 6,3
%   Creating a FALSE-branch interior node with wgtedCountFalseBranchPos = 20,0
%      addToQueueOfTreeStructuredLearningTasks (level=2; score=-0,193257)
%         ILP node to extend: advisedby(A, B) :- student(A), professor(B).  [covers 24,0/24,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 2 and with score = -0,193257) into the LAST position (#1) in the search queue.

% Time for loop #2: 3 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #2, the best clause found is:
%      advisedby(A, B) :- student(A), professor(B), publication(C, A), publication(C, B).  [covers 4,0/24,0 pos, 0,0/0,0 neg]
% This clause covers 4 positive examples, of which 4 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- student(A), professor(B).  [covers 24,0/20,0 pos, 0,0/0,0 neg]'
%     Score = -3,961007 (regressionFit = 3,961005, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- student(A), professor(B).  [covers 20,0/20,0 pos, 0,0/0,0 neg]

% Have these 8 positive seeds: 1 2 3 6 7 9 10 12
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% Consider expanding [#1 of outerLoop #3, bodyLen=2] 'advisedby(A, B) :- student(A), professor(B).  [covers 20,0/20,0 pos, 0,0/0,0 neg]' score=-3.961006693581129
%  At # nodes expanded = 1, |OPEN| = 0.  Pruned 16 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -3,837690 (regressionFit = 3,837687, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
% Gleaner: New best node found (score = -3,837690): advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,863350 (regressionFit = 3,863347, penalties=3.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _).  [covers 18,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,860354 (regressionFit = 3,860351, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,860483 (regressionFit = 3,860480, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.0200000000000007E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.0200000000000007E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(B, B).  [covers 20,0/20,0 pos, 0,0/0,0 neg]

% Consider expanding [#2 of outerLoop #3, bodyLen=3] 'advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]' score=-3.8376901150066787
%  At # nodes expanded = 2, |OPEN| = 8.  Pruned 34 variant children.  Sending 14 items to OPEN for evaluation and possible insertion.
% Have created 14 valid-on-seeds descendants and have picked up 26 bad extensions.
%     Score = -3,837691 (regressionFit = 3,837687, penalties=3.9300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(C, B), student(C).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,837691 (regressionFit = 3,837687, penalties=4.140000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B), tempadvisedby(_, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,854616 (regressionFit = 3,854612, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B), ta(_, A, _).  [covers 10,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,837691 (regressionFit = 3,837687, penalties=4.250000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(C, B), ta(_, C, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,837691 (regressionFit = 3,837687, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B), hasposition(B, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,824143 (regressionFit = 3,824139, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B), publication(_, B).  [covers 11,0/20,0 pos, 0,0/0,0 neg]
% Gleaner: New best node found (score = -3,824143): advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B), publication(_, B).  [covers 11,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,837691 (regressionFit = 3,837687, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B), inphase(A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,837691 (regressionFit = 3,837687, penalties=4.14E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(C, B), inphase(C, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,837691 (regressionFit = 3,837687, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B), yearsinprogram(A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,837691 (regressionFit = 3,837687, penalties=4.14E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(C, B), yearsinprogram(C, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,860484 (regressionFit = 3,860480, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B), projectmember(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,837691 (regressionFit = 3,837687, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B), sameperson(A, A).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,837691 (regressionFit = 3,837687, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B), sameperson(B, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,837691 (regressionFit = 3,837687, penalties=4.03E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(C, B), sameperson(C, C).  [covers 14,0/20,0 pos, 0,0/0,0 neg]

% Consider expanding [#3 of outerLoop #3, bodyLen=3] 'advisedby(A, B) :- student(A), professor(B), publication(_, B).  [covers 15,0/20,0 pos, 0,0/0,0 neg]' score=-3.860354130996728
%  At # nodes expanded = 3, |OPEN| = 7.  Pruned 18 variant children.  Sending 10 items to OPEN for evaluation and possible insertion.
% Have created 10 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -3,824143 (regressionFit = 3,824139, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), tempadvisedby(_, B).  [covers 11,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,677116 (regressionFit = 3,677112, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _).  [covers 12,0/20,0 pos, 0,0/0,0 neg]
% Gleaner: New best node found (score = -3,677116): advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _).  [covers 12,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,860355 (regressionFit = 3,860351, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), hasposition(B, _).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,860355 (regressionFit = 3,860351, penalties=4.040000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(C, B), publication(C, _).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,860355 (regressionFit = 3,860351, penalties=4.140000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), publication(_, B).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,860355 (regressionFit = 3,860351, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), inphase(A, _).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,860355 (regressionFit = 3,860351, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), yearsinprogram(A, _).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,840457 (regressionFit = 3,840453, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), projectmember(_, B).  [covers 3,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,860355 (regressionFit = 3,860351, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), sameperson(A, A).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,860355 (regressionFit = 3,860351, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), sameperson(B, B).  [covers 15,0/20,0 pos, 0,0/0,0 neg]

% Consider expanding [#4 of outerLoop #3, bodyLen=3] 'advisedby(A, B) :- student(A), professor(B), projectmember(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]' score=-3.860482837409514
%  At # nodes expanded = 4, |OPEN| = 6.  Pruned 20 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 15 bad extensions.
%     Score = -3,860484 (regressionFit = 3,860480, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B), tempadvisedby(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,860484 (regressionFit = 3,860480, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B), hasposition(B, _).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,840457 (regressionFit = 3,840453, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B), publication(_, B).  [covers 3,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,860484 (regressionFit = 3,860480, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B), inphase(A, _).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,860484 (regressionFit = 3,860480, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B), yearsinprogram(A, _).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,860484 (regressionFit = 3,860480, penalties=4.140000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B), projectmember(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,860484 (regressionFit = 3,860480, penalties=4.03E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(C, B), sameproject(C, C).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,860484 (regressionFit = 3,860480, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B), sameperson(A, A).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,860484 (regressionFit = 3,860480, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B), sameperson(B, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]

% Consider expanding [#5 of outerLoop #3, bodyLen=3] 'advisedby(A, B) :- student(A), professor(B), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]' score=-3.8633501717146217
% [ LazyGroundClauseIndex ]  Building full index for ta/3 with 53 assertions.
% [ LazyGroundNthArgumentClauseIndex ]  Argument 0:  Building full index for ta/3.
% [ LazyGroundNthArgumentClauseIndex ]  Argument 0:  Building full index for courselevel/2.
% [ LazyGroundClauseIndex ]  Building full index for samecourse/2 with 28 assertions.
% [ LazyGroundNthArgumentClauseIndex ]  Argument 0:  Building full index for samecourse/2.
% [ LazyGroundNthArgumentClauseIndex ]  Argument 1:  Building full index for samecourse/2.
%  At # nodes expanded = 5, |OPEN| = 5.  Pruned 26 variant children.  Sending 14 items to OPEN for evaluation and possible insertion.
% Have created 14 valid-on-seeds descendants and have picked up 15 bad extensions.
%     Score = -3,854616 (regressionFit = 3,854612, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), tempadvisedby(_, B).  [covers 10,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,863351 (regressionFit = 3,863347, penalties=4.05E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(C, _, D).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,863351 (regressionFit = 3,863347, penalties=4.260000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, C), ta(_, _, C).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,863351 (regressionFit = 3,863347, penalties=4.150000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,863351 (regressionFit = 3,863347, penalties=4.260000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, _, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,863351 (regressionFit = 3,863347, penalties=4.3600000000000015E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,825519 (regressionFit = 3,825515, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), hasposition(B, _).  [covers 13,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,677116 (regressionFit = 3,677112, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), publication(_, B).  [covers 12,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,863351 (regressionFit = 3,863347, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), inphase(A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,863351 (regressionFit = 3,863347, penalties=4.250000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), courselevel(C, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,863351 (regressionFit = 3,863347, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), yearsinprogram(A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,863351 (regressionFit = 3,863347, penalties=4.14E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), samecourse(C, C).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,863351 (regressionFit = 3,863347, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), sameperson(A, A).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,863351 (regressionFit = 3,863347, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), sameperson(B, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]

% Consider expanding [#6 of outerLoop #3, bodyLen=3] 'advisedby(A, B) :- student(A), professor(B), hasposition(B, _).  [covers 18,0/20,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 6, |OPEN| = 4.  Pruned 18 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -3,837691 (regressionFit = 3,837687, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _), tempadvisedby(_, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,825519 (regressionFit = 3,825515, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _), ta(_, A, _).  [covers 13,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.040000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, C), hasposition(_, C).  [covers 18,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,860355 (regressionFit = 3,860351, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _), publication(_, B).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _), inphase(A, _).  [covers 18,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _), yearsinprogram(A, _).  [covers 18,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,860484 (regressionFit = 3,860480, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _), projectmember(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _), sameperson(A, A).  [covers 18,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _), sameperson(B, B).  [covers 18,0/20,0 pos, 0,0/0,0 neg]

% Consider expanding [#7 of outerLoop #3, bodyLen=3] 'advisedby(A, B) :- student(A), professor(B), inphase(A, _).  [covers 20,0/20,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 7, |OPEN| = 3.  Pruned 18 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -3,837691 (regressionFit = 3,837687, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _), tempadvisedby(_, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,863351 (regressionFit = 3,863347, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _), hasposition(B, _).  [covers 18,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,860355 (regressionFit = 3,860351, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _), publication(_, B).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.040000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, C), inphase(_, C).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _), yearsinprogram(A, _).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,860484 (regressionFit = 3,860480, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _), projectmember(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _), sameperson(A, A).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _), sameperson(B, B).  [covers 20,0/20,0 pos, 0,0/0,0 neg]

% Consider expanding [#8 of outerLoop #3, bodyLen=3] 'advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _).  [covers 20,0/20,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 8, |OPEN| = 2.  Pruned 18 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -3,837691 (regressionFit = 3,837687, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _), tempadvisedby(_, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,863351 (regressionFit = 3,863347, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _), hasposition(B, _).  [covers 18,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,860355 (regressionFit = 3,860351, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _), publication(_, B).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _), inphase(A, _).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.040000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, C), yearsinprogram(_, C).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,860484 (regressionFit = 3,860480, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _), projectmember(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _), sameperson(A, A).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _), sameperson(B, B).  [covers 20,0/20,0 pos, 0,0/0,0 neg]

% Consider expanding [#9 of outerLoop #3, bodyLen=3] 'advisedby(A, B) :- student(A), professor(B), sameperson(A, A).  [covers 20,0/20,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 9, |OPEN| = 1.  Pruned 14 variant children.  Sending 8 items to OPEN for evaluation and possible insertion.
% Have created 8 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -3,837691 (regressionFit = 3,837687, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A), tempadvisedby(_, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,863351 (regressionFit = 3,863347, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A), hasposition(B, _).  [covers 18,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,860355 (regressionFit = 3,860351, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A), publication(_, B).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A), inphase(A, _).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A), yearsinprogram(A, _).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,860484 (regressionFit = 3,860480, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A), projectmember(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.920000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A), sameperson(B, B).  [covers 20,0/20,0 pos, 0,0/0,0 neg]

***** Warning: #2 TOO MANY NODES CONSIDERED (i.e., 'expanded') for 'LearnOneClause': nodesConsidered = 10 and maxNodesToConsider = 10. *****


% The best node found: advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _).  [covers 12,0/20,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _).  [covers 12,0/20,0 pos, 0,0/0,0 neg]

% Expanding node at Level 2 with score = -0,193.
% Will extend: advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _).  [covers 12,0/20,0 pos, 0,0/0,0 neg]
% Path: 3;true,false
Comparing variance: 0.19678109385079431 to score=0.0025 #egs=12.0
Comparing variance: 0.16446729997627493 to score=0.0025 #egs=8.0
%   Creating a TRUE-branch interior node with wgtedCountTrueBranchPos = 12,0
%      addToQueueOfTreeStructuredLearningTasks (level=3; score=-0,196781)
%         ILP node to extend: advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _).  [covers 12,0/20,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 3 and with score = -0,196781) into the LAST position (#1) in the search queue.
%   Creating a FALSE-branch interior node with wgtedCountFalseBranchPos = 8,0
%      addToQueueOfTreeStructuredLearningTasks (level=3; score=-0,164467)
%         ILP node to extend: advisedby(A, B) :- student(A), professor(B).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 3 and with score = -0,164467) into the LAST position (#2) in the search queue.

% Time for loop #3: 143 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #3, the best clause found is:
%      advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _).  [covers 12,0/20,0 pos, 0,0/0,0 neg]
% This clause covers 12 positive examples, of which 12 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]'
%     Score = -3,677116 (regressionFit = 3,677112, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]

% Have these 6 positive seeds: 2 4 5 6 7 11
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% Consider expanding [#1 of outerLoop #4, bodyLen=4] 'advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]' score=-3.677115876019731
%  At # nodes expanded = 1, |OPEN| = 0.  Pruned 28 variant children.  Sending 15 items to OPEN for evaluation and possible insertion.
% Have created 15 valid-on-seeds descendants and have picked up 15 bad extensions.
%     Score = -2,360581 (regressionFit = 2,360575, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), tempadvisedby(_, B).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
% Gleaner: New best node found (score = -2,360581): advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), tempadvisedby(_, B).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.160000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, D), ta(C, _, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, C), ta(_, _, C).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.2600000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, _, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.47E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), ta(_, A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), hasposition(B, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.2600000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(C, B), ta(_, A, _), publication(C, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.360000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), publication(_, B).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), inphase(A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.36E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), courselevel(C, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), yearsinprogram(A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.2500000000000006E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), samecourse(C, C).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.3500000000000004E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), sameperson(A, A).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.3500000000000004E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), sameperson(B, B).  [covers 12,0/12,0 pos, 0,0/0,0 neg]

% Consider expanding [#2 of outerLoop #4, bodyLen=5] 'advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), tempadvisedby(_, B).  [covers 9,0/12,0 pos, 0,0/0,0 neg]' score=-2.360580803054874
%  At # nodes expanded = 2, |OPEN| = 14.  Pruned 53 variant children.  Sending 20 items to OPEN for evaluation and possible insertion.
% Have created 20 valid-on-seeds descendants and have picked up 28 bad extensions.
%     Score = -2,360582 (regressionFit = 2,360575, penalties=6.260000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), tempadvisedby(C, B), student(C).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,360582 (regressionFit = 2,360575, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, D), tempadvisedby(_, B), ta(C, _, D).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,360582 (regressionFit = 2,360575, penalties=6.480000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, C), tempadvisedby(_, B), ta(_, _, C).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,360582 (regressionFit = 2,360575, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), tempadvisedby(_, B), ta(C, A, _).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), tempadvisedby(D, B), ta(C, D, _).  [covers 1,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,360582 (regressionFit = 2,360575, penalties=6.480000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), tempadvisedby(_, B), ta(C, _, _).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,360582 (regressionFit = 2,360575, penalties=6.580000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), tempadvisedby(_, B), ta(_, A, _).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,360582 (regressionFit = 2,360575, penalties=6.480000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), tempadvisedby(C, B), ta(_, C, _).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,360582 (regressionFit = 2,360575, penalties=6.5700000000000015E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), tempadvisedby(_, B), hasposition(B, _).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,360582 (regressionFit = 2,360575, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(C, B), ta(_, A, _), tempadvisedby(_, B), publication(C, _).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,360582 (regressionFit = 2,360575, penalties=6.470000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), tempadvisedby(_, B), publication(_, B).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,360582 (regressionFit = 2,360575, penalties=6.5700000000000015E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), tempadvisedby(_, B), inphase(A, _).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,360582 (regressionFit = 2,360575, penalties=6.470000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), tempadvisedby(C, B), inphase(C, _).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,360582 (regressionFit = 2,360575, penalties=6.470000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), tempadvisedby(_, B), courselevel(C, _).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,360582 (regressionFit = 2,360575, penalties=6.5700000000000015E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), tempadvisedby(_, B), yearsinprogram(A, _).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,360582 (regressionFit = 2,360575, penalties=6.470000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), tempadvisedby(C, B), yearsinprogram(C, _).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,360582 (regressionFit = 2,360575, penalties=6.360000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), tempadvisedby(_, B), samecourse(C, C).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,360582 (regressionFit = 2,360575, penalties=6.460000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), tempadvisedby(_, B), sameperson(A, A).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,360582 (regressionFit = 2,360575, penalties=6.460000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), tempadvisedby(_, B), sameperson(B, B).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,360582 (regressionFit = 2,360575, penalties=6.360000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), tempadvisedby(C, B), sameperson(C, C).  [covers 9,0/12,0 pos, 0,0/0,0 neg]

% Consider expanding [#3 of outerLoop #4, bodyLen=5] 'advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, D), ta(C, _, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 3, |OPEN| = 13.  Pruned 52 variant children.  Sending 23 items to OPEN for evaluation and possible insertion.
% Have created 23 valid-on-seeds descendants and have picked up 26 bad extensions.
%     Score = -Infinity (regressionFit = Infinity, penalties=5.9600000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, D), ta(C, E, D), student(E).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,360582 (regressionFit = 2,360575, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, D), ta(C, _, D), tempadvisedby(_, B).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.170000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, D), ta(C, _, D), ta(C, _, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, D), ta(C, _, D), ta(_, _, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.170000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, D), ta(C, _, D), ta(C, A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.07E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, D), ta(C, E, D), ta(C, E, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, D), ta(C, _, D), ta(C, _, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, D), ta(C, _, D), ta(_, A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.180000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, D), ta(C, E, D), ta(_, E, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, D), ta(C, _, D), hasposition(B, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.07E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(C, B), ta(D, A, E), ta(D, _, E), publication(C, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.170000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, D), ta(C, _, D), publication(_, B).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, D), ta(C, _, D), inphase(A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.170000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, D), ta(C, E, D), inphase(E, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, D), ta(C, _, D), courselevel(C, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, D), ta(C, _, D), yearsinprogram(A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.170000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, D), ta(C, E, D), yearsinprogram(E, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.160000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, D), ta(C, _, D), samecourse(C, C).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.160000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, D), ta(C, _, D), sameperson(A, A).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.060000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, D), ta(C, E, D), sameperson(A, E).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.160000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, D), ta(C, _, D), sameperson(B, B).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.060000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, D), ta(C, E, D), sameperson(E, A).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.060000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, D), ta(C, E, D), sameperson(E, E).  [covers 12,0/12,0 pos, 0,0/0,0 neg]

% Consider expanding [#4 of outerLoop #4, bodyLen=5] 'advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, C), ta(_, _, C).  [covers 12,0/12,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 4, |OPEN| = 12.  Pruned 71 variant children.  Sending 33 items to OPEN for evaluation and possible insertion.
% Have created 33 valid-on-seeds descendants and have picked up 29 bad extensions.
%     Score = -Infinity (regressionFit = Infinity, penalties=6.170000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, C), ta(_, D, C), student(D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3800000000000024E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, C), ta(_, D, C), tempadvisedby(D, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,360582 (regressionFit = 2,360575, penalties=6.480000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, C), ta(_, _, C), tempadvisedby(_, B).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, D), ta(_, _, D), ta(C, _, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, C), ta(D, _, C), ta(D, _, C).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.4900000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, C), ta(_, _, C), ta(_, _, C).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, D), ta(_, _, D), ta(C, A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.180000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, D), ta(_, E, D), ta(C, E, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3900000000000015E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, D), ta(_, _, D), ta(C, _, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, C), ta(D, _, C), ta(D, A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.180000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, C), ta(D, E, C), ta(D, E, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3900000000000015E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, C), ta(D, _, C), ta(D, _, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.4900000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, C), ta(_, _, C), ta(_, A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3900000000000015E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, C), ta(_, D, C), ta(_, D, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.480000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, C), ta(_, _, C), hasposition(B, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(C, B), ta(_, A, D), ta(_, _, D), publication(C, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3800000000000024E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, C), ta(_, _, C), publication(_, B).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,010776 (regressionFit = 2,010770, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, C), ta(_, D, C), publication(_, D).  [covers 4,0/12,0 pos, 0,0/0,0 neg]
% Gleaner: New best node found (score = -2,010776): advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, C), ta(_, D, C), publication(_, D).  [covers 4,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.480000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, C), ta(_, _, C), inphase(A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3800000000000024E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, C), ta(_, D, C), inphase(D, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3800000000000024E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, D), ta(_, _, D), courselevel(C, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3800000000000024E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, C), ta(D, _, C), courselevel(D, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.480000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, C), ta(_, _, C), yearsinprogram(A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3800000000000024E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, C), ta(_, D, C), yearsinprogram(D, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, D), ta(_, _, D), samecourse(C, C).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.170000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, D), ta(E, _, D), samecourse(C, E).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.170000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, D), ta(E, _, D), samecourse(E, C).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, C), ta(D, _, C), samecourse(D, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, C), ta(_, _, C), sameperson(A, A).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, C), ta(_, D, C), sameperson(A, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, C), ta(_, _, C), sameperson(B, B).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, C), ta(_, D, C), sameperson(D, A).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, C), ta(_, D, C), sameperson(D, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]

% Consider expanding [#5 of outerLoop #4, bodyLen=5] 'advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 5, |OPEN| = 11.  Pruned 34 variant children.  Sending 17 items to OPEN for evaluation and possible insertion.
% Have created 17 valid-on-seeds descendants and have picked up 16 bad extensions.
%     Score = -2,360582 (regressionFit = 2,360575, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, A, _), tempadvisedby(_, B).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.170000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, D), ta(C, A, _), ta(C, _, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.170000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, A, D), ta(C, _, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, D), ta(C, A, _), ta(_, _, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, A, D), ta(_, _, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, A, _), ta(C, A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3800000000000024E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, A, _), ta(C, _, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3800000000000024E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, A, _), ta(_, A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, A, _), hasposition(B, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.170000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(C, B), ta(D, A, _), ta(D, A, _), publication(C, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, A, _), publication(_, B).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, A, _), inphase(A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, A, _), courselevel(C, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, A, _), yearsinprogram(A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.260000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, A, _), samecourse(C, C).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.260000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, A, _), sameperson(A, A).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.260000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, A, _), sameperson(B, B).  [covers 12,0/12,0 pos, 0,0/0,0 neg]

% Consider expanding [#6 of outerLoop #4, bodyLen=5] 'advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, _, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 6, |OPEN| = 10.  Pruned 65 variant children.  Sending 30 items to OPEN for evaluation and possible insertion.
% Have created 30 valid-on-seeds descendants and have picked up 28 bad extensions.
%     Score = -Infinity (regressionFit = Infinity, penalties=6.170000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, D, _), student(D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, D, _), tempadvisedby(D, B).  [covers 1,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3800000000000024E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, D, _), tempadvisedby(D, _).  [covers 11,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,360582 (regressionFit = 2,360575, penalties=6.480000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, _, _), tempadvisedby(_, B).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, D), ta(C, _, _), ta(C, _, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, _, D), ta(C, _, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, _, D), ta(_, A, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.180000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, D), ta(C, E, _), ta(_, E, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3900000000000015E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, D), ta(C, _, _), ta(_, _, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3900000000000015E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, _, D), ta(_, _, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3800000000000024E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, _, _), ta(C, A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, D, _), ta(C, D, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.4900000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, _, _), ta(C, _, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.4900000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, _, _), ta(_, A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3900000000000015E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, D, _), ta(_, D, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.480000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, _, _), hasposition(B, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(C, B), ta(D, A, _), ta(D, _, _), publication(C, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3800000000000024E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, _, _), publication(_, B).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -1,953797 (regressionFit = 1,953791, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, D, _), publication(_, D).  [covers 3,0/12,0 pos, 0,0/0,0 neg]
% Gleaner: New best node found (score = -1,953797): advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, D, _), publication(_, D).  [covers 3,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.480000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, _, _), inphase(A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3800000000000024E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, D, _), inphase(D, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.480000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, _, _), courselevel(C, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.480000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, _, _), yearsinprogram(A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3800000000000024E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, D, _), yearsinprogram(D, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, _, _), samecourse(C, C).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, _, _), sameperson(A, A).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, D, _), sameperson(A, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, _, _), sameperson(B, B).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, D, _), sameperson(D, A).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, D, _), sameperson(D, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]

% Consider expanding [#7 of outerLoop #4, bodyLen=5] 'advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), ta(_, A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 7, |OPEN| = 9.  Pruned 56 variant children.  Sending 25 items to OPEN for evaluation and possible insertion.
% Have created 25 valid-on-seeds descendants and have picked up 20 bad extensions.
%     Score = -2,360582 (regressionFit = 2,360575, penalties=6.580000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), ta(_, A, _), tempadvisedby(_, B).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, D), ta(_, A, _), ta(C, _, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(_, A, D), ta(C, _, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, C), ta(D, A, _), ta(D, _, C).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), ta(C, A, D), ta(C, _, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.4900000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, C), ta(_, A, _), ta(_, _, C).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.4900000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), ta(_, A, C), ta(_, _, C).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3800000000000024E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(_, A, _), ta(C, A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.4900000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(_, A, _), ta(C, _, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3800000000000024E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), ta(C, A, _), ta(C, A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.4900000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), ta(C, A, _), ta(C, _, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.5900000000000004E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), ta(_, A, _), ta(_, A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.580000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), ta(_, A, _), hasposition(B, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3800000000000024E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(C, B), ta(_, A, _), ta(_, A, _), publication(C, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.480000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), ta(_, A, _), publication(_, B).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.580000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), ta(_, A, _), inphase(A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.480000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(_, A, _), courselevel(C, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.480000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), ta(C, A, _), courselevel(C, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.580000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), ta(_, A, _), yearsinprogram(A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(_, A, _), samecourse(C, C).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(D, A, _), samecourse(C, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(D, A, _), samecourse(D, C).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), ta(C, A, _), samecourse(C, C).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.470000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), ta(_, A, _), sameperson(A, A).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.470000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), ta(_, A, _), sameperson(B, B).  [covers 12,0/12,0 pos, 0,0/0,0 neg]

% Consider expanding [#8 of outerLoop #4, bodyLen=5] 'advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), hasposition(B, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 8, |OPEN| = 8.  Pruned 30 variant children.  Sending 15 items to OPEN for evaluation and possible insertion.
% Have created 15 valid-on-seeds descendants and have picked up 15 bad extensions.
%     Score = -2,360582 (regressionFit = 2,360575, penalties=6.5700000000000015E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), hasposition(B, _), tempadvisedby(_, B).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, D), hasposition(B, _), ta(C, _, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.480000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, C), hasposition(B, _), ta(_, _, C).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), hasposition(B, _), ta(C, A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.480000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), hasposition(B, _), ta(C, _, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.580000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), hasposition(B, _), ta(_, A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), hasposition(B, C), hasposition(_, C).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(C, B), ta(_, A, _), hasposition(B, _), publication(C, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.470000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), hasposition(B, _), publication(_, B).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.5700000000000015E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), hasposition(B, _), inphase(A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.470000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), hasposition(B, _), courselevel(C, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.5700000000000015E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), hasposition(B, _), yearsinprogram(A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.360000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), hasposition(B, _), samecourse(C, C).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.460000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), hasposition(B, _), sameperson(A, A).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.460000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _), hasposition(B, _), sameperson(B, B).  [covers 12,0/12,0 pos, 0,0/0,0 neg]

% Consider expanding [#9 of outerLoop #4, bodyLen=5] 'advisedby(A, B) :- student(A), professor(B), publication(C, B), ta(_, A, _), publication(C, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 9, |OPEN| = 7.  Pruned 53 variant children.  Sending 25 items to OPEN for evaluation and possible insertion.
% Have created 25 valid-on-seeds descendants and have picked up 24 bad extensions.
%     Score = -Infinity (regressionFit = Infinity, penalties=6.0600000000000004E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(C, B), ta(_, A, _), publication(C, D), professor(D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.0600000000000004E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(C, B), ta(_, A, _), publication(C, D), student(D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,360582 (regressionFit = 2,360575, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(C, B), ta(_, A, _), publication(C, _), tempadvisedby(_, B).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(C, B), ta(_, A, _), publication(C, D), tempadvisedby(_, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.07E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(C, B), ta(D, A, E), publication(C, _), ta(D, _, E).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(C, B), ta(_, A, D), publication(C, _), ta(_, _, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.170000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(C, B), ta(D, A, _), publication(C, _), ta(D, A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(C, B), ta(D, A, _), publication(C, _), ta(D, _, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3800000000000024E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(C, B), ta(_, A, _), publication(C, _), ta(_, A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(C, B), ta(_, A, _), publication(C, _), hasposition(B, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(C, B), ta(_, A, _), publication(C, D), hasposition(D, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(C, B), ta(_, A, _), publication(C, _), publication(C, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(C, B), ta(_, A, _), publication(C, _), publication(_, B).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.170000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(C, B), ta(_, A, _), publication(C, D), publication(_, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(C, B), ta(_, A, _), publication(C, _), inphase(A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,261941 (regressionFit = 2,261934, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(C, B), ta(_, A, _), publication(C, D), inphase(D, _).  [covers 8,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(C, B), ta(D, A, _), publication(C, _), courselevel(D, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(C, B), ta(_, A, _), publication(C, _), yearsinprogram(A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,261941 (regressionFit = 2,261934, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(C, B), ta(_, A, _), publication(C, D), yearsinprogram(D, _).  [covers 8,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.160000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(C, B), ta(D, A, _), publication(C, _), samecourse(D, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.260000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(C, B), ta(_, A, _), publication(C, _), sameperson(A, A).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.260000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(C, B), ta(_, A, _), publication(C, _), sameperson(B, B).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.160000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(C, B), ta(_, A, _), publication(C, D), sameperson(B, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.160000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(C, B), ta(_, A, _), publication(C, D), sameperson(D, B).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.160000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(C, B), ta(_, A, _), publication(C, D), sameperson(D, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]

***** Warning: #3 TOO MANY NODES CONSIDERED (i.e., 'expanded') for 'LearnOneClause': nodesConsidered = 10 and maxNodesToConsider = 10. *****


% The best node found: advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, D, _), publication(_, D).  [covers 3,0/12,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, D, _), publication(_, D).  [covers 3,0/12,0 pos, 0,0/0,0 neg]

% Expanding node at Level 3 with score = -0,197.
% Will extend: advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, D, _), publication(_, D).  [covers 3,0/12,0 pos, 0,0/0,0 neg]
% Path: 3;true,false,true
Comparing variance: 0.0030015656038113736 to score=0.0025 #egs=3.0
Comparing variance: 0.21608736396313336 to score=0.0025 #egs=9.0
%   Creating a TRUE-branch and FALSE-branch leaves because level = 3 >= 3

% Time for loop #4: 851 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #4, the best clause found is:
%      advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(C, A, _), ta(C, D, _), publication(_, D).  [covers 3,0/12,0 pos, 0,0/0,0 neg]
% This clause covers 3 positive examples, of which 3 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- student(A), professor(B).  [covers 20,0/8,0 pos, 0,0/0,0 neg]'
%     Score = -3,961007 (regressionFit = 3,961005, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- student(A), professor(B).  [covers 8,0/8,0 pos, 0,0/0,0 neg]

% Have these 8 positive seeds: 0 1 2 3 4 5 6 7
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% Consider expanding [#1 of outerLoop #5, bodyLen=2] 'advisedby(A, B) :- student(A), professor(B).  [covers 8,0/8,0 pos, 0,0/0,0 neg]' score=-3.961006693581129
%  At # nodes expanded = 1, |OPEN| = 0.  Pruned 16 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 28 bad extensions.
%     Score = -1,298752 (regressionFit = 1,298749, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
% Gleaner: New best node found (score = -1,298752): advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _).  [covers 2,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _).  [covers 6,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,203049 (regressionFit = 1,203045, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
% Gleaner: New best node found (score = -1,203049): advisedby(A, B) :- student(A), professor(B), publication(_, B).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,152546 (regressionFit = 1,152543, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
% Gleaner: New best node found (score = -1,152546): advisedby(A, B) :- student(A), professor(B), projectmember(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.0200000000000007E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.0200000000000007E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(B, B).  [covers 8,0/8,0 pos, 0,0/0,0 neg]

% Consider expanding [#2 of outerLoop #5, bodyLen=3] 'advisedby(A, B) :- student(A), professor(B), projectmember(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]' score=-1.1525460659443576
%  At # nodes expanded = 2, |OPEN| = 8.  Pruned 20 variant children.  Sending 10 items to OPEN for evaluation and possible insertion.
% Have created 10 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -1,152547 (regressionFit = 1,152543, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B), tempadvisedby(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B), ta(_, A, _).  [covers 1,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,152547 (regressionFit = 1,152543, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B), hasposition(B, _).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B), publication(_, B).  [covers 1,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,152547 (regressionFit = 1,152543, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B), inphase(A, _).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,152547 (regressionFit = 1,152543, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B), yearsinprogram(A, _).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,152547 (regressionFit = 1,152543, penalties=4.140000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B), projectmember(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,152547 (regressionFit = 1,152543, penalties=4.03E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(C, B), sameproject(C, C).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,152547 (regressionFit = 1,152543, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B), sameperson(A, A).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,152547 (regressionFit = 1,152543, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B), sameperson(B, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]

% Consider expanding [#3 of outerLoop #5, bodyLen=3] 'advisedby(A, B) :- student(A), professor(B), publication(_, B).  [covers 3,0/8,0 pos, 0,0/0,0 neg]' score=-1.2030486001321208
%  At # nodes expanded = 3, |OPEN| = 7.  Pruned 18 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 15 bad extensions.
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), tempadvisedby(_, B).  [covers 2,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,203050 (regressionFit = 1,203045, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), hasposition(B, _).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,203050 (regressionFit = 1,203045, penalties=4.040000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(C, B), publication(C, _).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,203050 (regressionFit = 1,203045, penalties=4.140000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), publication(_, B).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,203050 (regressionFit = 1,203045, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), inphase(A, _).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,203050 (regressionFit = 1,203045, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), yearsinprogram(A, _).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), projectmember(_, B).  [covers 1,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,203050 (regressionFit = 1,203045, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), sameperson(A, A).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,203050 (regressionFit = 1,203045, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), sameperson(B, B).  [covers 3,0/8,0 pos, 0,0/0,0 neg]

% Consider expanding [#4 of outerLoop #5, bodyLen=3] 'advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B).  [covers 5,0/8,0 pos, 0,0/0,0 neg]' score=-1.298752185038432
%  At # nodes expanded = 4, |OPEN| = 6.  Pruned 34 variant children.  Sending 13 items to OPEN for evaluation and possible insertion.
% Have created 13 valid-on-seeds descendants and have picked up 26 bad extensions.
%     Score = -1,298753 (regressionFit = 1,298749, penalties=3.9300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(C, B), student(C).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B), ta(_, A, _).  [covers 1,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,298753 (regressionFit = 1,298749, penalties=4.250000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(C, B), ta(_, C, _).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,298753 (regressionFit = 1,298749, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B), hasposition(B, _).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B), publication(_, B).  [covers 2,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,298753 (regressionFit = 1,298749, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B), inphase(A, _).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,298753 (regressionFit = 1,298749, penalties=4.14E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(C, B), inphase(C, _).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,298753 (regressionFit = 1,298749, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B), yearsinprogram(A, _).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,298753 (regressionFit = 1,298749, penalties=4.14E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(C, B), yearsinprogram(C, _).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,152547 (regressionFit = 1,152543, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B), projectmember(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,298753 (regressionFit = 1,298749, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B), sameperson(A, A).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,298753 (regressionFit = 1,298749, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B), sameperson(B, B).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,298753 (regressionFit = 1,298749, penalties=4.03E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(C, B), sameperson(C, C).  [covers 5,0/8,0 pos, 0,0/0,0 neg]

% Consider expanding [#5 of outerLoop #5, bodyLen=3] 'advisedby(A, B) :- student(A), professor(B), ta(_, A, _).  [covers 2,0/8,0 pos, 0,0/0,0 neg]' score=-Infinity

% Consider expanding [#6 of outerLoop #5, bodyLen=3] 'advisedby(A, B) :- student(A), professor(B), hasposition(B, _).  [covers 6,0/8,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 6, |OPEN| = 4.  Pruned 18 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -1,298753 (regressionFit = 1,298749, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _), tempadvisedby(_, B).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _), ta(_, A, _).  [covers 1,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.040000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, C), hasposition(_, C).  [covers 6,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,203050 (regressionFit = 1,203045, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _), publication(_, B).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _), inphase(A, _).  [covers 6,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _), yearsinprogram(A, _).  [covers 6,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,152547 (regressionFit = 1,152543, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _), projectmember(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _), sameperson(A, A).  [covers 6,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _), sameperson(B, B).  [covers 6,0/8,0 pos, 0,0/0,0 neg]

% Consider expanding [#7 of outerLoop #5, bodyLen=3] 'advisedby(A, B) :- student(A), professor(B), inphase(A, _).  [covers 8,0/8,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 7, |OPEN| = 3.  Pruned 18 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -1,298753 (regressionFit = 1,298749, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _), tempadvisedby(_, B).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _), ta(_, A, _).  [covers 2,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _), hasposition(B, _).  [covers 6,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,203050 (regressionFit = 1,203045, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _), publication(_, B).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.040000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, C), inphase(_, C).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _), yearsinprogram(A, _).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,152547 (regressionFit = 1,152543, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _), projectmember(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _), sameperson(A, A).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _), sameperson(B, B).  [covers 8,0/8,0 pos, 0,0/0,0 neg]

% Consider expanding [#8 of outerLoop #5, bodyLen=3] 'advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _).  [covers 8,0/8,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 8, |OPEN| = 2.  Pruned 18 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -1,298753 (regressionFit = 1,298749, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _), tempadvisedby(_, B).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _), ta(_, A, _).  [covers 2,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _), hasposition(B, _).  [covers 6,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,203050 (regressionFit = 1,203045, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _), publication(_, B).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _), inphase(A, _).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.040000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, C), yearsinprogram(_, C).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,152547 (regressionFit = 1,152543, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _), projectmember(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _), sameperson(A, A).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _), sameperson(B, B).  [covers 8,0/8,0 pos, 0,0/0,0 neg]

% Consider expanding [#9 of outerLoop #5, bodyLen=3] 'advisedby(A, B) :- student(A), professor(B), sameperson(A, A).  [covers 8,0/8,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 9, |OPEN| = 1.  Pruned 14 variant children.  Sending 8 items to OPEN for evaluation and possible insertion.
% Have created 8 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -1,298753 (regressionFit = 1,298749, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A), tempadvisedby(_, B).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A), ta(_, A, _).  [covers 2,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A), hasposition(B, _).  [covers 6,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,203050 (regressionFit = 1,203045, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A), publication(_, B).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A), inphase(A, _).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A), yearsinprogram(A, _).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,152547 (regressionFit = 1,152543, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A), projectmember(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.920000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A), sameperson(B, B).  [covers 8,0/8,0 pos, 0,0/0,0 neg]

***** Warning: #4 TOO MANY NODES CONSIDERED (i.e., 'expanded') for 'LearnOneClause': nodesConsidered = 10 and maxNodesToConsider = 10. *****


% The best node found: advisedby(A, B) :- student(A), professor(B), projectmember(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- student(A), professor(B), projectmember(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]

% Expanding node at Level 3 with score = -0,164.
% Will extend: advisedby(A, B) :- student(A), professor(B), projectmember(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
% Path: 3;true,false,false
Comparing variance: 0.10063573398608935 to score=0.0025 #egs=4.0
Comparing variance: 0.1875 to score=0.0025 #egs=4.0
%   Creating a TRUE-branch and FALSE-branch leaves because level = 3 >= 3

% Time for loop #5: 58 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #5, the best clause found is:
%      advisedby(A, B) :- student(A), professor(B), projectmember(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
% This clause covers 4 positive examples, of which 4 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% ******************************************

%  Have stopped ILP's outer loop because the tree-structured queue is empty.

% ******************************************

%%%%%  WILL-Produced Tree #4 @ 17:27:15 5/29/21.  [Using 4.341.048 memory cells.]  %%%%%


% FOR advisedby(A, B):
%   if ( student(A), professor(B) )
%   then if ( publication(C, A), publication(C, B) )
%   | then return 0.41751358415830997;  // std dev = 0,000, 4,000 (wgt'ed) examples reached here.  /* #pos=4 */
%   | else if ( publication(D, B), ta(E, A, F) )
%   | | then if ( ta(E, G, H), publication(I, G) )
%   | | | then return 0.6463136506525012;  // std dev = 0,095, 3,000 (wgt'ed) examples reached here.  /* #pos=3 */
%   | | | else return 0.22069924314265943;  // std dev = 1,395, 9,000 (wgt'ed) examples reached here.  /* #neg=4 #pos=5 */
%   | | else if ( projectmember(J, B) )
%   | | | then return 0.2720053963567208;  // std dev = 0,634, 4,000 (wgt'ed) examples reached here.  /* #neg=1 #pos=3 */
%   | | | else return -0.01364777084595721;  // std dev = 0,866, 4,000 (wgt'ed) examples reached here.  /* #neg=3 #pos=1 */
%   else return -0.10159632948783635;  // std dev = 0,000, 24,000 (wgt'ed) examples reached here.  /* #neg=24 */


% Clauses:

advisedby(A, B, 0.41751358415830997) :- 
     student(A), 
     professor(B), 
     publication(C, A), 
     publication(C, B), 
     !. // Clause #1.

advisedby(A, B, 0.6463136506525012) :- 
     student(A), 
     professor(B), 
     publication(C, B), 
     ta(D, A, E), 
     ta(D, F, G), 
     publication(H, F), 
     !. // Clause #2.

advisedby(A, B, 0.22069924314265943) :- 
     student(A), 
     professor(B), 
     publication(C, B), 
     ta(D, A, E), 
     !. // Clause #3.

advisedby(A, B, 0.2720053963567208) :- 
     student(A), 
     professor(B), 
     projectmember(C, B), 
     !. // Clause #4.

advisedby(A, B, -0.01364777084595721) :- 
     student(A), 
     professor(B), 
     !. // Clause #5.

advisedby(A, B, -0.10159632948783635) :- !. // Clause #6.


% The flattened versions of these clauses:

flattened_advisedby(a, b, 0.41751358415830997) :-  /* #pos=4 */ 
   student(a),
   professor(b),
   publication(uniqueVar6, a),
   publication(uniqueVar6, b),
   !. // Flattened version of clause #1.

flattened_advisedby(a, b, 0.6463136506525012) :-  /* #pos=3 */ 
   student(a),
   professor(b),
   publication(underscore, b),
   ta(uniqueVar7, a, underscore),
   ta(uniqueVar7, uniqueVar8, underscore),
   publication(underscore, uniqueVar8),
   !. // Flattened version of clause #2.

flattened_advisedby(a, b, 0.22069924314265943) :-  /* #neg=4 #pos=5 */ 
   student(a),
   professor(b),
   publication(underscore, b),
   ta(underscore, a, underscore),
   !. // Flattened version of clause #3.

flattened_advisedby(a, b, 0.2720053963567208) :-  /* #neg=1 #pos=3 */ 
   student(a),
   professor(b),
   projectmember(underscore, b),
   !. // Flattened version of clause #4.

flattened_advisedby(a, b, -0.01364777084595721) :-  /* #neg=3 #pos=1 */ 
   student(a),
   professor(b),
   !. // Flattened version of clause #5.

flattened_advisedby(underscore, underscore, -0.10159632948783635) :-  /* #neg=24 */ 
   !. // Flattened version of clause #6.


% The unique flattened literals:
%   ta(underscore, a, underscore)
%   publication(underscore, b)
%   professor(b)
%   projectmember(underscore, b)
%   publication(uniqueVar6, b)
%   publication(underscore, uniqueVar8)
%   ta(uniqueVar7, uniqueVar8, underscore)
%   ta(uniqueVar7, a, underscore)
%   student(a)
%   publication(uniqueVar6, a)

% Saving model in: train/models/bRDNs/advisedby.model.ckpt
% Time taken to learn 4 trees is 1,572 seconds.

%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.1644672999762749
Set score:0.0025
% Only 48 out of 48 converged.
% Kept 16 of the 16 positive examples.
% Kept 32 of the 32 negative examples.
% Dataset size: 48
Computing probabilities
prob time:7 milliseconds
No hidden examples for : advisedby
Time to build dataset: 7 milliseconds
%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.09786737243712815
Set score:0.0025
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% Have these 4 positive seeds: 12 15 17 39

% The best node found: null

% target           = advisedby(D, E)
%     Score = -Infinity (regressionFit = Infinity, penalties=2.2E-7) for clause:  advisedby(_, _).  [covers 48,0/48,0 pos, 0,0/0,0 neg]
%     Score = -3,584201 (regressionFit = 3,584200, penalties=1.12E-6) for clause:  advisedby(_, A) :- professor(A).  [covers 24,0/48,0 pos, 0,0/0,0 neg]
%     Score = -3,584202 (regressionFit = 3,584200, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- professor(B), student(A).  [covers 24,0/48,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- professor(B), student(A).  [covers 24,0/48,0 pos, 0,0/0,0 neg]

% Expanding node at Level 0 with score = 1,797693e+308.
% Will extend: advisedby(A, B) :- professor(B), student(A).  [covers 24,0/48,0 pos, 0,0/0,0 neg]
% Path: 4;
Comparing variance: 0.1493416765091333 to score=0.0025 #egs=24.0
Comparing variance: 4.625929269271485E-18 to score=0.0025 #egs=24.0
%   Creating a TRUE-branch interior node with wgtedCountTrueBranchPos = 24,0
%      addToQueueOfTreeStructuredLearningTasks (level=1; score=-0,149342)
%         ILP node to extend: advisedby(A, B) :- professor(B), student(A).  [covers 24,0/48,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 1 and with score = -0,149342) into the LAST position (#1) in the search queue.
%   Creating a FALSE-branch leaf because good enough fit since score < 0.0025

% Time for loop #1: 2 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #1, the best clause found is:
%      advisedby(A, B) :- professor(B), student(A).  [covers 24,0/48,0 pos, 0,0/0,0 neg]
% This clause covers 24 positive examples, of which 24 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- professor(B), student(A).  [covers 24,0/24,0 pos, 0,0/0,0 neg]'
%     Score = -3,584202 (regressionFit = 3,584200, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- professor(B), student(A).  [covers 24,0/24,0 pos, 0,0/0,0 neg]

% Have these 6 positive seeds: 2 4 8 13 16 21

% The best node found: null
%     Score = -3,527389 (regressionFit = 3,527386, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, A).  [covers 4,0/24,0 pos, 0,0/0,0 neg]
%     Score = -3,527390 (regressionFit = 3,527386, penalties=3.9300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(C, A), publication(C, B).  [covers 4,0/24,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- professor(B), student(A), publication(C, A), publication(C, B).  [covers 4,0/24,0 pos, 0,0/0,0 neg]

% Expanding node at Level 1 with score = -0,149.
% Will extend: advisedby(A, B) :- professor(B), student(A), publication(C, A), publication(C, B).  [covers 4,0/24,0 pos, 0,0/0,0 neg]
% Path: 4;true
Comparing variance: 0.0 to score=0.0025 #egs=4.0
Comparing variance: 0.1763692897182251 to score=0.0025 #egs=20.0
%   Creating a TRUE-branch leaf because wgtedCountTrueBranchPos = 4,0 < 2.1 * minPosCov = 6,3
%   Creating a FALSE-branch interior node with wgtedCountFalseBranchPos = 20,0
%      addToQueueOfTreeStructuredLearningTasks (level=2; score=-0,176369)
%         ILP node to extend: advisedby(A, B) :- professor(B), student(A).  [covers 24,0/24,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 2 and with score = -0,176369) into the LAST position (#1) in the search queue.

% Time for loop #2: 3 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #2, the best clause found is:
%      advisedby(A, B) :- professor(B), student(A), publication(C, A), publication(C, B).  [covers 4,0/24,0 pos, 0,0/0,0 neg]
% This clause covers 4 positive examples, of which 4 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- professor(B), student(A).  [covers 24,0/20,0 pos, 0,0/0,0 neg]'
%     Score = -3,584202 (regressionFit = 3,584200, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- professor(B), student(A).  [covers 20,0/20,0 pos, 0,0/0,0 neg]

% Have these 8 positive seeds: 0 3 4 5 6 8 10 11

% The best node found: null
%     Score = -3,513354 (regressionFit = 3,513350, penalties=3.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,415256 (regressionFit = 3,415252, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B).  [covers 12,0/20,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B).  [covers 12,0/20,0 pos, 0,0/0,0 neg]

% Expanding node at Level 2 with score = -0,176.
% Will extend: advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B).  [covers 12,0/20,0 pos, 0,0/0,0 neg]
% Path: 4;true,false
Comparing variance: 0.1813521508083568 to score=0.0025 #egs=12.0
Comparing variance: 0.1548782636993961 to score=0.0025 #egs=8.0
%   Creating a TRUE-branch interior node with wgtedCountTrueBranchPos = 12,0
%      addToQueueOfTreeStructuredLearningTasks (level=3; score=-0,181352)
%         ILP node to extend: advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B).  [covers 12,0/20,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 3 and with score = -0,181352) into the LAST position (#1) in the search queue.
%   Creating a FALSE-branch interior node with wgtedCountFalseBranchPos = 8,0
%      addToQueueOfTreeStructuredLearningTasks (level=3; score=-0,154878)
%         ILP node to extend: advisedby(A, B) :- professor(B), student(A).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 3 and with score = -0,154878) into the LAST position (#2) in the search queue.

% Time for loop #3: 3 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #3, the best clause found is:
%      advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B).  [covers 12,0/20,0 pos, 0,0/0,0 neg]
% This clause covers 12 positive examples, of which 12 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B).  [covers 12,0/12,0 pos, 0,0/0,0 neg]'
%     Score = -3,415256 (regressionFit = 3,415252, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B).  [covers 12,0/12,0 pos, 0,0/0,0 neg]

% Have these 6 positive seeds: 0 2 5 9 10 11

% The best node found: null
%     Score = -Infinity (regressionFit = Infinity, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), ta(_, _, C).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -1,840757 (regressionFit = 1,840751, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), ta(_, D, C), publication(_, D).  [covers 4,0/12,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), ta(_, D, C), publication(_, D).  [covers 4,0/12,0 pos, 0,0/0,0 neg]

% Expanding node at Level 3 with score = -0,181.
% Will extend: advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), ta(_, D, C), publication(_, D).  [covers 4,0/12,0 pos, 0,0/0,0 neg]
% Path: 4;true,false,true
Comparing variance: 0.0020815987166928063 to score=0.0025 #egs=4.0
Comparing variance: 0.22905301825878752 to score=0.0025 #egs=8.0
%   Creating a TRUE-branch and FALSE-branch leaves because level = 3 >= 3

% Time for loop #4: 6 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #4, the best clause found is:
%      advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), ta(_, D, C), publication(_, D).  [covers 4,0/12,0 pos, 0,0/0,0 neg]
% This clause covers 4 positive examples, of which 4 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- professor(B), student(A).  [covers 20,0/8,0 pos, 0,0/0,0 neg]'
%     Score = -3,584202 (regressionFit = 3,584200, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- professor(B), student(A).  [covers 8,0/8,0 pos, 0,0/0,0 neg]

% Have these 8 positive seeds: 0 1 2 3 4 5 6 7
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% Consider expanding [#1 of outerLoop #5, bodyLen=2] 'advisedby(A, B) :- professor(B), student(A).  [covers 8,0/8,0 pos, 0,0/0,0 neg]' score=-3.5842022562191995
%  At # nodes expanded = 1, |OPEN| = 0.  Pruned 16 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -1,235753 (regressionFit = 1,235750, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
% Gleaner: New best node found (score = -1,235753): advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _).  [covers 2,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _).  [covers 6,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,141126 (regressionFit = 1,141123, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
% Gleaner: New best node found (score = -1,141126): advisedby(A, B) :- professor(B), student(A), publication(_, B).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,143180 (regressionFit = 1,143177, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.0200000000000007E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.0200000000000007E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(B, B).  [covers 8,0/8,0 pos, 0,0/0,0 neg]

% Consider expanding [#2 of outerLoop #5, bodyLen=3] 'advisedby(A, B) :- professor(B), student(A), publication(_, B).  [covers 3,0/8,0 pos, 0,0/0,0 neg]' score=-1.1411264425944272
%  At # nodes expanded = 2, |OPEN| = 8.  Pruned 18 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 15 bad extensions.
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B), tempadvisedby(_, B).  [covers 2,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,141128 (regressionFit = 1,141123, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B), hasposition(B, _).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,141127 (regressionFit = 1,141123, penalties=4.040000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(C, B), publication(C, _).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,141127 (regressionFit = 1,141123, penalties=4.140000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B), publication(_, B).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,141128 (regressionFit = 1,141123, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B), inphase(A, _).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,141128 (regressionFit = 1,141123, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B), yearsinprogram(A, _).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B), projectmember(_, B).  [covers 1,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,141127 (regressionFit = 1,141123, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B), sameperson(A, A).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,141127 (regressionFit = 1,141123, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B), sameperson(B, B).  [covers 3,0/8,0 pos, 0,0/0,0 neg]

% Consider expanding [#3 of outerLoop #5, bodyLen=3] 'advisedby(A, B) :- professor(B), student(A), projectmember(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]' score=-1.143180085305517
%  At # nodes expanded = 3, |OPEN| = 7.  Pruned 20 variant children.  Sending 10 items to OPEN for evaluation and possible insertion.
% Have created 10 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -1,143181 (regressionFit = 1,143177, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), tempadvisedby(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), ta(_, A, _).  [covers 1,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,143181 (regressionFit = 1,143177, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), hasposition(B, _).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), publication(_, B).  [covers 1,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,143181 (regressionFit = 1,143177, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), inphase(A, _).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,143181 (regressionFit = 1,143177, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), yearsinprogram(A, _).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,143181 (regressionFit = 1,143177, penalties=4.140000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), projectmember(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,143181 (regressionFit = 1,143177, penalties=4.03E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(C, B), sameproject(C, C).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,143181 (regressionFit = 1,143177, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), sameperson(A, A).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,143181 (regressionFit = 1,143177, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), sameperson(B, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]

% Consider expanding [#4 of outerLoop #5, bodyLen=3] 'advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B).  [covers 5,0/8,0 pos, 0,0/0,0 neg]' score=-1.2357531444890295
%  At # nodes expanded = 4, |OPEN| = 6.  Pruned 34 variant children.  Sending 13 items to OPEN for evaluation and possible insertion.
% Have created 13 valid-on-seeds descendants and have picked up 26 bad extensions.
%     Score = -1,235754 (regressionFit = 1,235750, penalties=3.9300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(C, B), student(C).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B), ta(_, A, _).  [covers 1,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,235754 (regressionFit = 1,235750, penalties=4.250000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(C, B), ta(_, C, _).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,235754 (regressionFit = 1,235750, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B), hasposition(B, _).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B), publication(_, B).  [covers 2,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,235754 (regressionFit = 1,235750, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B), inphase(A, _).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,235754 (regressionFit = 1,235750, penalties=4.14E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(C, B), inphase(C, _).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,235754 (regressionFit = 1,235750, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B), yearsinprogram(A, _).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,235754 (regressionFit = 1,235750, penalties=4.14E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(C, B), yearsinprogram(C, _).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,143181 (regressionFit = 1,143177, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B), projectmember(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,235754 (regressionFit = 1,235750, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B), sameperson(A, A).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,235754 (regressionFit = 1,235750, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B), sameperson(B, B).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,235754 (regressionFit = 1,235750, penalties=4.03E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(C, B), sameperson(C, C).  [covers 5,0/8,0 pos, 0,0/0,0 neg]

% Consider expanding [#5 of outerLoop #5, bodyLen=3] 'advisedby(A, B) :- professor(B), student(A), ta(_, A, _).  [covers 2,0/8,0 pos, 0,0/0,0 neg]' score=-Infinity

% Consider expanding [#6 of outerLoop #5, bodyLen=3] 'advisedby(A, B) :- professor(B), student(A), hasposition(B, _).  [covers 6,0/8,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 6, |OPEN| = 4.  Pruned 18 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -1,235754 (regressionFit = 1,235750, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _), tempadvisedby(_, B).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _), ta(_, A, _).  [covers 1,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.040000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, C), hasposition(_, C).  [covers 6,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,141128 (regressionFit = 1,141123, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _), publication(_, B).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _), inphase(A, _).  [covers 6,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _), yearsinprogram(A, _).  [covers 6,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,143181 (regressionFit = 1,143177, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _), projectmember(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _), sameperson(A, A).  [covers 6,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _), sameperson(B, B).  [covers 6,0/8,0 pos, 0,0/0,0 neg]

% Consider expanding [#7 of outerLoop #5, bodyLen=3] 'advisedby(A, B) :- professor(B), student(A), inphase(A, _).  [covers 8,0/8,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 7, |OPEN| = 3.  Pruned 18 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -1,235754 (regressionFit = 1,235750, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _), tempadvisedby(_, B).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _), ta(_, A, _).  [covers 2,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _), hasposition(B, _).  [covers 6,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,141128 (regressionFit = 1,141123, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _), publication(_, B).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.040000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, C), inphase(_, C).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _), yearsinprogram(A, _).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,143181 (regressionFit = 1,143177, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _), projectmember(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _), sameperson(A, A).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _), sameperson(B, B).  [covers 8,0/8,0 pos, 0,0/0,0 neg]

% Consider expanding [#8 of outerLoop #5, bodyLen=3] 'advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _).  [covers 8,0/8,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 8, |OPEN| = 2.  Pruned 18 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -1,235754 (regressionFit = 1,235750, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _), tempadvisedby(_, B).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _), ta(_, A, _).  [covers 2,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _), hasposition(B, _).  [covers 6,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,141128 (regressionFit = 1,141123, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _), publication(_, B).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _), inphase(A, _).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.040000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, C), yearsinprogram(_, C).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,143181 (regressionFit = 1,143177, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _), projectmember(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _), sameperson(A, A).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _), sameperson(B, B).  [covers 8,0/8,0 pos, 0,0/0,0 neg]

% Consider expanding [#9 of outerLoop #5, bodyLen=3] 'advisedby(A, B) :- professor(B), student(A), sameperson(A, A).  [covers 8,0/8,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 9, |OPEN| = 1.  Pruned 14 variant children.  Sending 8 items to OPEN for evaluation and possible insertion.
% Have created 8 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -1,235754 (regressionFit = 1,235750, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A), tempadvisedby(_, B).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A), ta(_, A, _).  [covers 2,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A), hasposition(B, _).  [covers 6,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,141127 (regressionFit = 1,141123, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A), publication(_, B).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A), inphase(A, _).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A), yearsinprogram(A, _).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,143181 (regressionFit = 1,143177, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A), projectmember(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.920000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A), sameperson(B, B).  [covers 8,0/8,0 pos, 0,0/0,0 neg]

***** Warning: #5 TOO MANY NODES CONSIDERED (i.e., 'expanded') for 'LearnOneClause': nodesConsidered = 10 and maxNodesToConsider = 10. *****


% The best node found: advisedby(A, B) :- professor(B), student(A), publication(_, B).  [covers 3,0/8,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- professor(B), student(A), publication(_, B).  [covers 3,0/8,0 pos, 0,0/0,0 neg]

% Expanding node at Level 3 with score = -0,155.
% Will extend: advisedby(A, B) :- professor(B), student(A), publication(_, B).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
% Path: 4;true,false,false
Comparing variance: 0.09386785188831713 to score=0.0025 #egs=3.0
Comparing variance: 0.17190395138589515 to score=0.0025 #egs=5.0
%   Creating a TRUE-branch and FALSE-branch leaves because level = 3 >= 3

% Time for loop #5: 61 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #5, the best clause found is:
%      advisedby(A, B) :- professor(B), student(A), publication(_, B).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
% This clause covers 3 positive examples, of which 3 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% ******************************************

%  Have stopped ILP's outer loop because the tree-structured queue is empty.

% ******************************************

%%%%%  WILL-Produced Tree #5 @ 17:27:15 5/29/21.  [Using 4.352.528 memory cells.]  %%%%%


% FOR advisedby(A, B):
%   if ( professor(B), student(A) )
%   then if ( publication(C, A), publication(C, B) )
%   | then return 0.32071184716014967;  // std dev = 0,000, 4,000 (wgt'ed) examples reached here.  /* #pos=4 */
%   | else if ( ta(D, A, E), publication(F, B) )
%   | | then if ( ta(G, H, E), publication(I, H) )
%   | | | then return 0.4877537542089029;  // std dev = 0,091, 4,000 (wgt'ed) examples reached here.  /* #pos=4 */
%   | | | else return 0.13306624979663273;  // std dev = 1,354, 8,000 (wgt'ed) examples reached here.  /* #neg=4 #pos=4 */
%   | | else if ( publication(J, B) )
%   | | | then return -0.044364393170209605;  // std dev = 0,531, 3,000 (wgt'ed) examples reached here.  /* #neg=2 #pos=1 */
%   | | | else return 0.18414124148036587;  // std dev = 0,927, 5,000 (wgt'ed) examples reached here.  /* #neg=2 #pos=3 */
%   else return -0.09269127618926094;  // std dev = 1,05e-08, 24,000 (wgt'ed) examples reached here.  /* #neg=24 */


% Clauses:

advisedby(A, B, 0.32071184716014967) :- 
     professor(B), 
     student(A), 
     publication(C, A), 
     publication(C, B), 
     !. // Clause #1.

advisedby(A, B, 0.4877537542089029) :- 
     professor(B), 
     student(A), 
     ta(C, A, D), 
     publication(E, B), 
     ta(F, G, D), 
     publication(H, G), 
     !. // Clause #2.

advisedby(A, B, 0.13306624979663273) :- 
     professor(B), 
     student(A), 
     ta(C, A, D), 
     publication(E, B), 
     !. // Clause #3.

advisedby(A, B, -0.044364393170209605) :- 
     professor(B), 
     student(A), 
     publication(C, B), 
     !. // Clause #4.

advisedby(A, B, 0.18414124148036587) :- 
     professor(B), 
     student(A), 
     !. // Clause #5.

advisedby(A, B, -0.09269127618926094) :- !. // Clause #6.


% The flattened versions of these clauses:

flattened_advisedby(a, b, 0.32071184716014967) :-  /* #pos=4 */ 
   professor(b),
   student(a),
   publication(uniqueVar9, a),
   publication(uniqueVar9, b),
   !. // Flattened version of clause #1.

flattened_advisedby(a, b, 0.4877537542089029) :-  /* #pos=4 */ 
   professor(b),
   student(a),
   ta(underscore, a, uniqueVar10),
   publication(underscore, b),
   ta(underscore, uniqueVar11, uniqueVar10),
   publication(underscore, uniqueVar11),
   !. // Flattened version of clause #2.

flattened_advisedby(a, b, 0.13306624979663273) :-  /* #neg=4 #pos=4 */ 
   professor(b),
   student(a),
   ta(underscore, a, underscore),
   publication(underscore, b),
   !. // Flattened version of clause #3.

flattened_advisedby(a, b, -0.044364393170209605) :-  /* #neg=2 #pos=1 */ 
   professor(b),
   student(a),
   publication(underscore, b),
   !. // Flattened version of clause #4.

flattened_advisedby(a, b, 0.18414124148036587) :-  /* #neg=2 #pos=3 */ 
   professor(b),
   student(a),
   !. // Flattened version of clause #5.

flattened_advisedby(underscore, underscore, -0.09269127618926094) :-  /* #neg=24 */ 
   !. // Flattened version of clause #6.


% The unique flattened literals:
%   ta(underscore, a, underscore)
%   publication(underscore, b)
%   publication(underscore, uniqueVar11)
%   professor(b)
%   publication(uniqueVar9, b)
%   ta(underscore, uniqueVar11, uniqueVar10)
%   ta(underscore, a, uniqueVar10)
%   student(a)
%   publication(uniqueVar9, a)

% Saving model in: train/models/bRDNs/advisedby.model.ckpt
% Time taken to learn 5 trees is 1,728 seconds.

%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.1548782636993961
Set score:0.0025
% Only 48 out of 48 converged.
% Kept 16 of the 16 positive examples.
% Kept 32 of the 32 negative examples.
% Dataset size: 48
Computing probabilities
prob time:19 milliseconds
No hidden examples for : advisedby
Time to build dataset: 19 milliseconds
%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.08499936937839891
Set score:0.0025
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% Have these 7 positive seeds: 1 2 32 42 43 46 47

% The best node found: null

% target           = advisedby(D, E)
%     Score = -Infinity (regressionFit = Infinity, penalties=2.2E-7) for clause:  advisedby(_, _).  [covers 48,0/48,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=1.12E-6) for clause:  advisedby(A, _) :- student(A).  [covers 48,0/48,0 pos, 0,0/0,0 neg]
%     Score = -3,335874 (regressionFit = 3,335872, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- student(A), professor(B).  [covers 24,0/48,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- student(A), professor(B).  [covers 24,0/48,0 pos, 0,0/0,0 neg]

% Expanding node at Level 0 with score = 1,797693e+308.
% Will extend: advisedby(A, B) :- student(A), professor(B).  [covers 24,0/48,0 pos, 0,0/0,0 neg]
% Path: 5;
Comparing variance: 0.13899467762703557 to score=0.0025 #egs=24.0
Comparing variance: 1.1564823173178714E-17 to score=0.0025 #egs=24.0
%   Creating a TRUE-branch interior node with wgtedCountTrueBranchPos = 24,0
%      addToQueueOfTreeStructuredLearningTasks (level=1; score=-0,138995)
%         ILP node to extend: advisedby(A, B) :- student(A), professor(B).  [covers 24,0/48,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 1 and with score = -0,138995) into the LAST position (#1) in the search queue.
%   Creating a FALSE-branch leaf because good enough fit since score < 0.0025

% Time for loop #1: 3 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #1, the best clause found is:
%      advisedby(A, B) :- student(A), professor(B).  [covers 24,0/48,0 pos, 0,0/0,0 neg]
% This clause covers 24 positive examples, of which 24 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- student(A), professor(B).  [covers 24,0/24,0 pos, 0,0/0,0 neg]'
%     Score = -3,335874 (regressionFit = 3,335872, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- student(A), professor(B).  [covers 24,0/24,0 pos, 0,0/0,0 neg]

% Have these 8 positive seeds: 5 6 8 12 13 15 16 17

% The best node found: null
%     Score = -3,295827 (regressionFit = 3,295824, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, A).  [covers 4,0/24,0 pos, 0,0/0,0 neg]
%     Score = -3,295827 (regressionFit = 3,295824, penalties=3.9300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(C, A), publication(C, B).  [covers 4,0/24,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- student(A), professor(B), publication(C, A), publication(C, B).  [covers 4,0/24,0 pos, 0,0/0,0 neg]

% Expanding node at Level 1 with score = -0,139.
% Will extend: advisedby(A, B) :- student(A), professor(B), publication(C, A), publication(C, B).  [covers 4,0/24,0 pos, 0,0/0,0 neg]
% Path: 5;true
Comparing variance: 0.0 to score=0.0025 #egs=4.0
Comparing variance: 0.16479117615263317 to score=0.0025 #egs=20.0
%   Creating a TRUE-branch leaf because wgtedCountTrueBranchPos = 4,0 < 2.1 * minPosCov = 6,3
%   Creating a FALSE-branch interior node with wgtedCountFalseBranchPos = 20,0
%      addToQueueOfTreeStructuredLearningTasks (level=2; score=-0,164791)
%         ILP node to extend: advisedby(A, B) :- student(A), professor(B).  [covers 24,0/24,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 2 and with score = -0,164791) into the LAST position (#1) in the search queue.

% Time for loop #2: 3 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #2, the best clause found is:
%      advisedby(A, B) :- student(A), professor(B), publication(C, A), publication(C, B).  [covers 4,0/24,0 pos, 0,0/0,0 neg]
% This clause covers 4 positive examples, of which 4 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- student(A), professor(B).  [covers 24,0/20,0 pos, 0,0/0,0 neg]'
%     Score = -3,335874 (regressionFit = 3,335872, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- student(A), professor(B).  [covers 20,0/20,0 pos, 0,0/0,0 neg]

% Have these 6 positive seeds: 1 4 7 8 10 19

% The best node found: null
%     Score = -3,254757 (regressionFit = 3,254754, penalties=3.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,229438 (regressionFit = 3,229433, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), projectmember(_, B).  [covers 3,0/20,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- student(A), professor(B), ta(_, A, _), projectmember(_, B).  [covers 3,0/20,0 pos, 0,0/0,0 neg]

% Expanding node at Level 2 with score = -0,165.
% Will extend: advisedby(A, B) :- student(A), professor(B), ta(_, A, _), projectmember(_, B).  [covers 3,0/20,0 pos, 0,0/0,0 neg]
% Path: 5;true,false
Comparing variance: 0.24105722663822507 to score=0.0025 #egs=3.0
Comparing variance: 0.14742714932824277 to score=0.0025 #egs=17.0
%   Creating a TRUE-branch leaf because wgtedCountTrueBranchPos = 3,0 < 2.1 * minPosCov = 6,3
%   Creating a FALSE-branch interior node with wgtedCountFalseBranchPos = 17,0
%      addToQueueOfTreeStructuredLearningTasks (level=3; score=-0,147427)
%         ILP node to extend: advisedby(A, B) :- student(A), professor(B).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 3 and with score = -0,147427) into the LAST position (#1) in the search queue.

% Time for loop #3: 3 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #3, the best clause found is:
%      advisedby(A, B) :- student(A), professor(B), ta(_, A, _), projectmember(_, B).  [covers 3,0/20,0 pos, 0,0/0,0 neg]
% This clause covers 3 positive examples, of which 3 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- student(A), professor(B).  [covers 20,0/17,0 pos, 0,0/0,0 neg]'
%     Score = -3,335874 (regressionFit = 3,335872, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- student(A), professor(B).  [covers 17,0/17,0 pos, 0,0/0,0 neg]

% Have these 8 positive seeds: 2 3 5 6 7 8 9 11

% The best node found: null
%     Score = -2,368914 (regressionFit = 2,368910, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B).  [covers 3,0/17,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- student(A), professor(B), projectmember(_, B).  [covers 3,0/17,0 pos, 0,0/0,0 neg]

% Expanding node at Level 3 with score = -0,147.
% Will extend: advisedby(A, B) :- student(A), professor(B), projectmember(_, B).  [covers 3,0/17,0 pos, 0,0/0,0 neg]
% Path: 5;true,false,false
Comparing variance: 6.327750738437573E-4 to score=0.0025 #egs=3.0
Comparing variance: 0.16907229540336702 to score=0.0025 #egs=14.0
%   Creating a TRUE-branch and FALSE-branch leaves because level = 3 >= 3

% Time for loop #4: 1 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #4, the best clause found is:
%      advisedby(A, B) :- student(A), professor(B), projectmember(_, B).  [covers 3,0/17,0 pos, 0,0/0,0 neg]
% This clause covers 3 positive examples, of which 3 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% ******************************************

%  Have stopped ILP's outer loop because the tree-structured queue is empty.

% ******************************************

%%%%%  WILL-Produced Tree #6 @ 17:27:15 5/29/21.  [Using 4.363.696 memory cells.]  %%%%%


% FOR advisedby(A, B):
%   if ( student(A), professor(B) )
%   then if ( publication(C, A), publication(C, B) )
%   | then return 0.25517224256948945;  // std dev = 0,000, 4,000 (wgt'ed) examples reached here.  /* #pos=4 */
%   | else if ( ta(D, A, E), projectmember(F, B) )
%   | | then return 0.0084093205906934;  // std dev = 0,850, 3,000 (wgt'ed) examples reached here.  /* #neg=2 #pos=1 */
%   | | else if ( projectmember(G, B) )
%   | | | then return 0.3639399894242132;  // std dev = 0,044, 3,000 (wgt'ed) examples reached here.  /* #pos=3 */
%   | | | else return 0.12815516413727995;  // std dev = 1,539, 14,000 (wgt'ed) examples reached here.  /* #neg=6 #pos=8 */
%   else return -0.08518475138839682;  // std dev = 1,67e-08, 24,000 (wgt'ed) examples reached here.  /* #neg=24 */


% Clauses:

advisedby(A, B, 0.25517224256948945) :- 
     student(A), 
     professor(B), 
     publication(C, A), 
     publication(C, B), 
     !. // Clause #1.

advisedby(A, B, 0.0084093205906934) :- 
     student(A), 
     professor(B), 
     ta(C, A, D), 
     projectmember(E, B), 
     !. // Clause #2.

advisedby(A, B, 0.3639399894242132) :- 
     student(A), 
     professor(B), 
     projectmember(C, B), 
     !. // Clause #3.

advisedby(A, B, 0.12815516413727995) :- 
     student(A), 
     professor(B), 
     !. // Clause #4.

advisedby(A, B, -0.08518475138839682) :- !. // Clause #5.


% The flattened versions of these clauses:

flattened_advisedby(a, b, 0.25517224256948945) :-  /* #pos=4 */ 
   student(a),
   professor(b),
   publication(uniqueVar12, a),
   publication(uniqueVar12, b),
   !. // Flattened version of clause #1.

flattened_advisedby(a, b, 0.0084093205906934) :-  /* #neg=2 #pos=1 */ 
   student(a),
   professor(b),
   ta(underscore, a, underscore),
   projectmember(underscore, b),
   !. // Flattened version of clause #2.

flattened_advisedby(a, b, 0.3639399894242132) :-  /* #pos=3 */ 
   student(a),
   professor(b),
   projectmember(underscore, b),
   !. // Flattened version of clause #3.

flattened_advisedby(a, b, 0.12815516413727995) :-  /* #neg=6 #pos=8 */ 
   student(a),
   professor(b),
   !. // Flattened version of clause #4.

flattened_advisedby(underscore, underscore, -0.08518475138839682) :-  /* #neg=24 */ 
   !. // Flattened version of clause #5.


% The unique flattened literals:
%   publication(uniqueVar12, a)
%   publication(uniqueVar12, b)
%   ta(underscore, a, underscore)
%   student(a)
%   professor(b)
%   projectmember(underscore, b)

% Saving model in: train/models/bRDNs/advisedby.model.ckpt
% Time taken to learn 6 trees is 1,830 seconds.

%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.14742714932824275
Set score:0.0025
% Only 48 out of 48 converged.
% Kept 16 of the 16 positive examples.
% Kept 32 of the 32 negative examples.
% Dataset size: 48
Computing probabilities
prob time:10 milliseconds
No hidden examples for : advisedby
Time to build dataset: 11 milliseconds
%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.07833672810185444
Set score:0.0025
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% Have these 8 positive seeds: 1 3 15 22 23 28 31 32

% The best node found: null

% target           = advisedby(D, E)
%     Score = -Infinity (regressionFit = Infinity, penalties=2.2E-7) for clause:  advisedby(_, _).  [covers 48,0/48,0 pos, 0,0/0,0 neg]
%     Score = -3,241786 (regressionFit = 3,241785, penalties=1.12E-6) for clause:  advisedby(_, A) :- professor(A).  [covers 24,0/48,0 pos, 0,0/0,0 neg]
%     Score = -3,241787 (regressionFit = 3,241785, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- professor(B), student(A).  [covers 24,0/48,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- professor(B), student(A).  [covers 24,0/48,0 pos, 0,0/0,0 neg]

% Expanding node at Level 0 with score = 1,797693e+308.
% Will extend: advisedby(A, B) :- professor(B), student(A).  [covers 24,0/48,0 pos, 0,0/0,0 neg]
% Path: 6;
Comparing variance: 0.1350743752711312 to score=0.0025 #egs=24.0
Comparing variance: -4.625929269271485E-18 to score=0.0025 #egs=24.0
%   Creating a TRUE-branch interior node with wgtedCountTrueBranchPos = 24,0
%      addToQueueOfTreeStructuredLearningTasks (level=1; score=-0,135074)
%         ILP node to extend: advisedby(A, B) :- professor(B), student(A).  [covers 24,0/48,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 1 and with score = -0,135074) into the LAST position (#1) in the search queue.
%   Creating a FALSE-branch leaf because good enough fit since score < 0.0025

% Time for loop #1: 4 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #1, the best clause found is:
%      advisedby(A, B) :- professor(B), student(A).  [covers 24,0/48,0 pos, 0,0/0,0 neg]
% This clause covers 24 positive examples, of which 24 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- professor(B), student(A).  [covers 24,0/24,0 pos, 0,0/0,0 neg]'
%     Score = -3,241787 (regressionFit = 3,241785, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- professor(B), student(A).  [covers 24,0/24,0 pos, 0,0/0,0 neg]

% Have these 6 positive seeds: 11 15 16 17 18 20

% The best node found: null
%     Score = -3,210534 (regressionFit = 3,210531, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, A).  [covers 4,0/24,0 pos, 0,0/0,0 neg]
%     Score = -3,210535 (regressionFit = 3,210531, penalties=3.9300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(C, A), publication(C, B).  [covers 4,0/24,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- professor(B), student(A), publication(C, A), publication(C, B).  [covers 4,0/24,0 pos, 0,0/0,0 neg]

% Expanding node at Level 1 with score = -0,135.
% Will extend: advisedby(A, B) :- professor(B), student(A), publication(C, A), publication(C, B).  [covers 4,0/24,0 pos, 0,0/0,0 neg]
% Path: 6;true
Comparing variance: 0.0 to score=0.0025 #egs=4.0
Comparing variance: 0.16052653179154053 to score=0.0025 #egs=20.0
%   Creating a TRUE-branch leaf because wgtedCountTrueBranchPos = 4,0 < 2.1 * minPosCov = 6,3
%   Creating a FALSE-branch interior node with wgtedCountFalseBranchPos = 20,0
%      addToQueueOfTreeStructuredLearningTasks (level=2; score=-0,160527)
%         ILP node to extend: advisedby(A, B) :- professor(B), student(A).  [covers 24,0/24,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 2 and with score = -0,160527) into the LAST position (#1) in the search queue.

% Time for loop #2: 3 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #2, the best clause found is:
%      advisedby(A, B) :- professor(B), student(A), publication(C, A), publication(C, B).  [covers 4,0/24,0 pos, 0,0/0,0 neg]
% This clause covers 4 positive examples, of which 4 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- professor(B), student(A).  [covers 24,0/20,0 pos, 0,0/0,0 neg]'
%     Score = -3,241787 (regressionFit = 3,241785, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- professor(B), student(A).  [covers 20,0/20,0 pos, 0,0/0,0 neg]

% Have these 7 positive seeds: 0 4 8 9 11 18 19
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% Consider expanding [#1 of outerLoop #3, bodyLen=2] 'advisedby(A, B) :- professor(B), student(A).  [covers 20,0/20,0 pos, 0,0/0,0 neg]' score=-3.241787026507149
%  At # nodes expanded = 1, |OPEN| = 0.  Pruned 16 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -3,200842 (regressionFit = 3,200838, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
% Gleaner: New best node found (score = -3,200842): advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,189672 (regressionFit = 3,189669, penalties=3.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
% Gleaner: New best node found (score = -3,189672): advisedby(A, B) :- professor(B), student(A), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _).  [covers 18,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,209665 (regressionFit = 3,209662, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,201365 (regressionFit = 3,201361, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.0200000000000007E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.0200000000000007E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(B, B).  [covers 20,0/20,0 pos, 0,0/0,0 neg]

% Consider expanding [#2 of outerLoop #3, bodyLen=3] 'advisedby(A, B) :- professor(B), student(A), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]' score=-3.189671910419684
%  At # nodes expanded = 2, |OPEN| = 8.  Pruned 26 variant children.  Sending 14 items to OPEN for evaluation and possible insertion.
% Have created 14 valid-on-seeds descendants and have picked up 15 bad extensions.
%     Score = -3,209353 (regressionFit = 3,209349, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), tempadvisedby(_, B).  [covers 10,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,189673 (regressionFit = 3,189669, penalties=4.05E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), ta(C, _, D).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,189673 (regressionFit = 3,189669, penalties=4.260000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), ta(_, _, C).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,189673 (regressionFit = 3,189669, penalties=4.150000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,189673 (regressionFit = 3,189669, penalties=4.260000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, _, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,189673 (regressionFit = 3,189669, penalties=4.3600000000000015E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,206075 (regressionFit = 3,206071, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), hasposition(B, _).  [covers 13,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,126617 (regressionFit = 3,126612, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B).  [covers 12,0/20,0 pos, 0,0/0,0 neg]
% Gleaner: New best node found (score = -3,126617): advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B).  [covers 12,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,189673 (regressionFit = 3,189669, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), inphase(A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,189673 (regressionFit = 3,189669, penalties=4.250000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), courselevel(C, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,189673 (regressionFit = 3,189669, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), yearsinprogram(A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,189673 (regressionFit = 3,189669, penalties=4.14E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), samecourse(C, C).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,189673 (regressionFit = 3,189669, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), sameperson(A, A).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,189673 (regressionFit = 3,189669, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), sameperson(B, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]

% Consider expanding [#3 of outerLoop #3, bodyLen=3] 'advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]' score=-3.200841555439912
%  At # nodes expanded = 3, |OPEN| = 7.  Pruned 34 variant children.  Sending 13 items to OPEN for evaluation and possible insertion.
% Have created 13 valid-on-seeds descendants and have picked up 26 bad extensions.
%     Score = -3,200842 (regressionFit = 3,200838, penalties=3.9300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(C, B), student(C).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,209353 (regressionFit = 3,209349, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B), ta(_, A, _).  [covers 10,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,200843 (regressionFit = 3,200838, penalties=4.250000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(C, B), ta(_, C, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,200843 (regressionFit = 3,200838, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B), hasposition(B, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,181068 (regressionFit = 3,181063, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B), publication(_, B).  [covers 11,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,200843 (regressionFit = 3,200838, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B), inphase(A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,200843 (regressionFit = 3,200838, penalties=4.14E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(C, B), inphase(C, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,200843 (regressionFit = 3,200838, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B), yearsinprogram(A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,200843 (regressionFit = 3,200838, penalties=4.14E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(C, B), yearsinprogram(C, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,201366 (regressionFit = 3,201361, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B), projectmember(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,200843 (regressionFit = 3,200838, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B), sameperson(A, A).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,200843 (regressionFit = 3,200838, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B), sameperson(B, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,200842 (regressionFit = 3,200838, penalties=4.03E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(C, B), sameperson(C, C).  [covers 14,0/20,0 pos, 0,0/0,0 neg]

% Consider expanding [#4 of outerLoop #3, bodyLen=3] 'advisedby(A, B) :- professor(B), student(A), projectmember(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]' score=-3.201364513709044
%  At # nodes expanded = 4, |OPEN| = 6.  Pruned 20 variant children.  Sending 8 items to OPEN for evaluation and possible insertion.
% Have created 8 valid-on-seeds descendants and have picked up 16 bad extensions.
%     Score = -3,201366 (regressionFit = 3,201361, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), tempadvisedby(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,201366 (regressionFit = 3,201361, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), hasposition(B, _).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,201366 (regressionFit = 3,201361, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), inphase(A, _).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,201366 (regressionFit = 3,201361, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), yearsinprogram(A, _).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,201366 (regressionFit = 3,201361, penalties=4.140000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), projectmember(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,201365 (regressionFit = 3,201361, penalties=4.03E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(C, B), sameproject(C, C).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,201366 (regressionFit = 3,201361, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), sameperson(A, A).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,201366 (regressionFit = 3,201361, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), sameperson(B, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]

% Consider expanding [#5 of outerLoop #3, bodyLen=3] 'advisedby(A, B) :- professor(B), student(A), publication(_, B).  [covers 15,0/20,0 pos, 0,0/0,0 neg]' score=-3.209664790585341
%  At # nodes expanded = 5, |OPEN| = 5.  Pruned 18 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 15 bad extensions.
%     Score = -3,181068 (regressionFit = 3,181063, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B), tempadvisedby(_, B).  [covers 11,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,126617 (regressionFit = 3,126612, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B), ta(_, A, _).  [covers 12,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,209666 (regressionFit = 3,209662, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B), hasposition(B, _).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,209666 (regressionFit = 3,209662, penalties=4.040000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(C, B), publication(C, _).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,209666 (regressionFit = 3,209662, penalties=4.140000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B), publication(_, B).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,209666 (regressionFit = 3,209662, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B), inphase(A, _).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,209666 (regressionFit = 3,209662, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B), yearsinprogram(A, _).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,209666 (regressionFit = 3,209662, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B), sameperson(A, A).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,209666 (regressionFit = 3,209662, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B), sameperson(B, B).  [covers 15,0/20,0 pos, 0,0/0,0 neg]

% Consider expanding [#6 of outerLoop #3, bodyLen=3] 'advisedby(A, B) :- professor(B), student(A), hasposition(B, _).  [covers 18,0/20,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 6, |OPEN| = 4.  Pruned 18 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -3,200843 (regressionFit = 3,200838, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _), tempadvisedby(_, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,206075 (regressionFit = 3,206071, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _), ta(_, A, _).  [covers 13,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.040000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, C), hasposition(_, C).  [covers 18,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,209666 (regressionFit = 3,209662, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _), publication(_, B).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _), inphase(A, _).  [covers 18,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _), yearsinprogram(A, _).  [covers 18,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,201366 (regressionFit = 3,201361, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _), projectmember(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _), sameperson(A, A).  [covers 18,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _), sameperson(B, B).  [covers 18,0/20,0 pos, 0,0/0,0 neg]

% Consider expanding [#7 of outerLoop #3, bodyLen=3] 'advisedby(A, B) :- professor(B), student(A), inphase(A, _).  [covers 20,0/20,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 7, |OPEN| = 3.  Pruned 18 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -3,200843 (regressionFit = 3,200838, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _), tempadvisedby(_, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,189673 (regressionFit = 3,189669, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _), hasposition(B, _).  [covers 18,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,209666 (regressionFit = 3,209662, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _), publication(_, B).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.040000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, C), inphase(_, C).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _), yearsinprogram(A, _).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,201366 (regressionFit = 3,201361, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _), projectmember(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _), sameperson(A, A).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _), sameperson(B, B).  [covers 20,0/20,0 pos, 0,0/0,0 neg]

% Consider expanding [#8 of outerLoop #3, bodyLen=3] 'advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _).  [covers 20,0/20,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 8, |OPEN| = 2.  Pruned 18 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -3,200843 (regressionFit = 3,200838, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _), tempadvisedby(_, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,189673 (regressionFit = 3,189669, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _), hasposition(B, _).  [covers 18,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,209666 (regressionFit = 3,209662, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _), publication(_, B).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _), inphase(A, _).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.040000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, C), yearsinprogram(_, C).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,201366 (regressionFit = 3,201361, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _), projectmember(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _), sameperson(A, A).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _), sameperson(B, B).  [covers 20,0/20,0 pos, 0,0/0,0 neg]

% Consider expanding [#9 of outerLoop #3, bodyLen=3] 'advisedby(A, B) :- professor(B), student(A), sameperson(A, A).  [covers 20,0/20,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 9, |OPEN| = 1.  Pruned 14 variant children.  Sending 8 items to OPEN for evaluation and possible insertion.
% Have created 8 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -3,200843 (regressionFit = 3,200838, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A), tempadvisedby(_, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,189673 (regressionFit = 3,189669, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A), hasposition(B, _).  [covers 18,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,209666 (regressionFit = 3,209662, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A), publication(_, B).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A), inphase(A, _).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A), yearsinprogram(A, _).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,201366 (regressionFit = 3,201361, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A), projectmember(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.920000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A), sameperson(B, B).  [covers 20,0/20,0 pos, 0,0/0,0 neg]

***** Warning: #6 TOO MANY NODES CONSIDERED (i.e., 'expanded') for 'LearnOneClause': nodesConsidered = 10 and maxNodesToConsider = 10. *****


% The best node found: advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B).  [covers 12,0/20,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B).  [covers 12,0/20,0 pos, 0,0/0,0 neg]

% Expanding node at Level 2 with score = -0,161.
% Will extend: advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B).  [covers 12,0/20,0 pos, 0,0/0,0 neg]
% Path: 6;true,false
Comparing variance: 0.16935556000468768 to score=0.0025 #egs=12.0
Comparing variance: 0.1367932033226985 to score=0.0025 #egs=8.0
%   Creating a TRUE-branch interior node with wgtedCountTrueBranchPos = 12,0
%      addToQueueOfTreeStructuredLearningTasks (level=3; score=-0,169356)
%         ILP node to extend: advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B).  [covers 12,0/20,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 3 and with score = -0,169356) into the LAST position (#1) in the search queue.
%   Creating a FALSE-branch interior node with wgtedCountFalseBranchPos = 8,0
%      addToQueueOfTreeStructuredLearningTasks (level=3; score=-0,136793)
%         ILP node to extend: advisedby(A, B) :- professor(B), student(A).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 3 and with score = -0,136793) into the LAST position (#2) in the search queue.

% Time for loop #3: 81 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #3, the best clause found is:
%      advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B).  [covers 12,0/20,0 pos, 0,0/0,0 neg]
% This clause covers 12 positive examples, of which 12 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B).  [covers 12,0/12,0 pos, 0,0/0,0 neg]'
%     Score = -3,126617 (regressionFit = 3,126612, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B).  [covers 12,0/12,0 pos, 0,0/0,0 neg]

% Have these 8 positive seeds: 0 3 4 5 6 7 8 9
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% Consider expanding [#1 of outerLoop #4, bodyLen=4] 'advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B).  [covers 12,0/12,0 pos, 0,0/0,0 neg]' score=-3.1266166966378406
%  At # nodes expanded = 1, |OPEN| = 0.  Pruned 28 variant children.  Sending 16 items to OPEN for evaluation and possible insertion.
% Have created 16 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -2,028421 (regressionFit = 2,028415, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), tempadvisedby(_, B).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
% Gleaner: New best node found (score = -2,028421): advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), tempadvisedby(_, B).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.160000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(_, B), ta(C, _, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), ta(_, _, C).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.2600000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, _, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.47E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), ta(_, A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), hasposition(B, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.2600000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(C, B), publication(C, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.360000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), publication(_, B).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), inphase(A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.36E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), courselevel(C, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), yearsinprogram(A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), projectmember(_, B).  [covers 2,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.2500000000000006E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), samecourse(C, C).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.3500000000000004E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), sameperson(A, A).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.3500000000000004E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), sameperson(B, B).  [covers 12,0/12,0 pos, 0,0/0,0 neg]

% Consider expanding [#2 of outerLoop #4, bodyLen=5] 'advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), tempadvisedby(_, B).  [covers 9,0/12,0 pos, 0,0/0,0 neg]' score=-2.028420854698013
%  At # nodes expanded = 2, |OPEN| = 15.  Pruned 53 variant children.  Sending 21 items to OPEN for evaluation and possible insertion.
% Have created 21 valid-on-seeds descendants and have picked up 27 bad extensions.
%     Score = -2,028422 (regressionFit = 2,028415, penalties=6.260000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), tempadvisedby(C, B), student(C).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,028422 (regressionFit = 2,028415, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(_, B), tempadvisedby(_, B), ta(C, _, D).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), tempadvisedby(D, B), ta(_, D, C).  [covers 2,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,028422 (regressionFit = 2,028415, penalties=6.480000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), tempadvisedby(_, B), ta(_, _, C).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,028422 (regressionFit = 2,028415, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), tempadvisedby(_, B), ta(C, A, _).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,028422 (regressionFit = 2,028415, penalties=6.480000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), tempadvisedby(_, B), ta(C, _, _).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,028422 (regressionFit = 2,028415, penalties=6.580000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), tempadvisedby(_, B), ta(_, A, _).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,028422 (regressionFit = 2,028415, penalties=6.480000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), tempadvisedby(C, B), ta(_, C, _).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,028422 (regressionFit = 2,028415, penalties=6.5700000000000015E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), tempadvisedby(_, B), hasposition(B, _).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,028422 (regressionFit = 2,028415, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(C, B), tempadvisedby(_, B), publication(C, _).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,028422 (regressionFit = 2,028415, penalties=6.470000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), tempadvisedby(_, B), publication(_, B).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,028422 (regressionFit = 2,028415, penalties=6.5700000000000015E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), tempadvisedby(_, B), inphase(A, _).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,028422 (regressionFit = 2,028415, penalties=6.470000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), tempadvisedby(C, B), inphase(C, _).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,028422 (regressionFit = 2,028415, penalties=6.470000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), tempadvisedby(_, B), courselevel(C, _).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,028422 (regressionFit = 2,028415, penalties=6.5700000000000015E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), tempadvisedby(_, B), yearsinprogram(A, _).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,028422 (regressionFit = 2,028415, penalties=6.470000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), tempadvisedby(C, B), yearsinprogram(C, _).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.5700000000000015E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), tempadvisedby(_, B), projectmember(_, B).  [covers 2,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,028422 (regressionFit = 2,028415, penalties=6.360000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), tempadvisedby(_, B), samecourse(C, C).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,028422 (regressionFit = 2,028415, penalties=6.460000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), tempadvisedby(_, B), sameperson(A, A).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,028422 (regressionFit = 2,028415, penalties=6.460000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), tempadvisedby(_, B), sameperson(B, B).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,028422 (regressionFit = 2,028415, penalties=6.360000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), tempadvisedby(C, B), sameperson(C, C).  [covers 9,0/12,0 pos, 0,0/0,0 neg]

% Consider expanding [#3 of outerLoop #4, bodyLen=5] 'advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(_, B), ta(C, _, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 3, |OPEN| = 14.  Pruned 52 variant children.  Sending 25 items to OPEN for evaluation and possible insertion.
% Have created 25 valid-on-seeds descendants and have picked up 25 bad extensions.
%     Score = -Infinity (regressionFit = Infinity, penalties=5.9600000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(_, B), ta(C, E, D), student(E).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.170000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(_, B), ta(C, E, D), tempadvisedby(E, _).  [covers 1,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,028422 (regressionFit = 2,028415, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(_, B), ta(C, _, D), tempadvisedby(_, B).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.170000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(_, B), ta(C, _, D), ta(C, _, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(_, B), ta(C, _, D), ta(_, _, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.170000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(_, B), ta(C, _, D), ta(C, A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.07E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(_, B), ta(C, E, D), ta(C, E, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(_, B), ta(C, _, D), ta(C, _, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(_, B), ta(C, _, D), ta(_, A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.180000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(_, B), ta(C, E, D), ta(_, E, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(_, B), ta(C, _, D), hasposition(B, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.07E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(E, B), ta(C, _, D), publication(E, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.170000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(_, B), ta(C, _, D), publication(_, B).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(_, B), ta(C, _, D), inphase(A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.170000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(_, B), ta(C, E, D), inphase(E, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(_, B), ta(C, _, D), courselevel(C, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(_, B), ta(C, _, D), yearsinprogram(A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.170000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(_, B), ta(C, E, D), yearsinprogram(E, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(_, B), ta(C, _, D), projectmember(_, B).  [covers 2,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.160000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(_, B), ta(C, _, D), samecourse(C, C).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.160000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(_, B), ta(C, _, D), sameperson(A, A).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.060000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(_, B), ta(C, E, D), sameperson(A, E).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.160000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(_, B), ta(C, _, D), sameperson(B, B).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.060000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(_, B), ta(C, E, D), sameperson(E, A).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.060000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(_, B), ta(C, E, D), sameperson(E, E).  [covers 12,0/12,0 pos, 0,0/0,0 neg]

% Consider expanding [#4 of outerLoop #4, bodyLen=5] 'advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), ta(_, _, C).  [covers 12,0/12,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 4, |OPEN| = 13.  Pruned 71 variant children.  Sending 35 items to OPEN for evaluation and possible insertion.
% Have created 35 valid-on-seeds descendants and have picked up 27 bad extensions.
%     Score = -Infinity (regressionFit = Infinity, penalties=6.170000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), ta(_, D, C), student(D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), ta(_, D, C), tempadvisedby(D, B).  [covers 2,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3800000000000024E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), ta(_, D, C), tempadvisedby(D, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,028422 (regressionFit = 2,028415, penalties=6.480000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), ta(_, _, C), tempadvisedby(_, B).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(_, B), ta(_, _, D), ta(C, _, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), ta(D, _, C), ta(D, _, C).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.4900000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), ta(_, _, C), ta(_, _, C).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(_, B), ta(_, _, D), ta(C, A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.180000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(_, B), ta(_, E, D), ta(C, E, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3900000000000015E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(_, B), ta(_, _, D), ta(C, _, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), ta(D, _, C), ta(D, A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.180000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), ta(D, E, C), ta(D, E, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3900000000000015E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), ta(D, _, C), ta(D, _, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.4900000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), ta(_, _, C), ta(_, A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3900000000000015E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), ta(_, D, C), ta(_, D, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.480000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), ta(_, _, C), hasposition(B, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(D, B), ta(_, _, C), publication(D, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3800000000000024E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), ta(_, _, C), publication(_, B).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -1,848737 (regressionFit = 1,848730, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), ta(_, D, C), publication(_, D).  [covers 4,0/12,0 pos, 0,0/0,0 neg]
% Gleaner: New best node found (score = -1,848737): advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), ta(_, D, C), publication(_, D).  [covers 4,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.480000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), ta(_, _, C), inphase(A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3800000000000024E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), ta(_, D, C), inphase(D, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3800000000000024E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(_, B), ta(_, _, D), courselevel(C, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3800000000000024E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), ta(D, _, C), courselevel(D, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.480000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), ta(_, _, C), yearsinprogram(A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3800000000000024E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), ta(_, D, C), yearsinprogram(D, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.480000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), ta(_, _, C), projectmember(_, B).  [covers 2,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(_, B), ta(_, _, D), samecourse(C, C).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.170000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(_, B), ta(E, _, D), samecourse(C, E).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.170000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(_, B), ta(E, _, D), samecourse(E, C).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), ta(D, _, C), samecourse(D, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), ta(_, _, C), sameperson(A, A).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), ta(_, D, C), sameperson(A, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), ta(_, _, C), sameperson(B, B).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), ta(_, D, C), sameperson(D, A).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), ta(_, D, C), sameperson(D, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]

% Consider expanding [#5 of outerLoop #4, bodyLen=5] 'advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 5, |OPEN| = 12.  Pruned 34 variant children.  Sending 18 items to OPEN for evaluation and possible insertion.
% Have created 18 valid-on-seeds descendants and have picked up 15 bad extensions.
%     Score = -2,028422 (regressionFit = 2,028415, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, A, _), tempadvisedby(_, B).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.170000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(_, B), ta(C, A, _), ta(C, _, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.170000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, A, D), ta(C, _, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(_, B), ta(C, A, _), ta(_, _, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, A, D), ta(_, _, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, A, _), ta(C, A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3800000000000024E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, A, _), ta(C, _, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3800000000000024E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, A, _), ta(_, A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, A, _), hasposition(B, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.170000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(D, B), ta(C, A, _), publication(D, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, A, _), publication(_, B).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, A, _), inphase(A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, A, _), courselevel(C, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, A, _), yearsinprogram(A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, A, _), projectmember(_, B).  [covers 2,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.260000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, A, _), samecourse(C, C).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.260000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, A, _), sameperson(A, A).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.260000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, A, _), sameperson(B, B).  [covers 12,0/12,0 pos, 0,0/0,0 neg]

% Consider expanding [#6 of outerLoop #4, bodyLen=5] 'advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, _, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 6, |OPEN| = 11.  Pruned 65 variant children.  Sending 31 items to OPEN for evaluation and possible insertion.
% Have created 31 valid-on-seeds descendants and have picked up 27 bad extensions.
%     Score = -Infinity (regressionFit = Infinity, penalties=6.170000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, D, _), student(D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3800000000000024E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, D, _), tempadvisedby(D, _).  [covers 11,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,028422 (regressionFit = 2,028415, penalties=6.480000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, _, _), tempadvisedby(_, B).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.07E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(_, B), ta(C, E, _), ta(C, E, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(_, B), ta(C, _, _), ta(C, _, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, _, D), ta(C, _, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, _, D), ta(_, A, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.180000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(_, B), ta(C, E, _), ta(_, E, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3900000000000015E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(_, B), ta(C, _, _), ta(_, _, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3900000000000015E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, _, D), ta(_, _, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3800000000000024E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, _, _), ta(C, A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, D, _), ta(C, D, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.4900000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, _, _), ta(C, _, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.4900000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, _, _), ta(_, A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3900000000000015E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, D, _), ta(_, D, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.480000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, _, _), hasposition(B, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(D, B), ta(C, _, _), publication(D, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3800000000000024E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, _, _), publication(_, B).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -1,808670 (regressionFit = 1,808663, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, D, _), publication(_, D).  [covers 3,0/12,0 pos, 0,0/0,0 neg]
% Gleaner: New best node found (score = -1,808670): advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, D, _), publication(_, D).  [covers 3,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.480000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, _, _), inphase(A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3800000000000024E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, D, _), inphase(D, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.480000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, _, _), courselevel(C, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.480000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, _, _), yearsinprogram(A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3800000000000024E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, D, _), yearsinprogram(D, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.480000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, _, _), projectmember(_, B).  [covers 2,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, _, _), samecourse(C, C).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, _, _), sameperson(A, A).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, D, _), sameperson(A, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, _, _), sameperson(B, B).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, D, _), sameperson(D, A).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, D, _), sameperson(D, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]

% Consider expanding [#7 of outerLoop #4, bodyLen=5] 'advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), ta(_, A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 7, |OPEN| = 10.  Pruned 56 variant children.  Sending 26 items to OPEN for evaluation and possible insertion.
% Have created 26 valid-on-seeds descendants and have picked up 19 bad extensions.
%     Score = -2,028422 (regressionFit = 2,028415, penalties=6.580000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), ta(_, A, _), tempadvisedby(_, B).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(_, B), ta(_, A, _), ta(C, _, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(_, A, D), ta(C, _, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), ta(D, A, _), ta(D, _, C).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), ta(C, A, D), ta(C, _, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.4900000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), ta(_, A, _), ta(_, _, C).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.4900000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), ta(_, A, C), ta(_, _, C).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3800000000000024E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(_, A, _), ta(C, A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.4900000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(_, A, _), ta(C, _, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3800000000000024E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), ta(C, A, _), ta(C, A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.4900000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), ta(C, A, _), ta(C, _, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.5900000000000004E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), ta(_, A, _), ta(_, A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.580000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), ta(_, A, _), hasposition(B, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3800000000000024E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(C, B), ta(_, A, _), publication(C, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.480000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), ta(_, A, _), publication(_, B).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.580000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), ta(_, A, _), inphase(A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.480000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(_, A, _), courselevel(C, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.480000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), ta(C, A, _), courselevel(C, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.580000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), ta(_, A, _), yearsinprogram(A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.580000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), ta(_, A, _), projectmember(_, B).  [covers 2,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(_, A, _), samecourse(C, C).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(D, A, _), samecourse(C, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(D, A, _), samecourse(D, C).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), ta(C, A, _), samecourse(C, C).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.470000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), ta(_, A, _), sameperson(A, A).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.470000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), ta(_, A, _), sameperson(B, B).  [covers 12,0/12,0 pos, 0,0/0,0 neg]

% Consider expanding [#8 of outerLoop #4, bodyLen=5] 'advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), hasposition(B, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 8, |OPEN| = 9.  Pruned 30 variant children.  Sending 16 items to OPEN for evaluation and possible insertion.
% Have created 16 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -2,028422 (regressionFit = 2,028415, penalties=6.5700000000000015E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), hasposition(B, _), tempadvisedby(_, B).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(_, B), hasposition(B, _), ta(C, _, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.480000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), hasposition(B, _), ta(_, _, C).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), hasposition(B, _), ta(C, A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.480000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), hasposition(B, _), ta(C, _, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.580000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), hasposition(B, _), ta(_, A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), hasposition(B, C), hasposition(_, C).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(C, B), hasposition(B, _), publication(C, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.470000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), hasposition(B, _), publication(_, B).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.5700000000000015E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), hasposition(B, _), inphase(A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.470000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), hasposition(B, _), courselevel(C, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.5700000000000015E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), hasposition(B, _), yearsinprogram(A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.5700000000000015E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), hasposition(B, _), projectmember(_, B).  [covers 2,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.360000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), hasposition(B, _), samecourse(C, C).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.460000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), hasposition(B, _), sameperson(A, A).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.460000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), hasposition(B, _), sameperson(B, B).  [covers 12,0/12,0 pos, 0,0/0,0 neg]

% Consider expanding [#9 of outerLoop #4, bodyLen=5] 'advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(C, B), publication(C, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 9, |OPEN| = 8.  Pruned 53 variant children.  Sending 27 items to OPEN for evaluation and possible insertion.
% Have created 27 valid-on-seeds descendants and have picked up 22 bad extensions.
%     Score = -Infinity (regressionFit = Infinity, penalties=6.0600000000000004E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(C, B), publication(C, D), professor(D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.0600000000000004E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(C, B), publication(C, D), student(D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -2,028422 (regressionFit = 2,028415, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(C, B), publication(C, _), tempadvisedby(_, B).  [covers 9,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(C, B), publication(C, D), tempadvisedby(_, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.07E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), publication(E, B), publication(E, _), ta(C, _, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(D, B), publication(D, _), ta(_, _, C).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.170000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(D, B), publication(D, _), ta(C, A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.2800000000000026E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(D, B), publication(D, _), ta(C, _, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.3800000000000024E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(C, B), publication(C, _), ta(_, A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(C, B), publication(C, _), hasposition(B, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(C, B), publication(C, D), hasposition(D, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(C, B), publication(C, _), publication(C, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(C, B), publication(C, _), publication(_, B).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.170000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(C, B), publication(C, D), publication(_, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(C, B), publication(C, _), inphase(A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -1,966402 (regressionFit = 1,966396, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(C, B), publication(C, D), inphase(D, _).  [covers 8,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(D, B), publication(D, _), courselevel(C, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(C, B), publication(C, _), yearsinprogram(A, _).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -1,966402 (regressionFit = 1,966396, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(C, B), publication(C, D), yearsinprogram(D, _).  [covers 8,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.370000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(C, B), publication(C, _), projectmember(_, B).  [covers 2,0/12,0 pos, 0,0/0,0 neg]
%     Score = -1,932069 (regressionFit = 1,932062, penalties=6.270000000000003E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(C, B), publication(C, D), projectmember(_, D).  [covers 3,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.160000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(D, B), publication(D, _), samecourse(C, C).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.260000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(C, B), publication(C, _), sameperson(A, A).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.260000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(C, B), publication(C, _), sameperson(B, B).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.160000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(C, B), publication(C, D), sameperson(B, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.160000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(C, B), publication(C, D), sameperson(D, B).  [covers 12,0/12,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=6.160000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(C, B), publication(C, D), sameperson(D, D).  [covers 12,0/12,0 pos, 0,0/0,0 neg]

***** Warning: #7 TOO MANY NODES CONSIDERED (i.e., 'expanded') for 'LearnOneClause': nodesConsidered = 10 and maxNodesToConsider = 10. *****


% The best node found: advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, D, _), publication(_, D).  [covers 3,0/12,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, D, _), publication(_, D).  [covers 3,0/12,0 pos, 0,0/0,0 neg]

% Expanding node at Level 3 with score = -0,169.
% Will extend: advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, D, _), publication(_, D).  [covers 3,0/12,0 pos, 0,0/0,0 neg]
% Path: 6;true,false,true
Comparing variance: 0.008498652812411337 to score=0.0025 #egs=3.0
Comparing variance: 0.19812972235779158 to score=0.0025 #egs=9.0
%   Creating a TRUE-branch and FALSE-branch leaves because level = 3 >= 3

% Time for loop #4: 475 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #4, the best clause found is:
%      advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, D, _), publication(_, D).  [covers 3,0/12,0 pos, 0,0/0,0 neg]
% This clause covers 3 positive examples, of which 3 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- professor(B), student(A).  [covers 20,0/8,0 pos, 0,0/0,0 neg]'
%     Score = -3,241787 (regressionFit = 3,241785, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- professor(B), student(A).  [covers 8,0/8,0 pos, 0,0/0,0 neg]

% Have these 8 positive seeds: 0 1 2 3 4 5 6 7
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% Consider expanding [#1 of outerLoop #5, bodyLen=2] 'advisedby(A, B) :- professor(B), student(A).  [covers 8,0/8,0 pos, 0,0/0,0 neg]' score=-3.241787026507149
%  At # nodes expanded = 1, |OPEN| = 0.  Pruned 16 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 28 bad extensions.
%     Score = -1,093890 (regressionFit = 1,093887, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
% Gleaner: New best node found (score = -1,093890): advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _).  [covers 2,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _).  [covers 6,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,032846 (regressionFit = 1,032843, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
% Gleaner: New best node found (score = -1,032846): advisedby(A, B) :- professor(B), student(A), publication(_, B).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,036406 (regressionFit = 1,036403, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.0200000000000007E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.0200000000000007E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(B, B).  [covers 8,0/8,0 pos, 0,0/0,0 neg]

% Consider expanding [#2 of outerLoop #5, bodyLen=3] 'advisedby(A, B) :- professor(B), student(A), publication(_, B).  [covers 3,0/8,0 pos, 0,0/0,0 neg]' score=-1.0328458464322743
%  At # nodes expanded = 2, |OPEN| = 8.  Pruned 18 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 15 bad extensions.
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B), tempadvisedby(_, B).  [covers 2,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,032847 (regressionFit = 1,032843, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B), hasposition(B, _).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,032847 (regressionFit = 1,032843, penalties=4.040000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(C, B), publication(C, _).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,032847 (regressionFit = 1,032843, penalties=4.140000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B), publication(_, B).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,032847 (regressionFit = 1,032843, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B), inphase(A, _).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,032847 (regressionFit = 1,032843, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B), yearsinprogram(A, _).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B), projectmember(_, B).  [covers 1,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,032847 (regressionFit = 1,032843, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B), sameperson(A, A).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,032847 (regressionFit = 1,032843, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B), sameperson(B, B).  [covers 3,0/8,0 pos, 0,0/0,0 neg]

% Consider expanding [#3 of outerLoop #5, bodyLen=3] 'advisedby(A, B) :- professor(B), student(A), projectmember(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]' score=-1.036406086927359
%  At # nodes expanded = 3, |OPEN| = 7.  Pruned 20 variant children.  Sending 10 items to OPEN for evaluation and possible insertion.
% Have created 10 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -1,036407 (regressionFit = 1,036403, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), tempadvisedby(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), ta(_, A, _).  [covers 1,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,036407 (regressionFit = 1,036403, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), hasposition(B, _).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), publication(_, B).  [covers 1,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,036407 (regressionFit = 1,036403, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), inphase(A, _).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,036407 (regressionFit = 1,036403, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), yearsinprogram(A, _).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,036407 (regressionFit = 1,036403, penalties=4.140000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), projectmember(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,036407 (regressionFit = 1,036403, penalties=4.03E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(C, B), sameproject(C, C).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,036407 (regressionFit = 1,036403, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), sameperson(A, A).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,036407 (regressionFit = 1,036403, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), sameperson(B, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]

% Consider expanding [#4 of outerLoop #5, bodyLen=3] 'advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B).  [covers 5,0/8,0 pos, 0,0/0,0 neg]' score=-1.0938897079527754
%  At # nodes expanded = 4, |OPEN| = 6.  Pruned 34 variant children.  Sending 13 items to OPEN for evaluation and possible insertion.
% Have created 13 valid-on-seeds descendants and have picked up 26 bad extensions.
%     Score = -1,093891 (regressionFit = 1,093887, penalties=3.9300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(C, B), student(C).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B), ta(_, A, _).  [covers 1,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,093891 (regressionFit = 1,093887, penalties=4.250000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(C, B), ta(_, C, _).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,093891 (regressionFit = 1,093887, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B), hasposition(B, _).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B), publication(_, B).  [covers 2,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,093891 (regressionFit = 1,093887, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B), inphase(A, _).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,093891 (regressionFit = 1,093887, penalties=4.14E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(C, B), inphase(C, _).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,093891 (regressionFit = 1,093887, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B), yearsinprogram(A, _).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,093891 (regressionFit = 1,093887, penalties=4.14E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(C, B), yearsinprogram(C, _).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,036407 (regressionFit = 1,036403, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B), projectmember(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,093891 (regressionFit = 1,093887, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B), sameperson(A, A).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,093891 (regressionFit = 1,093887, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B), sameperson(B, B).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,093891 (regressionFit = 1,093887, penalties=4.03E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(C, B), sameperson(C, C).  [covers 5,0/8,0 pos, 0,0/0,0 neg]

% Consider expanding [#5 of outerLoop #5, bodyLen=3] 'advisedby(A, B) :- professor(B), student(A), ta(_, A, _).  [covers 2,0/8,0 pos, 0,0/0,0 neg]' score=-Infinity

% Consider expanding [#6 of outerLoop #5, bodyLen=3] 'advisedby(A, B) :- professor(B), student(A), hasposition(B, _).  [covers 6,0/8,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 6, |OPEN| = 4.  Pruned 18 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -1,093891 (regressionFit = 1,093887, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _), tempadvisedby(_, B).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _), ta(_, A, _).  [covers 1,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.040000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, C), hasposition(_, C).  [covers 6,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,032847 (regressionFit = 1,032843, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _), publication(_, B).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _), inphase(A, _).  [covers 6,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _), yearsinprogram(A, _).  [covers 6,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,036407 (regressionFit = 1,036403, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _), projectmember(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _), sameperson(A, A).  [covers 6,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _), sameperson(B, B).  [covers 6,0/8,0 pos, 0,0/0,0 neg]

% Consider expanding [#7 of outerLoop #5, bodyLen=3] 'advisedby(A, B) :- professor(B), student(A), inphase(A, _).  [covers 8,0/8,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 7, |OPEN| = 3.  Pruned 18 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -1,093891 (regressionFit = 1,093887, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _), tempadvisedby(_, B).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _), ta(_, A, _).  [covers 2,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _), hasposition(B, _).  [covers 6,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,032847 (regressionFit = 1,032843, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _), publication(_, B).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.040000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, C), inphase(_, C).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _), yearsinprogram(A, _).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,036407 (regressionFit = 1,036403, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _), projectmember(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _), sameperson(A, A).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _), sameperson(B, B).  [covers 8,0/8,0 pos, 0,0/0,0 neg]

% Consider expanding [#8 of outerLoop #5, bodyLen=3] 'advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _).  [covers 8,0/8,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 8, |OPEN| = 2.  Pruned 18 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -1,093891 (regressionFit = 1,093887, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _), tempadvisedby(_, B).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _), ta(_, A, _).  [covers 2,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _), hasposition(B, _).  [covers 6,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,032847 (regressionFit = 1,032843, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _), publication(_, B).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _), inphase(A, _).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.040000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, C), yearsinprogram(_, C).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,036407 (regressionFit = 1,036403, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _), projectmember(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _), sameperson(A, A).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _), sameperson(B, B).  [covers 8,0/8,0 pos, 0,0/0,0 neg]

% Consider expanding [#9 of outerLoop #5, bodyLen=3] 'advisedby(A, B) :- professor(B), student(A), sameperson(A, A).  [covers 8,0/8,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 9, |OPEN| = 1.  Pruned 14 variant children.  Sending 8 items to OPEN for evaluation and possible insertion.
% Have created 8 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -1,093891 (regressionFit = 1,093887, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A), tempadvisedby(_, B).  [covers 5,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A), ta(_, A, _).  [covers 2,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A), hasposition(B, _).  [covers 6,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,032847 (regressionFit = 1,032843, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A), publication(_, B).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A), inphase(A, _).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A), yearsinprogram(A, _).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -1,036407 (regressionFit = 1,036403, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A), projectmember(_, B).  [covers 4,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.920000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A), sameperson(B, B).  [covers 8,0/8,0 pos, 0,0/0,0 neg]

***** Warning: #8 TOO MANY NODES CONSIDERED (i.e., 'expanded') for 'LearnOneClause': nodesConsidered = 10 and maxNodesToConsider = 10. *****


% The best node found: advisedby(A, B) :- professor(B), student(A), publication(_, B).  [covers 3,0/8,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- professor(B), student(A), publication(_, B).  [covers 3,0/8,0 pos, 0,0/0,0 neg]

% Expanding node at Level 3 with score = -0,137.
% Will extend: advisedby(A, B) :- professor(B), student(A), publication(_, B).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
% Path: 6;true,false,false
Comparing variance: 0.07831805532760869 to score=0.0025 #egs=3.0
Comparing variance: 0.15957771008988964 to score=0.0025 #egs=5.0
%   Creating a TRUE-branch and FALSE-branch leaves because level = 3 >= 3

% Time for loop #5: 39 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #5, the best clause found is:
%      advisedby(A, B) :- professor(B), student(A), publication(_, B).  [covers 3,0/8,0 pos, 0,0/0,0 neg]
% This clause covers 3 positive examples, of which 3 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% ******************************************

%  Have stopped ILP's outer loop because the tree-structured queue is empty.

% ******************************************

%%%%%  WILL-Produced Tree #7 @ 17:27:16 5/29/21.  [Using 4.425.304 memory cells.]  %%%%%


% FOR advisedby(A, B):
%   if ( professor(B), student(A) )
%   then if ( publication(C, A), publication(C, B) )
%   | then return 0.20975771563253554;  // std dev = 0,000, 4,000 (wgt'ed) examples reached here.  /* #pos=4 */
%   | else if ( ta(D, A, E), publication(F, B) )
%   | | then if ( ta(D, G, H), publication(I, G) )
%   | | | then return 0.40224917676249355;  // std dev = 0,160, 3,000 (wgt'ed) examples reached here.  /* #pos=3 */
%   | | | else return 0.08700446730022045;  // std dev = 1,335, 9,000 (wgt'ed) examples reached here.  /* #neg=4 #pos=5 */
%   | | else if ( publication(J, B) )
%   | | | then return -0.07960255631709001;  // std dev = 0,485, 3,000 (wgt'ed) examples reached here.  /* #neg=2 #pos=1 */
%   | | | else return 0.1015094313580335;  // std dev = 0,893, 5,000 (wgt'ed) examples reached here.  /* #neg=2 #pos=3 */
%   else return -0.07877675473109176;  // std dev = 0,000, 24,000 (wgt'ed) examples reached here.  /* #neg=24 */


% Clauses:

advisedby(A, B, 0.20975771563253554) :- 
     professor(B), 
     student(A), 
     publication(C, A), 
     publication(C, B), 
     !. // Clause #1.

advisedby(A, B, 0.40224917676249355) :- 
     professor(B), 
     student(A), 
     ta(C, A, D), 
     publication(E, B), 
     ta(C, F, G), 
     publication(H, F), 
     !. // Clause #2.

advisedby(A, B, 0.08700446730022045) :- 
     professor(B), 
     student(A), 
     ta(C, A, D), 
     publication(E, B), 
     !. // Clause #3.

advisedby(A, B, -0.07960255631709001) :- 
     professor(B), 
     student(A), 
     publication(C, B), 
     !. // Clause #4.

advisedby(A, B, 0.1015094313580335) :- 
     professor(B), 
     student(A), 
     !. // Clause #5.

advisedby(A, B, -0.07877675473109176) :- !. // Clause #6.


% The flattened versions of these clauses:

flattened_advisedby(a, b, 0.20975771563253554) :-  /* #pos=4 */ 
   professor(b),
   student(a),
   publication(uniqueVar13, a),
   publication(uniqueVar13, b),
   !. // Flattened version of clause #1.

flattened_advisedby(a, b, 0.40224917676249355) :-  /* #pos=3 */ 
   professor(b),
   student(a),
   ta(uniqueVar14, a, underscore),
   publication(underscore, b),
   ta(uniqueVar14, uniqueVar15, underscore),
   publication(underscore, uniqueVar15),
   !. // Flattened version of clause #2.

flattened_advisedby(a, b, 0.08700446730022045) :-  /* #neg=4 #pos=5 */ 
   professor(b),
   student(a),
   ta(underscore, a, underscore),
   publication(underscore, b),
   !. // Flattened version of clause #3.

flattened_advisedby(a, b, -0.07960255631709001) :-  /* #neg=2 #pos=1 */ 
   professor(b),
   student(a),
   publication(underscore, b),
   !. // Flattened version of clause #4.

flattened_advisedby(a, b, 0.1015094313580335) :-  /* #neg=2 #pos=3 */ 
   professor(b),
   student(a),
   !. // Flattened version of clause #5.

flattened_advisedby(underscore, underscore, -0.07877675473109176) :-  /* #neg=24 */ 
   !. // Flattened version of clause #6.


% The unique flattened literals:
%   publication(uniqueVar13, a)
%   ta(underscore, a, underscore)
%   publication(underscore, b)
%   professor(b)
%   publication(underscore, uniqueVar15)
%   ta(uniqueVar14, a, underscore)
%   ta(uniqueVar14, uniqueVar15, underscore)
%   publication(uniqueVar13, b)
%   student(a)

% Saving model in: train/models/bRDNs/advisedby.model.ckpt
% Time taken to learn 7 trees is 2,503 seconds.

%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.13679320332269854
Set score:0.0025
% Only 48 out of 48 converged.
% Kept 16 of the 16 positive examples.
% Kept 32 of the 32 negative examples.
% Dataset size: 48
Computing probabilities
prob time:7 milliseconds
No hidden examples for : advisedby
Time to build dataset: 8 milliseconds
%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.07221586129198808
Set score:0.0025
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% Have these 7 positive seeds: 4 5 21 24 26 29 36

% The best node found: null

% target           = advisedby(D, E)
%     Score = -Infinity (regressionFit = Infinity, penalties=2.2E-7) for clause:  advisedby(_, _).  [covers 48,0/48,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=1.12E-6) for clause:  advisedby(A, _) :- student(A).  [covers 48,0/48,0 pos, 0,0/0,0 neg]
%     Score = -3,096142 (regressionFit = 3,096140, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- student(A), professor(B).  [covers 24,0/48,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- student(A), professor(B).  [covers 24,0/48,0 pos, 0,0/0,0 neg]

% Expanding node at Level 0 with score = 1,797693e+308.
% Will extend: advisedby(A, B) :- student(A), professor(B).  [covers 24,0/48,0 pos, 0,0/0,0 neg]
% Path: 7;
Comparing variance: 0.12900584967680323 to score=0.0025 #egs=24.0
Comparing variance: -1.1564823173178713E-18 to score=0.0025 #egs=24.0
%   Creating a TRUE-branch interior node with wgtedCountTrueBranchPos = 24,0
%      addToQueueOfTreeStructuredLearningTasks (level=1; score=-0,129006)
%         ILP node to extend: advisedby(A, B) :- student(A), professor(B).  [covers 24,0/48,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 1 and with score = -0,129006) into the LAST position (#1) in the search queue.
%   Creating a FALSE-branch leaf because good enough fit since score < 0.0025

% Time for loop #1: 1 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #1, the best clause found is:
%      advisedby(A, B) :- student(A), professor(B).  [covers 24,0/48,0 pos, 0,0/0,0 neg]
% This clause covers 24 positive examples, of which 24 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- student(A), professor(B).  [covers 24,0/24,0 pos, 0,0/0,0 neg]'
%     Score = -3,096142 (regressionFit = 3,096140, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- student(A), professor(B).  [covers 24,0/24,0 pos, 0,0/0,0 neg]

% Have these 8 positive seeds: 1 9 12 13 16 18 22 23

% The best node found: null
%     Score = -3,069362 (regressionFit = 3,069359, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, A).  [covers 4,0/24,0 pos, 0,0/0,0 neg]
%     Score = -3,069363 (regressionFit = 3,069359, penalties=3.9300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(C, A), publication(C, B).  [covers 4,0/24,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- student(A), professor(B), publication(C, A), publication(C, B).  [covers 4,0/24,0 pos, 0,0/0,0 neg]

% Expanding node at Level 1 with score = -0,129.
% Will extend: advisedby(A, B) :- student(A), professor(B), publication(C, A), publication(C, B).  [covers 4,0/24,0 pos, 0,0/0,0 neg]
% Path: 7;true
Comparing variance: 0.0 to score=0.0025 #egs=4.0
Comparing variance: 0.15346793881287743 to score=0.0025 #egs=20.0
%   Creating a TRUE-branch leaf because wgtedCountTrueBranchPos = 4,0 < 2.1 * minPosCov = 6,3
%   Creating a FALSE-branch interior node with wgtedCountFalseBranchPos = 20,0
%      addToQueueOfTreeStructuredLearningTasks (level=2; score=-0,153468)
%         ILP node to extend: advisedby(A, B) :- student(A), professor(B).  [covers 24,0/24,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 2 and with score = -0,153468) into the LAST position (#1) in the search queue.

% Time for loop #2: 2 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #2, the best clause found is:
%      advisedby(A, B) :- student(A), professor(B), publication(C, A), publication(C, B).  [covers 4,0/24,0 pos, 0,0/0,0 neg]
% This clause covers 4 positive examples, of which 4 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- student(A), professor(B).  [covers 24,0/20,0 pos, 0,0/0,0 neg]'
%     Score = -3,096142 (regressionFit = 3,096140, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- student(A), professor(B).  [covers 20,0/20,0 pos, 0,0/0,0 neg]

% Have these 8 positive seeds: 1 2 3 4 5 8 10 12
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% Consider expanding [#1 of outerLoop #3, bodyLen=2] 'advisedby(A, B) :- student(A), professor(B).  [covers 20,0/20,0 pos, 0,0/0,0 neg]' score=-3.0961424122432777
%  At # nodes expanded = 1, |OPEN| = 0.  Pruned 16 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -3,058101 (regressionFit = 3,058098, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
% Gleaner: New best node found (score = -3,058101): advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,024109 (regressionFit = 3,024106, penalties=3.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
% Gleaner: New best node found (score = -3,024109): advisedby(A, B) :- student(A), professor(B), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _).  [covers 18,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,068972 (regressionFit = 3,068969, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,052497 (regressionFit = 3,052493, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.0200000000000007E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.0200000000000007E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(B, B).  [covers 20,0/20,0 pos, 0,0/0,0 neg]

% Consider expanding [#2 of outerLoop #3, bodyLen=3] 'advisedby(A, B) :- student(A), professor(B), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]' score=-3.024108825755425
%  At # nodes expanded = 2, |OPEN| = 8.  Pruned 26 variant children.  Sending 15 items to OPEN for evaluation and possible insertion.
% Have created 15 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -3,069361 (regressionFit = 3,069356, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), tempadvisedby(_, B).  [covers 10,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,024110 (regressionFit = 3,024106, penalties=4.05E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(C, _, D).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,024110 (regressionFit = 3,024106, penalties=4.260000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, C), ta(_, _, C).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,024110 (regressionFit = 3,024106, penalties=4.150000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,024110 (regressionFit = 3,024106, penalties=4.260000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, _, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,024110 (regressionFit = 3,024106, penalties=4.3600000000000015E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,069363 (regressionFit = 3,069359, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), hasposition(B, _).  [covers 13,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,019214 (regressionFit = 3,019209, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), publication(_, B).  [covers 12,0/20,0 pos, 0,0/0,0 neg]
% Gleaner: New best node found (score = -3,019214): advisedby(A, B) :- student(A), professor(B), ta(_, A, _), publication(_, B).  [covers 12,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,024110 (regressionFit = 3,024106, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), inphase(A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,024110 (regressionFit = 3,024106, penalties=4.250000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), courselevel(C, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,024110 (regressionFit = 3,024106, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), yearsinprogram(A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,033113 (regressionFit = 3,033109, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), projectmember(_, B).  [covers 3,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,024110 (regressionFit = 3,024106, penalties=4.14E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), samecourse(C, C).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,024110 (regressionFit = 3,024106, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), sameperson(A, A).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,024110 (regressionFit = 3,024106, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), sameperson(B, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]

% Consider expanding [#3 of outerLoop #3, bodyLen=3] 'advisedby(A, B) :- student(A), professor(B), projectmember(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]' score=-3.052496532494334
%  At # nodes expanded = 3, |OPEN| = 7.  Pruned 20 variant children.  Sending 10 items to OPEN for evaluation and possible insertion.
% Have created 10 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -3,052498 (regressionFit = 3,052493, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B), tempadvisedby(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,033113 (regressionFit = 3,033109, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B), ta(_, A, _).  [covers 3,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,052498 (regressionFit = 3,052493, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B), hasposition(B, _).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,995819 (regressionFit = 2,995815, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B), publication(_, B).  [covers 3,0/20,0 pos, 0,0/0,0 neg]
% Gleaner: New best node found (score = -2,995819): advisedby(A, B) :- student(A), professor(B), projectmember(_, B), publication(_, B).  [covers 3,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,052498 (regressionFit = 3,052493, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B), inphase(A, _).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,052498 (regressionFit = 3,052493, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B), yearsinprogram(A, _).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,052498 (regressionFit = 3,052493, penalties=4.140000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B), projectmember(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,052497 (regressionFit = 3,052493, penalties=4.03E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(C, B), sameproject(C, C).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,052498 (regressionFit = 3,052493, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B), sameperson(A, A).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,052498 (regressionFit = 3,052493, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B), sameperson(B, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]

% Consider expanding [#4 of outerLoop #3, bodyLen=3] 'advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]' score=-3.058101200028108
%  At # nodes expanded = 4, |OPEN| = 6.  Pruned 34 variant children.  Sending 14 items to OPEN for evaluation and possible insertion.
% Have created 14 valid-on-seeds descendants and have picked up 26 bad extensions.
%     Score = -3,058102 (regressionFit = 3,058098, penalties=3.9300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(C, B), student(C).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,058102 (regressionFit = 3,058098, penalties=4.140000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B), tempadvisedby(_, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,069361 (regressionFit = 3,069356, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B), ta(_, A, _).  [covers 10,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,058102 (regressionFit = 3,058098, penalties=4.250000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(C, B), ta(_, C, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,058102 (regressionFit = 3,058098, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B), hasposition(B, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,039515 (regressionFit = 3,039510, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B), publication(_, B).  [covers 11,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,058102 (regressionFit = 3,058098, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B), inphase(A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,058102 (regressionFit = 3,058098, penalties=4.14E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(C, B), inphase(C, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,058102 (regressionFit = 3,058098, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B), yearsinprogram(A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,058102 (regressionFit = 3,058098, penalties=4.14E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(C, B), yearsinprogram(C, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,052498 (regressionFit = 3,052493, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B), projectmember(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,058102 (regressionFit = 3,058098, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B), sameperson(A, A).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,058102 (regressionFit = 3,058098, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B), sameperson(B, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,058102 (regressionFit = 3,058098, penalties=4.03E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(C, B), sameperson(C, C).  [covers 14,0/20,0 pos, 0,0/0,0 neg]

% Consider expanding [#5 of outerLoop #3, bodyLen=3] 'advisedby(A, B) :- student(A), professor(B), publication(_, B).  [covers 15,0/20,0 pos, 0,0/0,0 neg]' score=-3.0689719266027455
%  At # nodes expanded = 5, |OPEN| = 5.  Pruned 18 variant children.  Sending 10 items to OPEN for evaluation and possible insertion.
% Have created 10 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -3,039515 (regressionFit = 3,039510, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), tempadvisedby(_, B).  [covers 11,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,019214 (regressionFit = 3,019209, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _).  [covers 12,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,068973 (regressionFit = 3,068969, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), hasposition(B, _).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,068973 (regressionFit = 3,068969, penalties=4.040000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(C, B), publication(C, _).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,068973 (regressionFit = 3,068969, penalties=4.140000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), publication(_, B).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,068973 (regressionFit = 3,068969, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), inphase(A, _).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,068973 (regressionFit = 3,068969, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), yearsinprogram(A, _).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,995819 (regressionFit = 2,995815, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), projectmember(_, B).  [covers 3,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,068973 (regressionFit = 3,068969, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), sameperson(A, A).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,068973 (regressionFit = 3,068969, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), sameperson(B, B).  [covers 15,0/20,0 pos, 0,0/0,0 neg]

% Consider expanding [#6 of outerLoop #3, bodyLen=3] 'advisedby(A, B) :- student(A), professor(B), hasposition(B, _).  [covers 18,0/20,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 6, |OPEN| = 4.  Pruned 18 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -3,058102 (regressionFit = 3,058098, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _), tempadvisedby(_, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,069363 (regressionFit = 3,069359, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _), ta(_, A, _).  [covers 13,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.040000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, C), hasposition(_, C).  [covers 18,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,068973 (regressionFit = 3,068969, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _), publication(_, B).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _), inphase(A, _).  [covers 18,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _), yearsinprogram(A, _).  [covers 18,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,052498 (regressionFit = 3,052493, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _), projectmember(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _), sameperson(A, A).  [covers 18,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _), sameperson(B, B).  [covers 18,0/20,0 pos, 0,0/0,0 neg]

% Consider expanding [#7 of outerLoop #3, bodyLen=3] 'advisedby(A, B) :- student(A), professor(B), inphase(A, _).  [covers 20,0/20,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 7, |OPEN| = 3.  Pruned 18 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -3,058102 (regressionFit = 3,058098, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _), tempadvisedby(_, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,024110 (regressionFit = 3,024106, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _), hasposition(B, _).  [covers 18,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,068973 (regressionFit = 3,068969, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _), publication(_, B).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.040000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, C), inphase(_, C).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _), yearsinprogram(A, _).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,052498 (regressionFit = 3,052493, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _), projectmember(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _), sameperson(A, A).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _), sameperson(B, B).  [covers 20,0/20,0 pos, 0,0/0,0 neg]

% Consider expanding [#8 of outerLoop #3, bodyLen=3] 'advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _).  [covers 20,0/20,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 8, |OPEN| = 2.  Pruned 18 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -3,058102 (regressionFit = 3,058098, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _), tempadvisedby(_, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,024110 (regressionFit = 3,024106, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _), hasposition(B, _).  [covers 18,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,068973 (regressionFit = 3,068969, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _), publication(_, B).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _), inphase(A, _).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.040000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, C), yearsinprogram(_, C).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,052498 (regressionFit = 3,052493, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _), projectmember(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _), sameperson(A, A).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _), sameperson(B, B).  [covers 20,0/20,0 pos, 0,0/0,0 neg]

% Consider expanding [#9 of outerLoop #3, bodyLen=3] 'advisedby(A, B) :- student(A), professor(B), sameperson(A, A).  [covers 20,0/20,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 9, |OPEN| = 1.  Pruned 14 variant children.  Sending 8 items to OPEN for evaluation and possible insertion.
% Have created 8 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -3,058102 (regressionFit = 3,058098, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A), tempadvisedby(_, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,024110 (regressionFit = 3,024106, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A), hasposition(B, _).  [covers 18,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,068973 (regressionFit = 3,068969, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A), publication(_, B).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A), inphase(A, _).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A), yearsinprogram(A, _).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,052498 (regressionFit = 3,052493, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A), projectmember(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.920000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A), sameperson(B, B).  [covers 20,0/20,0 pos, 0,0/0,0 neg]

***** Warning: #9 TOO MANY NODES CONSIDERED (i.e., 'expanded') for 'LearnOneClause': nodesConsidered = 10 and maxNodesToConsider = 10. *****


% The best node found: advisedby(A, B) :- student(A), professor(B), projectmember(_, B), publication(_, B).  [covers 3,0/20,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- student(A), professor(B), projectmember(_, B), publication(_, B).  [covers 3,0/20,0 pos, 0,0/0,0 neg]

% Expanding node at Level 2 with score = -0,153.
% Will extend: advisedby(A, B) :- student(A), professor(B), projectmember(_, B), publication(_, B).  [covers 3,0/20,0 pos, 0,0/0,0 neg]
% Path: 7;true,false
Comparing variance: 0.17184970300611838 to score=0.0025 #egs=3.0
Comparing variance: 0.1458979760718337 to score=0.0025 #egs=17.0
%   Creating a TRUE-branch leaf because wgtedCountTrueBranchPos = 3,0 < 2.1 * minPosCov = 6,3
%   Creating a FALSE-branch interior node with wgtedCountFalseBranchPos = 17,0
%      addToQueueOfTreeStructuredLearningTasks (level=3; score=-0,145898)
%         ILP node to extend: advisedby(A, B) :- student(A), professor(B).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 3 and with score = -0,145898) into the LAST position (#1) in the search queue.

% Time for loop #3: 57 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #3, the best clause found is:
%      advisedby(A, B) :- student(A), professor(B), projectmember(_, B), publication(_, B).  [covers 3,0/20,0 pos, 0,0/0,0 neg]
% This clause covers 3 positive examples, of which 3 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- student(A), professor(B).  [covers 20,0/17,0 pos, 0,0/0,0 neg]'
%     Score = -3,096142 (regressionFit = 3,096140, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- student(A), professor(B).  [covers 17,0/17,0 pos, 0,0/0,0 neg]

% Have these 8 positive seeds: 3 5 6 7 8 10 12 14
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% Consider expanding [#1 of outerLoop #4, bodyLen=2] 'advisedby(A, B) :- student(A), professor(B).  [covers 17,0/17,0 pos, 0,0/0,0 neg]' score=-3.0961424122432777
%  At # nodes expanded = 1, |OPEN| = 0.  Pruned 16 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 28 bad extensions.
%     Score = -2,479193 (regressionFit = 2,479190, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B).  [covers 11,0/17,0 pos, 0,0/0,0 neg]
% Gleaner: New best node found (score = -2,479193): advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B).  [covers 11,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,451767 (regressionFit = 2,451764, penalties=3.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _).  [covers 12,0/17,0 pos, 0,0/0,0 neg]
% Gleaner: New best node found (score = -2,451767): advisedby(A, B) :- student(A), professor(B), ta(_, A, _).  [covers 12,0/17,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _).  [covers 15,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,478018 (regressionFit = 2,478015, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B).  [covers 12,0/17,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _).  [covers 17,0/17,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _).  [covers 17,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,476955 (regressionFit = 2,476951, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B).  [covers 3,0/17,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.0200000000000007E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A).  [covers 17,0/17,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.0200000000000007E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(B, B).  [covers 17,0/17,0 pos, 0,0/0,0 neg]

% Consider expanding [#2 of outerLoop #4, bodyLen=3] 'advisedby(A, B) :- student(A), professor(B), ta(_, A, _).  [covers 12,0/17,0 pos, 0,0/0,0 neg]' score=-2.45176710174755
%  At # nodes expanded = 2, |OPEN| = 8.  Pruned 26 variant children.  Sending 14 items to OPEN for evaluation and possible insertion.
% Have created 14 valid-on-seeds descendants and have picked up 15 bad extensions.
%     Score = -2,480227 (regressionFit = 2,480223, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), tempadvisedby(_, B).  [covers 8,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,451768 (regressionFit = 2,451764, penalties=4.05E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(C, _, D).  [covers 12,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,451768 (regressionFit = 2,451764, penalties=4.260000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, C), ta(_, _, C).  [covers 12,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,451768 (regressionFit = 2,451764, penalties=4.150000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, A, _).  [covers 12,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,451768 (regressionFit = 2,451764, penalties=4.260000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, _, _).  [covers 12,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,451768 (regressionFit = 2,451764, penalties=4.3600000000000015E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), ta(_, A, _).  [covers 12,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,478041 (regressionFit = 2,478037, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), hasposition(B, _).  [covers 11,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,404523 (regressionFit = 2,404519, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), publication(_, B).  [covers 10,0/17,0 pos, 0,0/0,0 neg]
% Gleaner: New best node found (score = -2,404523): advisedby(A, B) :- student(A), professor(B), ta(_, A, _), publication(_, B).  [covers 10,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,451768 (regressionFit = 2,451764, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), inphase(A, _).  [covers 12,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,451768 (regressionFit = 2,451764, penalties=4.250000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), courselevel(C, _).  [covers 12,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,451768 (regressionFit = 2,451764, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), yearsinprogram(A, _).  [covers 12,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,451768 (regressionFit = 2,451764, penalties=4.14E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), samecourse(C, C).  [covers 12,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,451768 (regressionFit = 2,451764, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), sameperson(A, A).  [covers 12,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,451768 (regressionFit = 2,451764, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), sameperson(B, B).  [covers 12,0/17,0 pos, 0,0/0,0 neg]

% Consider expanding [#3 of outerLoop #4, bodyLen=3] 'advisedby(A, B) :- student(A), professor(B), projectmember(_, B).  [covers 3,0/17,0 pos, 0,0/0,0 neg]' score=-2.476954603568602
%  At # nodes expanded = 3, |OPEN| = 7.  Pruned 20 variant children.  Sending 8 items to OPEN for evaluation and possible insertion.
% Have created 8 valid-on-seeds descendants and have picked up 16 bad extensions.
%     Score = -2,476956 (regressionFit = 2,476951, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B), tempadvisedby(_, B).  [covers 3,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,476956 (regressionFit = 2,476951, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B), hasposition(B, _).  [covers 3,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,476956 (regressionFit = 2,476951, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B), inphase(A, _).  [covers 3,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,476956 (regressionFit = 2,476951, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B), yearsinprogram(A, _).  [covers 3,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,476956 (regressionFit = 2,476951, penalties=4.140000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B), projectmember(_, B).  [covers 3,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,476956 (regressionFit = 2,476951, penalties=4.03E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(C, B), sameproject(C, C).  [covers 3,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,476956 (regressionFit = 2,476951, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B), sameperson(A, A).  [covers 3,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,476956 (regressionFit = 2,476951, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B), sameperson(B, B).  [covers 3,0/17,0 pos, 0,0/0,0 neg]

% Consider expanding [#4 of outerLoop #4, bodyLen=3] 'advisedby(A, B) :- student(A), professor(B), publication(_, B).  [covers 12,0/17,0 pos, 0,0/0,0 neg]' score=-2.4780179936456865
%  At # nodes expanded = 4, |OPEN| = 6.  Pruned 18 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 15 bad extensions.
%     Score = -2,474589 (regressionFit = 2,474584, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), tempadvisedby(_, B).  [covers 8,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,404523 (regressionFit = 2,404519, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _).  [covers 10,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,478019 (regressionFit = 2,478015, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), hasposition(B, _).  [covers 12,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,478019 (regressionFit = 2,478015, penalties=4.040000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(C, B), publication(C, _).  [covers 12,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,478019 (regressionFit = 2,478015, penalties=4.140000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), publication(_, B).  [covers 12,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,478019 (regressionFit = 2,478015, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), inphase(A, _).  [covers 12,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,478019 (regressionFit = 2,478015, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), yearsinprogram(A, _).  [covers 12,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,478019 (regressionFit = 2,478015, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), sameperson(A, A).  [covers 12,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,478019 (regressionFit = 2,478015, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), sameperson(B, B).  [covers 12,0/17,0 pos, 0,0/0,0 neg]

% Consider expanding [#5 of outerLoop #4, bodyLen=3] 'advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B).  [covers 11,0/17,0 pos, 0,0/0,0 neg]' score=-2.479192792826519
%  At # nodes expanded = 5, |OPEN| = 5.  Pruned 34 variant children.  Sending 13 items to OPEN for evaluation and possible insertion.
% Have created 13 valid-on-seeds descendants and have picked up 26 bad extensions.
%     Score = -2,479194 (regressionFit = 2,479190, penalties=3.9300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(C, B), student(C).  [covers 11,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,480227 (regressionFit = 2,480223, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B), ta(_, A, _).  [covers 8,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,479194 (regressionFit = 2,479190, penalties=4.250000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(C, B), ta(_, C, _).  [covers 11,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,479194 (regressionFit = 2,479190, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B), hasposition(B, _).  [covers 11,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,474589 (regressionFit = 2,474584, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B), publication(_, B).  [covers 8,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,479194 (regressionFit = 2,479190, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B), inphase(A, _).  [covers 11,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,479194 (regressionFit = 2,479190, penalties=4.14E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(C, B), inphase(C, _).  [covers 11,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,479194 (regressionFit = 2,479190, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B), yearsinprogram(A, _).  [covers 11,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,479194 (regressionFit = 2,479190, penalties=4.14E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(C, B), yearsinprogram(C, _).  [covers 11,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,476956 (regressionFit = 2,476951, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B), projectmember(_, B).  [covers 3,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,479194 (regressionFit = 2,479190, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B), sameperson(A, A).  [covers 11,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,479194 (regressionFit = 2,479190, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B), sameperson(B, B).  [covers 11,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,479194 (regressionFit = 2,479190, penalties=4.03E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(C, B), sameperson(C, C).  [covers 11,0/17,0 pos, 0,0/0,0 neg]

% Consider expanding [#6 of outerLoop #4, bodyLen=3] 'advisedby(A, B) :- student(A), professor(B), hasposition(B, _).  [covers 15,0/17,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 6, |OPEN| = 4.  Pruned 18 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -2,479194 (regressionFit = 2,479190, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _), tempadvisedby(_, B).  [covers 11,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,478041 (regressionFit = 2,478037, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _), ta(_, A, _).  [covers 11,0/17,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.040000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, C), hasposition(_, C).  [covers 15,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,478019 (regressionFit = 2,478015, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _), publication(_, B).  [covers 12,0/17,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _), inphase(A, _).  [covers 15,0/17,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _), yearsinprogram(A, _).  [covers 15,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,476956 (regressionFit = 2,476951, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _), projectmember(_, B).  [covers 3,0/17,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _), sameperson(A, A).  [covers 15,0/17,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _), sameperson(B, B).  [covers 15,0/17,0 pos, 0,0/0,0 neg]

% Consider expanding [#7 of outerLoop #4, bodyLen=3] 'advisedby(A, B) :- student(A), professor(B), inphase(A, _).  [covers 17,0/17,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 7, |OPEN| = 3.  Pruned 18 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -2,479194 (regressionFit = 2,479190, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _), tempadvisedby(_, B).  [covers 11,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,451768 (regressionFit = 2,451764, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _), ta(_, A, _).  [covers 12,0/17,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _), hasposition(B, _).  [covers 15,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,478019 (regressionFit = 2,478015, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _), publication(_, B).  [covers 12,0/17,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.040000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, C), inphase(_, C).  [covers 17,0/17,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _), yearsinprogram(A, _).  [covers 17,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,476956 (regressionFit = 2,476951, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _), projectmember(_, B).  [covers 3,0/17,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _), sameperson(A, A).  [covers 17,0/17,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _), sameperson(B, B).  [covers 17,0/17,0 pos, 0,0/0,0 neg]

% Consider expanding [#8 of outerLoop #4, bodyLen=3] 'advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _).  [covers 17,0/17,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 8, |OPEN| = 2.  Pruned 18 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -2,479194 (regressionFit = 2,479190, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _), tempadvisedby(_, B).  [covers 11,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,451768 (regressionFit = 2,451764, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _), ta(_, A, _).  [covers 12,0/17,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _), hasposition(B, _).  [covers 15,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,478019 (regressionFit = 2,478015, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _), publication(_, B).  [covers 12,0/17,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _), inphase(A, _).  [covers 17,0/17,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.040000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, C), yearsinprogram(_, C).  [covers 17,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,476956 (regressionFit = 2,476951, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _), projectmember(_, B).  [covers 3,0/17,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _), sameperson(A, A).  [covers 17,0/17,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _), sameperson(B, B).  [covers 17,0/17,0 pos, 0,0/0,0 neg]

% Consider expanding [#9 of outerLoop #4, bodyLen=3] 'advisedby(A, B) :- student(A), professor(B), sameperson(A, A).  [covers 17,0/17,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 9, |OPEN| = 1.  Pruned 14 variant children.  Sending 8 items to OPEN for evaluation and possible insertion.
% Have created 8 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -2,479194 (regressionFit = 2,479190, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A), tempadvisedby(_, B).  [covers 11,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,451768 (regressionFit = 2,451764, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A), ta(_, A, _).  [covers 12,0/17,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A), hasposition(B, _).  [covers 15,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,478019 (regressionFit = 2,478015, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A), publication(_, B).  [covers 12,0/17,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A), inphase(A, _).  [covers 17,0/17,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A), yearsinprogram(A, _).  [covers 17,0/17,0 pos, 0,0/0,0 neg]
%     Score = -2,476956 (regressionFit = 2,476951, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A), projectmember(_, B).  [covers 3,0/17,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.920000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A), sameperson(B, B).  [covers 17,0/17,0 pos, 0,0/0,0 neg]

***** Warning: #10 TOO MANY NODES CONSIDERED (i.e., 'expanded') for 'LearnOneClause': nodesConsidered = 10 and maxNodesToConsider = 10. *****


% The best node found: advisedby(A, B) :- student(A), professor(B), ta(_, A, _), publication(_, B).  [covers 10,0/17,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- student(A), professor(B), ta(_, A, _), publication(_, B).  [covers 10,0/17,0 pos, 0,0/0,0 neg]

% Expanding node at Level 3 with score = -0,146.
% Will extend: advisedby(A, B) :- student(A), professor(B), ta(_, A, _), publication(_, B).  [covers 10,0/17,0 pos, 0,0/0,0 neg]
% Path: 7;true,false,false
Comparing variance: 0.14363048550083748 to score=0.0025 #egs=10.0
Comparing variance: 0.1383163164266432 to score=0.0025 #egs=7.0
%   Creating a TRUE-branch and FALSE-branch leaves because level = 3 >= 3

% Time for loop #4: 51 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #4, the best clause found is:
%      advisedby(A, B) :- student(A), professor(B), ta(_, A, _), publication(_, B).  [covers 10,0/17,0 pos, 0,0/0,0 neg]
% This clause covers 10 positive examples, of which 10 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% ******************************************

%  Have stopped ILP's outer loop because the tree-structured queue is empty.

% ******************************************

%%%%%  WILL-Produced Tree #8 @ 17:27:16 5/29/21.  [Using 4.443.672 memory cells.]  %%%%%


% FOR advisedby(A, B):
%   if ( student(A), professor(B) )
%   then if ( publication(C, A), publication(C, B) )
%   | then return 0.17709649774527736;  // std dev = 0,000, 4,000 (wgt'ed) examples reached here.  /* #pos=4 */
%   | else if ( projectmember(D, B), publication(E, B) )
%   | | then return 0.2318131675901743;  // std dev = 0,718, 3,000 (wgt'ed) examples reached here.  /* #neg=1 #pos=2 */
%   | | else if ( ta(F, A, G), publication(H, B) )
%   | | | then return 0.1178351148153443;  // std dev = 1,198, 10,000 (wgt'ed) examples reached here.  /* #neg=3 #pos=7 */
%   | | | else return -0.0177952070603352;  // std dev = 0,984, 7,000 (wgt'ed) examples reached here.  /* #neg=4 #pos=3 */
%   else return -0.07324622576333704;  // std dev = 0,000, 24,000 (wgt'ed) examples reached here.  /* #neg=24 */


% Clauses:

advisedby(A, B, 0.17709649774527736) :- 
     student(A), 
     professor(B), 
     publication(C, A), 
     publication(C, B), 
     !. // Clause #1.

advisedby(A, B, 0.2318131675901743) :- 
     student(A), 
     professor(B), 
     projectmember(C, B), 
     publication(D, B), 
     !. // Clause #2.

advisedby(A, B, 0.1178351148153443) :- 
     student(A), 
     professor(B), 
     ta(C, A, D), 
     publication(E, B), 
     !. // Clause #3.

advisedby(A, B, -0.0177952070603352) :- 
     student(A), 
     professor(B), 
     !. // Clause #4.

advisedby(A, B, -0.07324622576333704) :- !. // Clause #5.


% The flattened versions of these clauses:

flattened_advisedby(a, b, 0.17709649774527736) :-  /* #pos=4 */ 
   student(a),
   professor(b),
   publication(uniqueVar16, a),
   publication(uniqueVar16, b),
   !. // Flattened version of clause #1.

flattened_advisedby(a, b, 0.2318131675901743) :-  /* #neg=1 #pos=2 */ 
   student(a),
   professor(b),
   projectmember(underscore, b),
   publication(underscore, b),
   !. // Flattened version of clause #2.

flattened_advisedby(a, b, 0.1178351148153443) :-  /* #neg=3 #pos=7 */ 
   student(a),
   professor(b),
   ta(underscore, a, underscore),
   publication(underscore, b),
   !. // Flattened version of clause #3.

flattened_advisedby(a, b, -0.0177952070603352) :-  /* #neg=4 #pos=3 */ 
   student(a),
   professor(b),
   !. // Flattened version of clause #4.

flattened_advisedby(underscore, underscore, -0.07324622576333704) :-  /* #neg=24 */ 
   !. // Flattened version of clause #5.


% The unique flattened literals:
%   ta(underscore, a, underscore)
%   publication(underscore, b)
%   professor(b)
%   publication(uniqueVar16, a)
%   projectmember(underscore, b)
%   student(a)
%   publication(uniqueVar16, b)

% Saving model in: train/models/bRDNs/advisedby.model.ckpt
% Time taken to learn 8 trees is 2,668 seconds.

%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.1458979760718337
Set score:0.0025
% Only 48 out of 48 converged.
% Kept 16 of the 16 positive examples.
% Kept 32 of the 32 negative examples.
% Dataset size: 48
Computing probabilities
prob time:7 milliseconds
No hidden examples for : advisedby
Time to build dataset: 8 milliseconds
%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.06905160863161192
Set score:0.0025
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% Have these 5 positive seeds: 9 20 27 40 44

% The best node found: null

% target           = advisedby(D, E)
%     Score = -Infinity (regressionFit = Infinity, penalties=2.2E-7) for clause:  advisedby(_, _).  [covers 48,0/48,0 pos, 0,0/0,0 neg]
%     Score = -3,043476 (regressionFit = 3,043475, penalties=1.12E-6) for clause:  advisedby(_, A) :- professor(A).  [covers 24,0/48,0 pos, 0,0/0,0 neg]
%     Score = -3,043477 (regressionFit = 3,043475, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- professor(B), student(A).  [covers 24,0/48,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- professor(B), student(A).  [covers 24,0/48,0 pos, 0,0/0,0 neg]

% Expanding node at Level 0 with score = 1,797693e+308.
% Will extend: advisedby(A, B) :- professor(B), student(A).  [covers 24,0/48,0 pos, 0,0/0,0 neg]
% Path: 8;
Comparing variance: 0.12681145191792112 to score=0.0025 #egs=24.0
Comparing variance: -4.625929269271485E-18 to score=0.0025 #egs=24.0
%   Creating a TRUE-branch interior node with wgtedCountTrueBranchPos = 24,0
%      addToQueueOfTreeStructuredLearningTasks (level=1; score=-0,126811)
%         ILP node to extend: advisedby(A, B) :- professor(B), student(A).  [covers 24,0/48,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 1 and with score = -0,126811) into the LAST position (#1) in the search queue.
%   Creating a FALSE-branch leaf because good enough fit since score < 0.0025

% Time for loop #1: 2 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #1, the best clause found is:
%      advisedby(A, B) :- professor(B), student(A).  [covers 24,0/48,0 pos, 0,0/0,0 neg]
% This clause covers 24 positive examples, of which 24 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- professor(B), student(A).  [covers 24,0/24,0 pos, 0,0/0,0 neg]'
%     Score = -3,043477 (regressionFit = 3,043475, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- professor(B), student(A).  [covers 24,0/24,0 pos, 0,0/0,0 neg]

% Have these 8 positive seeds: 0 1 3 6 8 9 14 15

% The best node found: null
%     Score = -3,019354 (regressionFit = 3,019351, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, A).  [covers 4,0/24,0 pos, 0,0/0,0 neg]
%     Score = -3,019355 (regressionFit = 3,019351, penalties=3.9300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(C, A), publication(C, B).  [covers 4,0/24,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- professor(B), student(A), publication(C, A), publication(C, B).  [covers 4,0/24,0 pos, 0,0/0,0 neg]

% Expanding node at Level 1 with score = -0,127.
% Will extend: advisedby(A, B) :- professor(B), student(A), publication(C, A), publication(C, B).  [covers 4,0/24,0 pos, 0,0/0,0 neg]
% Path: 8;true
Comparing variance: 0.0 to score=0.0025 #egs=4.0
Comparing variance: 0.15096755774316548 to score=0.0025 #egs=20.0
%   Creating a TRUE-branch leaf because wgtedCountTrueBranchPos = 4,0 < 2.1 * minPosCov = 6,3
%   Creating a FALSE-branch interior node with wgtedCountFalseBranchPos = 20,0
%      addToQueueOfTreeStructuredLearningTasks (level=2; score=-0,150968)
%         ILP node to extend: advisedby(A, B) :- professor(B), student(A).  [covers 24,0/24,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 2 and with score = -0,150968) into the LAST position (#1) in the search queue.

% Time for loop #2: 2 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #2, the best clause found is:
%      advisedby(A, B) :- professor(B), student(A), publication(C, A), publication(C, B).  [covers 4,0/24,0 pos, 0,0/0,0 neg]
% This clause covers 4 positive examples, of which 4 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- professor(B), student(A).  [covers 24,0/20,0 pos, 0,0/0,0 neg]'
%     Score = -3,043477 (regressionFit = 3,043475, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- professor(B), student(A).  [covers 20,0/20,0 pos, 0,0/0,0 neg]

% Have these 8 positive seeds: 0 1 6 7 9 10 11 14
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% Consider expanding [#1 of outerLoop #3, bodyLen=2] 'advisedby(A, B) :- professor(B), student(A).  [covers 20,0/20,0 pos, 0,0/0,0 neg]' score=-3.0434768660301073
%  At # nodes expanded = 1, |OPEN| = 0.  Pruned 16 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -3,012502 (regressionFit = 3,012499, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
% Gleaner: New best node found (score = -3,012502): advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,954265 (regressionFit = 2,954261, penalties=3.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
% Gleaner: New best node found (score = -2,954265): advisedby(A, B) :- professor(B), student(A), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _).  [covers 18,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,017659 (regressionFit = 3,017656, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,005435 (regressionFit = 3,005432, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.0200000000000007E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.0200000000000007E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(B, B).  [covers 20,0/20,0 pos, 0,0/0,0 neg]

% Consider expanding [#2 of outerLoop #3, bodyLen=3] 'advisedby(A, B) :- professor(B), student(A), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]' score=-2.9542647193953444
%  At # nodes expanded = 2, |OPEN| = 8.  Pruned 26 variant children.  Sending 14 items to OPEN for evaluation and possible insertion.
% Have created 14 valid-on-seeds descendants and have picked up 15 bad extensions.
%     Score = -3,017695 (regressionFit = 3,017690, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), tempadvisedby(_, B).  [covers 10,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,954266 (regressionFit = 2,954261, penalties=4.05E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), ta(C, _, D).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,954266 (regressionFit = 2,954261, penalties=4.260000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), ta(_, _, C).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,954266 (regressionFit = 2,954261, penalties=4.150000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,954266 (regressionFit = 2,954261, penalties=4.260000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, _, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,954266 (regressionFit = 2,954261, penalties=4.3600000000000015E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,016647 (regressionFit = 3,016643, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), hasposition(B, _).  [covers 13,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,992973 (regressionFit = 2,992969, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B).  [covers 12,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,954266 (regressionFit = 2,954261, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), inphase(A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,954266 (regressionFit = 2,954261, penalties=4.250000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), courselevel(C, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,954266 (regressionFit = 2,954261, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), yearsinprogram(A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,954266 (regressionFit = 2,954261, penalties=4.14E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), samecourse(C, C).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,954266 (regressionFit = 2,954261, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), sameperson(A, A).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,954266 (regressionFit = 2,954261, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), sameperson(B, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]

% Consider expanding [#3 of outerLoop #3, bodyLen=3] 'advisedby(A, B) :- professor(B), student(A), projectmember(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]' score=-3.005435384742703
%  At # nodes expanded = 3, |OPEN| = 7.  Pruned 20 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 15 bad extensions.
%     Score = -3,005436 (regressionFit = 3,005432, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), tempadvisedby(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,005436 (regressionFit = 3,005432, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), hasposition(B, _).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,974459 (regressionFit = 2,974455, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), publication(_, B).  [covers 3,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,005436 (regressionFit = 3,005432, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), inphase(A, _).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,005436 (regressionFit = 3,005432, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), yearsinprogram(A, _).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,005436 (regressionFit = 3,005432, penalties=4.140000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), projectmember(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,005436 (regressionFit = 3,005432, penalties=4.03E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(C, B), sameproject(C, C).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,005436 (regressionFit = 3,005432, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), sameperson(A, A).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,005436 (regressionFit = 3,005432, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), projectmember(_, B), sameperson(B, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]

% Consider expanding [#4 of outerLoop #3, bodyLen=3] 'advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]' score=-3.0125023790013628
%  At # nodes expanded = 4, |OPEN| = 6.  Pruned 34 variant children.  Sending 14 items to OPEN for evaluation and possible insertion.
% Have created 14 valid-on-seeds descendants and have picked up 26 bad extensions.
%     Score = -3,012503 (regressionFit = 3,012499, penalties=3.9300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(C, B), student(C).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,012503 (regressionFit = 3,012499, penalties=4.140000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B), tempadvisedby(_, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,017695 (regressionFit = 3,017690, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B), ta(_, A, _).  [covers 10,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,012503 (regressionFit = 3,012499, penalties=4.250000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(C, B), ta(_, C, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,012503 (regressionFit = 3,012499, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B), hasposition(B, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,005038 (regressionFit = 3,005034, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B), publication(_, B).  [covers 11,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,012503 (regressionFit = 3,012499, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B), inphase(A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,012503 (regressionFit = 3,012499, penalties=4.14E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(C, B), inphase(C, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,012503 (regressionFit = 3,012499, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B), yearsinprogram(A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,012503 (regressionFit = 3,012499, penalties=4.14E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(C, B), yearsinprogram(C, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,005436 (regressionFit = 3,005432, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B), projectmember(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,012503 (regressionFit = 3,012499, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B), sameperson(A, A).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,012503 (regressionFit = 3,012499, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, B), sameperson(B, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,012503 (regressionFit = 3,012499, penalties=4.03E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(C, B), sameperson(C, C).  [covers 14,0/20,0 pos, 0,0/0,0 neg]

% Consider expanding [#5 of outerLoop #3, bodyLen=3] 'advisedby(A, B) :- professor(B), student(A), publication(_, B).  [covers 15,0/20,0 pos, 0,0/0,0 neg]' score=-3.0176593076954856
%  At # nodes expanded = 5, |OPEN| = 5.  Pruned 18 variant children.  Sending 10 items to OPEN for evaluation and possible insertion.
% Have created 10 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -3,005038 (regressionFit = 3,005034, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B), tempadvisedby(_, B).  [covers 11,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,992973 (regressionFit = 2,992969, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B), ta(_, A, _).  [covers 12,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,017660 (regressionFit = 3,017656, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B), hasposition(B, _).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,017660 (regressionFit = 3,017656, penalties=4.040000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(C, B), publication(C, _).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,017660 (regressionFit = 3,017656, penalties=4.140000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B), publication(_, B).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,017660 (regressionFit = 3,017656, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B), inphase(A, _).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,017660 (regressionFit = 3,017656, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B), yearsinprogram(A, _).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,974459 (regressionFit = 2,974455, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B), projectmember(_, B).  [covers 3,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,017660 (regressionFit = 3,017656, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B), sameperson(A, A).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,017660 (regressionFit = 3,017656, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), publication(_, B), sameperson(B, B).  [covers 15,0/20,0 pos, 0,0/0,0 neg]

% Consider expanding [#6 of outerLoop #3, bodyLen=3] 'advisedby(A, B) :- professor(B), student(A), hasposition(B, _).  [covers 18,0/20,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 6, |OPEN| = 4.  Pruned 18 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -3,012503 (regressionFit = 3,012499, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _), tempadvisedby(_, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,016647 (regressionFit = 3,016643, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _), ta(_, A, _).  [covers 13,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.040000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, C), hasposition(_, C).  [covers 18,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,017660 (regressionFit = 3,017656, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _), publication(_, B).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _), inphase(A, _).  [covers 18,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _), yearsinprogram(A, _).  [covers 18,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,005436 (regressionFit = 3,005432, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _), projectmember(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _), sameperson(A, A).  [covers 18,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), hasposition(B, _), sameperson(B, B).  [covers 18,0/20,0 pos, 0,0/0,0 neg]

% Consider expanding [#7 of outerLoop #3, bodyLen=3] 'advisedby(A, B) :- professor(B), student(A), inphase(A, _).  [covers 20,0/20,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 7, |OPEN| = 3.  Pruned 18 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -3,012503 (regressionFit = 3,012499, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _), tempadvisedby(_, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,954266 (regressionFit = 2,954261, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _), hasposition(B, _).  [covers 18,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,017660 (regressionFit = 3,017656, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _), publication(_, B).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.040000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, C), inphase(_, C).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _), yearsinprogram(A, _).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,005436 (regressionFit = 3,005432, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _), projectmember(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _), sameperson(A, A).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), inphase(A, _), sameperson(B, B).  [covers 20,0/20,0 pos, 0,0/0,0 neg]

% Consider expanding [#8 of outerLoop #3, bodyLen=3] 'advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _).  [covers 20,0/20,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 8, |OPEN| = 2.  Pruned 18 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -3,012503 (regressionFit = 3,012499, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _), tempadvisedby(_, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,954266 (regressionFit = 2,954261, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _), hasposition(B, _).  [covers 18,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,017660 (regressionFit = 3,017656, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _), publication(_, B).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _), inphase(A, _).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.040000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, C), yearsinprogram(_, C).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,005436 (regressionFit = 3,005432, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _), projectmember(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _), sameperson(A, A).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), yearsinprogram(A, _), sameperson(B, B).  [covers 20,0/20,0 pos, 0,0/0,0 neg]

% Consider expanding [#9 of outerLoop #3, bodyLen=3] 'advisedby(A, B) :- professor(B), student(A), sameperson(A, A).  [covers 20,0/20,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 9, |OPEN| = 1.  Pruned 14 variant children.  Sending 8 items to OPEN for evaluation and possible insertion.
% Have created 8 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -3,012503 (regressionFit = 3,012499, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A), tempadvisedby(_, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,954266 (regressionFit = 2,954261, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A), hasposition(B, _).  [covers 18,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,017660 (regressionFit = 3,017656, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A), publication(_, B).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A), inphase(A, _).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A), yearsinprogram(A, _).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -3,005436 (regressionFit = 3,005432, penalties=4.13E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A), projectmember(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.920000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), sameperson(A, A), sameperson(B, B).  [covers 20,0/20,0 pos, 0,0/0,0 neg]

***** Warning: #11 TOO MANY NODES CONSIDERED (i.e., 'expanded') for 'LearnOneClause': nodesConsidered = 10 and maxNodesToConsider = 10. *****


% The best node found: advisedby(A, B) :- professor(B), student(A), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- professor(B), student(A), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]

% Expanding node at Level 2 with score = -0,151.
% Will extend: advisedby(A, B) :- professor(B), student(A), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
% Path: 8;true,false
Comparing variance: 0.16613012467026195 to score=0.0025 #egs=14.0
Comparing variance: 0.1047399556686129 to score=0.0025 #egs=6.0
%   Creating a TRUE-branch interior node with wgtedCountTrueBranchPos = 14,0
%      addToQueueOfTreeStructuredLearningTasks (level=3; score=-0,166130)
%         ILP node to extend: advisedby(A, B) :- professor(B), student(A), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 3 and with score = -0,166130) into the LAST position (#1) in the search queue.
%   Creating a FALSE-branch leaf because wgtedCountFalseBranchPos = 6,0 < 2.1 * minPosCov = 6,3

% Time for loop #3: 57 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #3, the best clause found is:
%      advisedby(A, B) :- professor(B), student(A), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
% This clause covers 14 positive examples, of which 14 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- professor(B), student(A), ta(_, A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]'
%     Score = -2,954265 (regressionFit = 2,954261, penalties=3.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]

% Have these 7 positive seeds: 1 2 3 6 7 9 12
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% Consider expanding [#1 of outerLoop #4, bodyLen=3] 'advisedby(A, B) :- professor(B), student(A), ta(_, A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]' score=-2.9542647193953444
%  At # nodes expanded = 1, |OPEN| = 0.  Pruned 26 variant children.  Sending 14 items to OPEN for evaluation and possible insertion.
% Have created 14 valid-on-seeds descendants and have picked up 29 bad extensions.
%     Score = -2,297926 (regressionFit = 2,297921, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), tempadvisedby(_, B).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
% Gleaner: New best node found (score = -2,297926): advisedby(A, B) :- professor(B), student(A), ta(_, A, _), tempadvisedby(_, B).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.260000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), ta(_, _, C).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.150000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.260000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, _, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.3600000000000015E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), ta(_, A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), hasposition(B, _).  [covers 13,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B).  [covers 12,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), inphase(A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.250000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), courselevel(C, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), yearsinprogram(A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,302793 (regressionFit = 2,302789, penalties=4.35E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), projectmember(_, B).  [covers 3,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.14E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), samecourse(C, C).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), sameperson(A, A).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), sameperson(B, B).  [covers 14,0/14,0 pos, 0,0/0,0 neg]

% Consider expanding [#2 of outerLoop #4, bodyLen=4] 'advisedby(A, B) :- professor(B), student(A), ta(_, A, _), tempadvisedby(_, B).  [covers 10,0/14,0 pos, 0,0/0,0 neg]' score=-2.2979255338285816
%  At # nodes expanded = 2, |OPEN| = 13.  Pruned 49 variant children.  Sending 21 items to OPEN for evaluation and possible insertion.
% Have created 21 valid-on-seeds descendants and have picked up 27 bad extensions.
%     Score = -2,297926 (regressionFit = 2,297921, penalties=5.150000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), tempadvisedby(C, B), student(C).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,297927 (regressionFit = 2,297921, penalties=5.360000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), tempadvisedby(_, B), tempadvisedby(_, B).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.160000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), tempadvisedby(D, B), ta(_, D, C).  [covers 2,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,297927 (regressionFit = 2,297921, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), tempadvisedby(_, B), ta(_, _, C).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,297926 (regressionFit = 2,297921, penalties=5.2600000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), tempadvisedby(_, B), ta(C, A, _).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.160000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), tempadvisedby(D, B), ta(C, D, _).  [covers 1,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,297927 (regressionFit = 2,297921, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), tempadvisedby(_, B), ta(C, _, _).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,297927 (regressionFit = 2,297921, penalties=5.47E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), tempadvisedby(_, B), ta(_, A, _).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,297927 (regressionFit = 2,297921, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), tempadvisedby(C, B), ta(_, C, _).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,297927 (regressionFit = 2,297921, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), tempadvisedby(_, B), hasposition(B, _).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,168176 (regressionFit = 2,168170, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), tempadvisedby(_, B), publication(_, B).  [covers 9,0/14,0 pos, 0,0/0,0 neg]
% Gleaner: New best node found (score = -2,168176): advisedby(A, B) :- professor(B), student(A), ta(_, A, _), tempadvisedby(_, B), publication(_, B).  [covers 9,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,297927 (regressionFit = 2,297921, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), tempadvisedby(_, B), inphase(A, _).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,297927 (regressionFit = 2,297921, penalties=5.36E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), tempadvisedby(C, B), inphase(C, _).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,297927 (regressionFit = 2,297921, penalties=5.36E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), tempadvisedby(_, B), courselevel(C, _).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,297927 (regressionFit = 2,297921, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), tempadvisedby(_, B), yearsinprogram(A, _).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,297927 (regressionFit = 2,297921, penalties=5.36E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), tempadvisedby(C, B), yearsinprogram(C, _).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,302794 (regressionFit = 2,302789, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), tempadvisedby(_, B), projectmember(_, B).  [covers 3,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,297926 (regressionFit = 2,297921, penalties=5.2500000000000006E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), tempadvisedby(_, B), samecourse(C, C).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,297927 (regressionFit = 2,297921, penalties=5.3500000000000004E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), tempadvisedby(_, B), sameperson(A, A).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,297927 (regressionFit = 2,297921, penalties=5.3500000000000004E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), tempadvisedby(_, B), sameperson(B, B).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,297926 (regressionFit = 2,297921, penalties=5.2500000000000006E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), tempadvisedby(C, B), sameperson(C, C).  [covers 10,0/14,0 pos, 0,0/0,0 neg]

% Consider expanding [#3 of outerLoop #4, bodyLen=4] 'advisedby(A, B) :- professor(B), student(A), ta(_, A, _), projectmember(_, B).  [covers 3,0/14,0 pos, 0,0/0,0 neg]' score=-2.302792886100675
%  At # nodes expanded = 3, |OPEN| = 12.  Pruned 30 variant children.  Sending 14 items to OPEN for evaluation and possible insertion.
% Have created 14 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -2,302794 (regressionFit = 2,302789, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), projectmember(_, B), tempadvisedby(_, B).  [covers 3,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,302794 (regressionFit = 2,302789, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), projectmember(_, B), ta(_, _, C).  [covers 3,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,302794 (regressionFit = 2,302789, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), projectmember(_, B), ta(C, _, _).  [covers 3,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,302794 (regressionFit = 2,302789, penalties=5.47E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), projectmember(_, B), ta(_, A, _).  [covers 3,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,302794 (regressionFit = 2,302789, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), projectmember(_, B), hasposition(B, _).  [covers 3,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), projectmember(_, B), publication(_, B).  [covers 2,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,302794 (regressionFit = 2,302789, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), projectmember(_, B), inphase(A, _).  [covers 3,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,302794 (regressionFit = 2,302789, penalties=5.36E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), projectmember(_, B), courselevel(C, _).  [covers 3,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,302794 (regressionFit = 2,302789, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), projectmember(_, B), yearsinprogram(A, _).  [covers 3,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,302794 (regressionFit = 2,302789, penalties=5.360000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), projectmember(_, B), projectmember(_, B).  [covers 3,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,302794 (regressionFit = 2,302789, penalties=5.2500000000000006E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), projectmember(C, B), sameproject(C, C).  [covers 3,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,302794 (regressionFit = 2,302789, penalties=5.2500000000000006E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), projectmember(_, B), samecourse(C, C).  [covers 3,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,302794 (regressionFit = 2,302789, penalties=5.3500000000000004E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), projectmember(_, B), sameperson(A, A).  [covers 3,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,302794 (regressionFit = 2,302789, penalties=5.3500000000000004E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), projectmember(_, B), sameperson(B, B).  [covers 3,0/14,0 pos, 0,0/0,0 neg]

% Consider expanding [#4 of outerLoop #4, bodyLen=4] 'advisedby(A, B) :- professor(B), student(A), ta(_, A, C), ta(_, _, C).  [covers 14,0/14,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 4, |OPEN| = 11.  Pruned 67 variant children.  Sending 33 items to OPEN for evaluation and possible insertion.
% Have created 33 valid-on-seeds descendants and have picked up 26 bad extensions.
%     Score = -Infinity (regressionFit = Infinity, penalties=5.060000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), ta(_, D, C), student(D).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.160000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), ta(_, D, C), tempadvisedby(D, B).  [covers 2,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.27E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), ta(_, D, C), tempadvisedby(D, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,297927 (regressionFit = 2,297921, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), ta(_, _, C), tempadvisedby(_, B).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.17E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), ta(D, _, C), ta(D, _, C).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.38E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), ta(_, _, C), ta(_, _, C).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.17E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), ta(_, _, D), ta(C, A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.070000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), ta(_, E, D), ta(C, E, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.28E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), ta(_, _, D), ta(C, _, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.17E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), ta(D, _, C), ta(D, A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.070000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), ta(D, E, C), ta(D, E, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.28E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), ta(D, _, C), ta(D, _, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.38E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), ta(_, _, C), ta(_, A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.28E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), ta(_, D, C), ta(_, D, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), ta(_, _, C), hasposition(B, _).  [covers 13,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), ta(_, _, C), publication(_, B).  [covers 12,0/14,0 pos, 0,0/0,0 neg]
%     Score = -1,966348 (regressionFit = 1,966342, penalties=5.27E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), ta(_, D, C), publication(_, D).  [covers 4,0/14,0 pos, 0,0/0,0 neg]
% Gleaner: New best node found (score = -1,966348): advisedby(A, B) :- professor(B), student(A), ta(_, A, C), ta(_, D, C), publication(_, D).  [covers 4,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), ta(_, _, C), inphase(A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.27E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), ta(_, D, C), inphase(D, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.27E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), ta(_, _, D), courselevel(C, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.27E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), ta(D, _, C), courselevel(D, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), ta(_, _, C), yearsinprogram(A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.27E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), ta(_, D, C), yearsinprogram(D, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,302794 (regressionFit = 2,302789, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), ta(_, _, C), projectmember(_, B).  [covers 3,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.160000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), ta(_, _, D), samecourse(C, C).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.060000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), ta(E, _, D), samecourse(C, E).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.060000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), ta(E, _, D), samecourse(E, C).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.160000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), ta(D, _, C), samecourse(D, D).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.2600000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), ta(_, _, C), sameperson(A, A).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.160000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), ta(_, D, C), sameperson(A, D).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.2600000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), ta(_, _, C), sameperson(B, B).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.160000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), ta(_, D, C), sameperson(D, A).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.160000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), ta(_, D, C), sameperson(D, D).  [covers 14,0/14,0 pos, 0,0/0,0 neg]

% Consider expanding [#5 of outerLoop #4, bodyLen=4] 'advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 5, |OPEN| = 10.  Pruned 32 variant children.  Sending 15 items to OPEN for evaluation and possible insertion.
% Have created 15 valid-on-seeds descendants and have picked up 15 bad extensions.
%     Score = -2,297926 (regressionFit = 2,297921, penalties=5.2600000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, A, _), tempadvisedby(_, B).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.17E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), ta(C, A, _), ta(_, _, D).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.17E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, A, D), ta(_, _, D).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.1600000000000006E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, A, _), ta(C, A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.27E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, A, _), ta(C, _, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.27E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, A, _), ta(_, A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.2600000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, A, _), hasposition(B, _).  [covers 13,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.2600000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, A, _), publication(_, B).  [covers 12,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.2600000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, A, _), inphase(A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.2600000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, A, _), courselevel(C, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.2600000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, A, _), yearsinprogram(A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,302794 (regressionFit = 2,302789, penalties=5.2600000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, A, _), projectmember(_, B).  [covers 3,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.150000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, A, _), samecourse(C, C).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.150000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, A, _), sameperson(A, A).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.150000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, A, _), sameperson(B, B).  [covers 14,0/14,0 pos, 0,0/0,0 neg]

% Consider expanding [#6 of outerLoop #4, bodyLen=4] 'advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, _, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 6, |OPEN| = 9.  Pruned 61 variant children.  Sending 28 items to OPEN for evaluation and possible insertion.
% Have created 28 valid-on-seeds descendants and have picked up 27 bad extensions.
%     Score = -Infinity (regressionFit = Infinity, penalties=5.060000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, D, _), student(D).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.160000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, D, _), tempadvisedby(D, B).  [covers 1,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.27E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, D, _), tempadvisedby(D, _).  [covers 13,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,297927 (regressionFit = 2,297921, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, _, _), tempadvisedby(_, B).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.17E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, _, D), ta(C, _, D).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.17E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, _, D), ta(_, A, D).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.070000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), ta(C, E, _), ta(_, E, D).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.28E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, D), ta(C, _, _), ta(_, _, D).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.28E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, _, D), ta(_, _, D).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.27E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, _, _), ta(C, A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.17E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, D, _), ta(C, D, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.38E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, _, _), ta(C, _, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.38E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, _, _), ta(_, A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.28E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, D, _), ta(_, D, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, _, _), hasposition(B, _).  [covers 13,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, _, _), publication(_, B).  [covers 12,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, _, _), inphase(A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.27E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, D, _), inphase(D, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, _, _), courselevel(C, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, _, _), yearsinprogram(A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.27E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, D, _), yearsinprogram(D, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,302794 (regressionFit = 2,302789, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, _, _), projectmember(_, B).  [covers 3,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.2600000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, _, _), samecourse(C, C).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.2600000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, _, _), sameperson(A, A).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.160000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, D, _), sameperson(A, D).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.2600000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, _, _), sameperson(B, B).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.160000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, D, _), sameperson(D, A).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.160000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(C, D, _), sameperson(D, D).  [covers 14,0/14,0 pos, 0,0/0,0 neg]

% Consider expanding [#7 of outerLoop #4, bodyLen=4] 'advisedby(A, B) :- professor(B), student(A), ta(_, A, _), ta(_, A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 7, |OPEN| = 8.  Pruned 54 variant children.  Sending 23 items to OPEN for evaluation and possible insertion.
% Have created 23 valid-on-seeds descendants and have picked up 19 bad extensions.
%     Score = -2,297927 (regressionFit = 2,297921, penalties=5.47E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), ta(_, A, _), tempadvisedby(_, B).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.17E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(_, A, D), ta(C, _, D).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.17E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), ta(D, A, _), ta(D, _, C).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.38E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), ta(_, A, _), ta(_, _, C).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.38E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), ta(_, A, C), ta(_, _, C).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.27E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(_, A, _), ta(C, A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.38E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(_, A, _), ta(C, _, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.27E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), ta(C, A, _), ta(C, A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.38E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), ta(C, A, _), ta(C, _, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.480000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), ta(_, A, _), ta(_, A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.47E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), ta(_, A, _), hasposition(B, _).  [covers 13,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.47E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), ta(_, A, _), publication(_, B).  [covers 12,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.47E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), ta(_, A, _), inphase(A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(_, A, _), courselevel(C, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), ta(C, A, _), courselevel(C, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.47E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), ta(_, A, _), yearsinprogram(A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,302794 (regressionFit = 2,302789, penalties=5.47E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), ta(_, A, _), projectmember(_, B).  [covers 3,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.2600000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(_, A, _), samecourse(C, C).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.160000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(D, A, _), samecourse(C, D).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.160000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), ta(D, A, _), samecourse(D, C).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.2600000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), ta(C, A, _), samecourse(C, C).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.360000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), ta(_, A, _), sameperson(A, A).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.360000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), ta(_, A, _), sameperson(B, B).  [covers 14,0/14,0 pos, 0,0/0,0 neg]

% Consider expanding [#8 of outerLoop #4, bodyLen=4] 'advisedby(A, B) :- professor(B), student(A), ta(_, A, _), hasposition(B, _).  [covers 13,0/14,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 8, |OPEN| = 7.  Pruned 28 variant children.  Sending 14 items to OPEN for evaluation and possible insertion.
% Have created 14 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -2,297927 (regressionFit = 2,297921, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), hasposition(B, _), tempadvisedby(_, B).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), hasposition(B, _), ta(_, _, C).  [covers 13,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.2600000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), hasposition(B, _), ta(C, A, _).  [covers 13,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), hasposition(B, _), ta(C, _, _).  [covers 13,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.47E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), hasposition(B, _), ta(_, A, _).  [covers 13,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.2600000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), hasposition(B, C), hasposition(_, C).  [covers 13,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), hasposition(B, _), publication(_, B).  [covers 12,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), hasposition(B, _), inphase(A, _).  [covers 13,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.36E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), hasposition(B, _), courselevel(C, _).  [covers 13,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), hasposition(B, _), yearsinprogram(A, _).  [covers 13,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,302794 (regressionFit = 2,302789, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), hasposition(B, _), projectmember(_, B).  [covers 3,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.2500000000000006E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), hasposition(B, _), samecourse(C, C).  [covers 13,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.3500000000000004E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), hasposition(B, _), sameperson(A, A).  [covers 13,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.3500000000000004E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), hasposition(B, _), sameperson(B, B).  [covers 13,0/14,0 pos, 0,0/0,0 neg]

% Consider expanding [#9 of outerLoop #4, bodyLen=4] 'advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B).  [covers 12,0/14,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 9, |OPEN| = 6.  Pruned 28 variant children.  Sending 15 items to OPEN for evaluation and possible insertion.
% Have created 15 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -2,168176 (regressionFit = 2,168170, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), tempadvisedby(_, B).  [covers 9,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, C), publication(_, B), ta(_, _, C).  [covers 12,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.2600000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, A, _).  [covers 12,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), ta(C, _, _).  [covers 12,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.47E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), ta(_, A, _).  [covers 12,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), hasposition(B, _).  [covers 12,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.2600000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(C, B), publication(C, _).  [covers 12,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.360000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), publication(_, B).  [covers 12,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), inphase(A, _).  [covers 12,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.36E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), courselevel(C, _).  [covers 12,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), yearsinprogram(A, _).  [covers 12,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), projectmember(_, B).  [covers 2,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.2500000000000006E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(C, A, _), publication(_, B), samecourse(C, C).  [covers 12,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.3500000000000004E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), sameperson(A, A).  [covers 12,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.3500000000000004E-6) for clause:  advisedby(A, B) :- professor(B), student(A), ta(_, A, _), publication(_, B), sameperson(B, B).  [covers 12,0/14,0 pos, 0,0/0,0 neg]

***** Warning: #12 TOO MANY NODES CONSIDERED (i.e., 'expanded') for 'LearnOneClause': nodesConsidered = 10 and maxNodesToConsider = 10. *****


% The best node found: advisedby(A, B) :- professor(B), student(A), ta(_, A, C), ta(_, D, C), publication(_, D).  [covers 4,0/14,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- professor(B), student(A), ta(_, A, C), ta(_, D, C), publication(_, D).  [covers 4,0/14,0 pos, 0,0/0,0 neg]

% Expanding node at Level 3 with score = -0,166.
% Will extend: advisedby(A, B) :- professor(B), student(A), ta(_, A, C), ta(_, D, C), publication(_, D).  [covers 4,0/14,0 pos, 0,0/0,0 neg]
% Path: 8;true,false,true
Comparing variance: 0.0034706768045367764 to score=0.0025 #egs=4.0
Comparing variance: 0.19524597550660336 to score=0.0025 #egs=10.0
%   Creating a TRUE-branch and FALSE-branch leaves because level = 3 >= 3

% Time for loop #4: 114 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #4, the best clause found is:
%      advisedby(A, B) :- professor(B), student(A), ta(_, A, C), ta(_, D, C), publication(_, D).  [covers 4,0/14,0 pos, 0,0/0,0 neg]
% This clause covers 4 positive examples, of which 4 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% ******************************************

%  Have stopped ILP's outer loop because the tree-structured queue is empty.

% ******************************************

%%%%%  WILL-Produced Tree #9 @ 17:27:16 5/29/21.  [Using 4.497.496 memory cells.]  %%%%%


% FOR advisedby(A, B):
%   if ( professor(B), student(A) )
%   then if ( publication(C, A), publication(C, B) )
%   | then return 0.15274385809367097;  // std dev = 0,000, 4,000 (wgt'ed) examples reached here.  /* #pos=4 */
%   | else if ( ta(D, A, E) )
%   | | then if ( ta(F, G, E), publication(H, G) )
%   | | | then return 0.2836887721124507;  // std dev = 0,118, 4,000 (wgt'ed) examples reached here.  /* #pos=4 */
%   | | | else return -0.07101920508121233;  // std dev = 1,397, 10,000 (wgt'ed) examples reached here.  /* #neg=6 #pos=4 */
%   | | else return 0.15481505439148321;  // std dev = 0,793, 6,000 (wgt'ed) examples reached here.  /* #neg=2 #pos=4 */
%   else return -0.06842697784420275;  // std dev = 0,000, 24,000 (wgt'ed) examples reached here.  /* #neg=24 */


% Clauses:

advisedby(A, B, 0.15274385809367097) :- 
     professor(B), 
     student(A), 
     publication(C, A), 
     publication(C, B), 
     !. // Clause #1.

advisedby(A, B, 0.2836887721124507) :- 
     professor(B), 
     student(A), 
     ta(C, A, D), 
     ta(E, F, D), 
     publication(G, F), 
     !. // Clause #2.

advisedby(A, B, -0.07101920508121233) :- 
     professor(B), 
     student(A), 
     ta(C, A, D), 
     !. // Clause #3.

advisedby(A, B, 0.15481505439148321) :- 
     professor(B), 
     student(A), 
     !. // Clause #4.

advisedby(A, B, -0.06842697784420275) :- !. // Clause #5.


% The flattened versions of these clauses:

flattened_advisedby(a, b, 0.15274385809367097) :-  /* #pos=4 */ 
   professor(b),
   student(a),
   publication(uniqueVar17, a),
   publication(uniqueVar17, b),
   !. // Flattened version of clause #1.

flattened_advisedby(a, b, 0.2836887721124507) :-  /* #pos=4 */ 
   professor(b),
   student(a),
   ta(underscore, a, uniqueVar18),
   ta(underscore, uniqueVar19, uniqueVar18),
   publication(underscore, uniqueVar19),
   !. // Flattened version of clause #2.

flattened_advisedby(a, b, -0.07101920508121233) :-  /* #neg=6 #pos=4 */ 
   professor(b),
   student(a),
   ta(underscore, a, underscore),
   !. // Flattened version of clause #3.

flattened_advisedby(a, b, 0.15481505439148321) :-  /* #neg=2 #pos=4 */ 
   professor(b),
   student(a),
   !. // Flattened version of clause #4.

flattened_advisedby(underscore, underscore, -0.06842697784420275) :-  /* #neg=24 */ 
   !. // Flattened version of clause #5.


% The unique flattened literals:
%   ta(underscore, a, underscore)
%   professor(b)
%   publication(underscore, uniqueVar19)
%   publication(uniqueVar17, b)
%   student(a)
%   ta(underscore, a, uniqueVar18)
%   publication(uniqueVar17, a)
%   ta(underscore, uniqueVar19, uniqueVar18)

% Saving model in: train/models/bRDNs/advisedby.model.ckpt
% Time taken to learn 9 trees is 2,900 seconds.

%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.16613012467026195
Set score:0.0025
% Only 48 out of 48 converged.
% Kept 16 of the 16 positive examples.
% Kept 32 of the 32 negative examples.
% Dataset size: 48
Computing probabilities
prob time:8 milliseconds
No hidden examples for : advisedby
Time to build dataset: 9 milliseconds
%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.06437548621833654
Set score:0.0025
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% Have these 8 positive seeds: 4 5 10 14 17 19 20 26

% The best node found: null

% target           = advisedby(D, E)
%     Score = -Infinity (regressionFit = Infinity, penalties=2.2E-7) for clause:  advisedby(_, _).  [covers 48,0/48,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=1.12E-6) for clause:  advisedby(A, _) :- student(A).  [covers 48,0/48,0 pos, 0,0/0,0 neg]
%     Score = -2,876407 (regressionFit = 2,876405, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- student(A), professor(B).  [covers 24,0/48,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- student(A), professor(B).  [covers 24,0/48,0 pos, 0,0/0,0 neg]

% Expanding node at Level 0 with score = 1,797693e+308.
% Will extend: advisedby(A, B) :- student(A), professor(B).  [covers 24,0/48,0 pos, 0,0/0,0 neg]
% Path: 9;
Comparing variance: 0.11985022214572753 to score=0.0025 #egs=24.0
Comparing variance: -1.734723475976807E-18 to score=0.0025 #egs=24.0
%   Creating a TRUE-branch interior node with wgtedCountTrueBranchPos = 24,0
%      addToQueueOfTreeStructuredLearningTasks (level=1; score=-0,119850)
%         ILP node to extend: advisedby(A, B) :- student(A), professor(B).  [covers 24,0/48,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 1 and with score = -0,119850) into the LAST position (#1) in the search queue.
%   Creating a FALSE-branch leaf because good enough fit since score < 0.0025

% Time for loop #1: 2 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #1, the best clause found is:
%      advisedby(A, B) :- student(A), professor(B).  [covers 24,0/48,0 pos, 0,0/0,0 neg]
% This clause covers 24 positive examples, of which 24 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- student(A), professor(B).  [covers 24,0/24,0 pos, 0,0/0,0 neg]'
%     Score = -2,876407 (regressionFit = 2,876405, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- student(A), professor(B).  [covers 24,0/24,0 pos, 0,0/0,0 neg]

% Have these 8 positive seeds: 3 13 15 17 18 20 21 22

% The best node found: null
%     Score = -2,856268 (regressionFit = 2,856264, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, A).  [covers 4,0/24,0 pos, 0,0/0,0 neg]
%     Score = -2,856268 (regressionFit = 2,856264, penalties=3.9300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(C, A), publication(C, B).  [covers 4,0/24,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- student(A), professor(B), publication(C, A), publication(C, B).  [covers 4,0/24,0 pos, 0,0/0,0 neg]

% Expanding node at Level 1 with score = -0,120.
% Will extend: advisedby(A, B) :- student(A), professor(B), publication(C, A), publication(C, B).  [covers 4,0/24,0 pos, 0,0/0,0 neg]
% Path: 9;true
Comparing variance: 0.0 to score=0.0025 #egs=4.0
Comparing variance: 0.1428132244936457 to score=0.0025 #egs=20.0
%   Creating a TRUE-branch leaf because wgtedCountTrueBranchPos = 4,0 < 2.1 * minPosCov = 6,3
%   Creating a FALSE-branch interior node with wgtedCountFalseBranchPos = 20,0
%      addToQueueOfTreeStructuredLearningTasks (level=2; score=-0,142813)
%         ILP node to extend: advisedby(A, B) :- student(A), professor(B).  [covers 24,0/24,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 2 and with score = -0,142813) into the LAST position (#1) in the search queue.

% Time for loop #2: 2 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #2, the best clause found is:
%      advisedby(A, B) :- student(A), professor(B), publication(C, A), publication(C, B).  [covers 4,0/24,0 pos, 0,0/0,0 neg]
% This clause covers 4 positive examples, of which 4 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- student(A), professor(B).  [covers 24,0/20,0 pos, 0,0/0,0 neg]'
%     Score = -2,876407 (regressionFit = 2,876405, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- student(A), professor(B).  [covers 20,0/20,0 pos, 0,0/0,0 neg]

% Have these 5 positive seeds: 2 8 11 13 18
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% Consider expanding [#1 of outerLoop #3, bodyLen=2] 'advisedby(A, B) :- student(A), professor(B).  [covers 20,0/20,0 pos, 0,0/0,0 neg]' score=-2.876407351497461
%  At # nodes expanded = 1, |OPEN| = 0.  Pruned 16 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -2,848881 (regressionFit = 2,848877, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
% Gleaner: New best node found (score = -2,848881): advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,816760 (regressionFit = 2,816756, penalties=3.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
% Gleaner: New best node found (score = -2,816760): advisedby(A, B) :- student(A), professor(B), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _).  [covers 18,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,854666 (regressionFit = 2,854663, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,838486 (regressionFit = 2,838483, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.0200000000000007E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.0200000000000007E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(B, B).  [covers 20,0/20,0 pos, 0,0/0,0 neg]

% Consider expanding [#2 of outerLoop #3, bodyLen=3] 'advisedby(A, B) :- student(A), professor(B), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]' score=-2.81675968326409
%  At # nodes expanded = 2, |OPEN| = 8.  Pruned 26 variant children.  Sending 14 items to OPEN for evaluation and possible insertion.
% Have created 14 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -2,856236 (regressionFit = 2,856232, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), tempadvisedby(_, B).  [covers 10,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,816760 (regressionFit = 2,816756, penalties=4.05E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(C, _, D).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,816761 (regressionFit = 2,816756, penalties=4.260000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, C), ta(_, _, C).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,816761 (regressionFit = 2,816756, penalties=4.260000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, _, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,816761 (regressionFit = 2,816756, penalties=4.3600000000000015E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,856155 (regressionFit = 2,856151, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), hasposition(B, _).  [covers 13,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,820248 (regressionFit = 2,820244, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), publication(_, B).  [covers 12,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,816761 (regressionFit = 2,816756, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), inphase(A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,816761 (regressionFit = 2,816756, penalties=4.250000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), courselevel(C, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,816761 (regressionFit = 2,816756, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), yearsinprogram(A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,829534 (regressionFit = 2,829529, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), projectmember(_, B).  [covers 3,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,816761 (regressionFit = 2,816756, penalties=4.14E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), samecourse(C, C).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,816761 (regressionFit = 2,816756, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), sameperson(A, A).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,816761 (regressionFit = 2,816756, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), sameperson(B, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]

% Consider expanding [#3 of outerLoop #3, bodyLen=3] 'advisedby(A, B) :- student(A), professor(B), projectmember(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]' score=-2.838486465026989
%  At # nodes expanded = 3, |OPEN| = 7.  Pruned 20 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 15 bad extensions.
%     Score = -2,838488 (regressionFit = 2,838483, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B), tempadvisedby(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,829534 (regressionFit = 2,829529, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B), ta(_, A, _).  [covers 3,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,838488 (regressionFit = 2,838483, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B), hasposition(B, _).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,838488 (regressionFit = 2,838483, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B), inphase(A, _).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,838488 (regressionFit = 2,838483, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B), yearsinprogram(A, _).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,838487 (regressionFit = 2,838483, penalties=4.140000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B), projectmember(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,838487 (regressionFit = 2,838483, penalties=4.03E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(C, B), sameproject(C, C).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,838487 (regressionFit = 2,838483, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B), sameperson(A, A).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,838487 (regressionFit = 2,838483, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), projectmember(_, B), sameperson(B, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]

% Consider expanding [#4 of outerLoop #3, bodyLen=3] 'advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]' score=-2.848880589786623
%  At # nodes expanded = 4, |OPEN| = 6.  Pruned 34 variant children.  Sending 13 items to OPEN for evaluation and possible insertion.
% Have created 13 valid-on-seeds descendants and have picked up 26 bad extensions.
%     Score = -2,848881 (regressionFit = 2,848877, penalties=3.9300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(C, B), student(C).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,856236 (regressionFit = 2,856232, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B), ta(_, A, _).  [covers 10,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,848882 (regressionFit = 2,848877, penalties=4.250000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(C, B), ta(_, C, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,848882 (regressionFit = 2,848877, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B), hasposition(B, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,840674 (regressionFit = 2,840669, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B), publication(_, B).  [covers 11,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,848882 (regressionFit = 2,848877, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B), inphase(A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,848882 (regressionFit = 2,848877, penalties=4.14E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(C, B), inphase(C, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,848882 (regressionFit = 2,848877, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B), yearsinprogram(A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,848882 (regressionFit = 2,848877, penalties=4.14E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(C, B), yearsinprogram(C, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,838488 (regressionFit = 2,838483, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B), projectmember(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,848882 (regressionFit = 2,848877, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B), sameperson(A, A).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,848882 (regressionFit = 2,848877, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(_, B), sameperson(B, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,848881 (regressionFit = 2,848877, penalties=4.03E-6) for clause:  advisedby(A, B) :- student(A), professor(B), tempadvisedby(C, B), sameperson(C, C).  [covers 14,0/20,0 pos, 0,0/0,0 neg]

% Consider expanding [#5 of outerLoop #3, bodyLen=3] 'advisedby(A, B) :- student(A), professor(B), publication(_, B).  [covers 15,0/20,0 pos, 0,0/0,0 neg]' score=-2.854665711831761
%  At # nodes expanded = 5, |OPEN| = 5.  Pruned 18 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 15 bad extensions.
%     Score = -2,840674 (regressionFit = 2,840669, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), tempadvisedby(_, B).  [covers 11,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,820248 (regressionFit = 2,820244, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), ta(_, A, _).  [covers 12,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,854667 (regressionFit = 2,854663, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), hasposition(B, _).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,854667 (regressionFit = 2,854663, penalties=4.040000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(C, B), publication(C, _).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,854667 (regressionFit = 2,854663, penalties=4.140000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), publication(_, B).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,854667 (regressionFit = 2,854663, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), inphase(A, _).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,854667 (regressionFit = 2,854663, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), yearsinprogram(A, _).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,854667 (regressionFit = 2,854663, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), sameperson(A, A).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,854667 (regressionFit = 2,854663, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), publication(_, B), sameperson(B, B).  [covers 15,0/20,0 pos, 0,0/0,0 neg]

% Consider expanding [#6 of outerLoop #3, bodyLen=3] 'advisedby(A, B) :- student(A), professor(B), hasposition(B, _).  [covers 18,0/20,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 6, |OPEN| = 4.  Pruned 18 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -2,848882 (regressionFit = 2,848877, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _), tempadvisedby(_, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,856155 (regressionFit = 2,856151, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _), ta(_, A, _).  [covers 13,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.040000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, C), hasposition(_, C).  [covers 18,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,854667 (regressionFit = 2,854663, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _), publication(_, B).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _), inphase(A, _).  [covers 18,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _), yearsinprogram(A, _).  [covers 18,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,838488 (regressionFit = 2,838483, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _), projectmember(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _), sameperson(A, A).  [covers 18,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), hasposition(B, _), sameperson(B, B).  [covers 18,0/20,0 pos, 0,0/0,0 neg]

% Consider expanding [#7 of outerLoop #3, bodyLen=3] 'advisedby(A, B) :- student(A), professor(B), inphase(A, _).  [covers 20,0/20,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 7, |OPEN| = 3.  Pruned 18 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -2,848882 (regressionFit = 2,848877, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _), tempadvisedby(_, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,816761 (regressionFit = 2,816756, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _), hasposition(B, _).  [covers 18,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,854667 (regressionFit = 2,854663, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _), publication(_, B).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.040000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, C), inphase(_, C).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _), yearsinprogram(A, _).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,838488 (regressionFit = 2,838483, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _), projectmember(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _), sameperson(A, A).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), inphase(A, _), sameperson(B, B).  [covers 20,0/20,0 pos, 0,0/0,0 neg]

% Consider expanding [#8 of outerLoop #3, bodyLen=3] 'advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _).  [covers 20,0/20,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 8, |OPEN| = 2.  Pruned 18 variant children.  Sending 9 items to OPEN for evaluation and possible insertion.
% Have created 9 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -2,848882 (regressionFit = 2,848877, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _), tempadvisedby(_, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,816761 (regressionFit = 2,816756, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _), hasposition(B, _).  [covers 18,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,854667 (regressionFit = 2,854663, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _), publication(_, B).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _), inphase(A, _).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.040000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, C), yearsinprogram(_, C).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,838488 (regressionFit = 2,838483, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _), projectmember(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _), sameperson(A, A).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), yearsinprogram(A, _), sameperson(B, B).  [covers 20,0/20,0 pos, 0,0/0,0 neg]

% Consider expanding [#9 of outerLoop #3, bodyLen=3] 'advisedby(A, B) :- student(A), professor(B), sameperson(A, A).  [covers 20,0/20,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 9, |OPEN| = 1.  Pruned 14 variant children.  Sending 8 items to OPEN for evaluation and possible insertion.
% Have created 8 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -2,848882 (regressionFit = 2,848877, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A), tempadvisedby(_, B).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,816761 (regressionFit = 2,816756, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A), hasposition(B, _).  [covers 18,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,854667 (regressionFit = 2,854663, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A), publication(_, B).  [covers 15,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A), inphase(A, _).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A), yearsinprogram(A, _).  [covers 20,0/20,0 pos, 0,0/0,0 neg]
%     Score = -2,838487 (regressionFit = 2,838483, penalties=4.13E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A), projectmember(_, B).  [covers 6,0/20,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.920000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), sameperson(A, A), sameperson(B, B).  [covers 20,0/20,0 pos, 0,0/0,0 neg]

***** Warning: #13 TOO MANY NODES CONSIDERED (i.e., 'expanded') for 'LearnOneClause': nodesConsidered = 10 and maxNodesToConsider = 10. *****


% The best node found: advisedby(A, B) :- student(A), professor(B), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- student(A), professor(B), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]

% Expanding node at Level 2 with score = -0,143.
% Will extend: advisedby(A, B) :- student(A), professor(B), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
% Path: 9;true,false
Comparing variance: 0.15658176884980812 to score=0.0025 #egs=14.0
Comparing variance: 0.10410194656112941 to score=0.0025 #egs=6.0
%   Creating a TRUE-branch interior node with wgtedCountTrueBranchPos = 14,0
%      addToQueueOfTreeStructuredLearningTasks (level=3; score=-0,156582)
%         ILP node to extend: advisedby(A, B) :- student(A), professor(B), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 3 and with score = -0,156582) into the LAST position (#1) in the search queue.
%   Creating a FALSE-branch leaf because wgtedCountFalseBranchPos = 6,0 < 2.1 * minPosCov = 6,3

% Time for loop #3: 48 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #3, the best clause found is:
%      advisedby(A, B) :- student(A), professor(B), ta(_, A, _).  [covers 14,0/20,0 pos, 0,0/0,0 neg]
% This clause covers 14 positive examples, of which 14 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- student(A), professor(B), ta(_, A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]'
%     Score = -2,816760 (regressionFit = 2,816756, penalties=3.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]

% Have these 8 positive seeds: 0 1 3 5 6 8 9 11
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% Consider expanding [#1 of outerLoop #4, bodyLen=3] 'advisedby(A, B) :- student(A), professor(B), ta(_, A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]' score=-2.81675968326409
%  At # nodes expanded = 1, |OPEN| = 0.  Pruned 26 variant children.  Sending 15 items to OPEN for evaluation and possible insertion.
% Have created 15 valid-on-seeds descendants and have picked up 28 bad extensions.
%     Score = -2,165071 (regressionFit = 2,165067, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), tempadvisedby(_, B).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
% Gleaner: New best node found (score = -2,165071): advisedby(A, B) :- student(A), professor(B), ta(_, A, _), tempadvisedby(_, B).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.05E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(C, _, D).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.260000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, C), ta(_, _, C).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.150000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.260000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, _, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.3600000000000015E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), ta(_, A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), hasposition(B, _).  [covers 13,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), publication(_, B).  [covers 12,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), inphase(A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.250000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), courselevel(C, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), yearsinprogram(A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,179332 (regressionFit = 2,179328, penalties=4.35E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), projectmember(_, B).  [covers 3,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.14E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), samecourse(C, C).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), sameperson(A, A).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.240000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), sameperson(B, B).  [covers 14,0/14,0 pos, 0,0/0,0 neg]

% Consider expanding [#2 of outerLoop #4, bodyLen=4] 'advisedby(A, B) :- student(A), professor(B), ta(_, A, _), tempadvisedby(_, B).  [covers 10,0/14,0 pos, 0,0/0,0 neg]' score=-2.1650714141826306
%  At # nodes expanded = 2, |OPEN| = 14.  Pruned 49 variant children.  Sending 21 items to OPEN for evaluation and possible insertion.
% Have created 21 valid-on-seeds descendants and have picked up 27 bad extensions.
%     Score = -2,165072 (regressionFit = 2,165067, penalties=5.150000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), tempadvisedby(C, B), student(C).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,165072 (regressionFit = 2,165067, penalties=5.360000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), tempadvisedby(_, B), tempadvisedby(_, B).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,165072 (regressionFit = 2,165067, penalties=5.160000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), tempadvisedby(_, B), ta(C, _, D).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.160000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, C), tempadvisedby(D, B), ta(_, D, C).  [covers 2,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,165072 (regressionFit = 2,165067, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, C), tempadvisedby(_, B), ta(_, _, C).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,165072 (regressionFit = 2,165067, penalties=5.2600000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), tempadvisedby(_, B), ta(C, A, _).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,165072 (regressionFit = 2,165067, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), tempadvisedby(_, B), ta(C, _, _).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,165073 (regressionFit = 2,165067, penalties=5.47E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), tempadvisedby(_, B), ta(_, A, _).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,165072 (regressionFit = 2,165067, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), tempadvisedby(C, B), ta(_, C, _).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,165073 (regressionFit = 2,165067, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), tempadvisedby(_, B), hasposition(B, _).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,045056 (regressionFit = 2,045050, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), tempadvisedby(_, B), publication(_, B).  [covers 9,0/14,0 pos, 0,0/0,0 neg]
% Gleaner: New best node found (score = -2,045056): advisedby(A, B) :- student(A), professor(B), ta(_, A, _), tempadvisedby(_, B), publication(_, B).  [covers 9,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,165073 (regressionFit = 2,165067, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), tempadvisedby(_, B), inphase(A, _).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,165072 (regressionFit = 2,165067, penalties=5.36E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), tempadvisedby(C, B), inphase(C, _).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,165072 (regressionFit = 2,165067, penalties=5.36E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), tempadvisedby(_, B), courselevel(C, _).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,165073 (regressionFit = 2,165067, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), tempadvisedby(_, B), yearsinprogram(A, _).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,165072 (regressionFit = 2,165067, penalties=5.36E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), tempadvisedby(C, B), yearsinprogram(C, _).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,179333 (regressionFit = 2,179328, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), tempadvisedby(_, B), projectmember(_, B).  [covers 3,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,165072 (regressionFit = 2,165067, penalties=5.2500000000000006E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), tempadvisedby(_, B), samecourse(C, C).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,165072 (regressionFit = 2,165067, penalties=5.3500000000000004E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), tempadvisedby(_, B), sameperson(A, A).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,165072 (regressionFit = 2,165067, penalties=5.3500000000000004E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), tempadvisedby(_, B), sameperson(B, B).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,165072 (regressionFit = 2,165067, penalties=5.2500000000000006E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), tempadvisedby(C, B), sameperson(C, C).  [covers 10,0/14,0 pos, 0,0/0,0 neg]

% Consider expanding [#3 of outerLoop #4, bodyLen=4] 'advisedby(A, B) :- student(A), professor(B), ta(_, A, _), projectmember(_, B).  [covers 3,0/14,0 pos, 0,0/0,0 neg]' score=-2.179332275395078
%  At # nodes expanded = 3, |OPEN| = 13.  Pruned 30 variant children.  Sending 14 items to OPEN for evaluation and possible insertion.
% Have created 14 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -2,179333 (regressionFit = 2,179328, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), projectmember(_, B), tempadvisedby(_, B).  [covers 3,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,179333 (regressionFit = 2,179328, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, C), projectmember(_, B), ta(_, _, C).  [covers 3,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,179333 (regressionFit = 2,179328, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), projectmember(_, B), ta(C, _, _).  [covers 3,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,179333 (regressionFit = 2,179328, penalties=5.47E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), projectmember(_, B), ta(_, A, _).  [covers 3,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,179333 (regressionFit = 2,179328, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), projectmember(_, B), hasposition(B, _).  [covers 3,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), projectmember(_, B), publication(_, B).  [covers 2,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,179333 (regressionFit = 2,179328, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), projectmember(_, B), inphase(A, _).  [covers 3,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,179333 (regressionFit = 2,179328, penalties=5.36E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), projectmember(_, B), courselevel(C, _).  [covers 3,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,179333 (regressionFit = 2,179328, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), projectmember(_, B), yearsinprogram(A, _).  [covers 3,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,179333 (regressionFit = 2,179328, penalties=5.360000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), projectmember(_, B), projectmember(_, B).  [covers 3,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,179333 (regressionFit = 2,179328, penalties=5.2500000000000006E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), projectmember(C, B), sameproject(C, C).  [covers 3,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,179333 (regressionFit = 2,179328, penalties=5.2500000000000006E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), projectmember(_, B), samecourse(C, C).  [covers 3,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,179333 (regressionFit = 2,179328, penalties=5.3500000000000004E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), projectmember(_, B), sameperson(A, A).  [covers 3,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,179333 (regressionFit = 2,179328, penalties=5.3500000000000004E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), projectmember(_, B), sameperson(B, B).  [covers 3,0/14,0 pos, 0,0/0,0 neg]

% Consider expanding [#4 of outerLoop #4, bodyLen=4] 'advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(C, _, D).  [covers 14,0/14,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 4, |OPEN| = 12.  Pruned 48 variant children.  Sending 24 items to OPEN for evaluation and possible insertion.
% Have created 24 valid-on-seeds descendants and have picked up 25 bad extensions.
%     Score = -Infinity (regressionFit = Infinity, penalties=4.85E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(C, E, D), student(E).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.060000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(C, E, D), tempadvisedby(E, _).  [covers 1,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,165072 (regressionFit = 2,165067, penalties=5.160000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(C, _, D), tempadvisedby(_, B).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.060000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(C, _, D), ta(C, _, D).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.17E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(C, _, D), ta(_, _, D).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.060000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(C, _, D), ta(C, A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.96E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(C, E, D), ta(C, E, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.17E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(C, _, D), ta(C, _, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.17E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(C, _, D), ta(_, A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.070000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(C, E, D), ta(_, E, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.160000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(C, _, D), hasposition(B, _).  [covers 13,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.160000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(C, _, D), publication(_, B).  [covers 12,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.160000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(C, _, D), inphase(A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.060000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(C, E, D), inphase(E, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.160000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(C, _, D), courselevel(C, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.160000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(C, _, D), yearsinprogram(A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.060000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(C, E, D), yearsinprogram(E, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,179333 (regressionFit = 2,179328, penalties=5.160000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(C, _, D), projectmember(_, B).  [covers 3,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.050000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(C, _, D), samecourse(C, C).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.050000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(C, _, D), sameperson(A, A).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.950000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(C, E, D), sameperson(A, E).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.050000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(C, _, D), sameperson(B, B).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.950000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(C, E, D), sameperson(E, A).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.950000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(C, E, D), sameperson(E, E).  [covers 14,0/14,0 pos, 0,0/0,0 neg]

% Consider expanding [#5 of outerLoop #4, bodyLen=4] 'advisedby(A, B) :- student(A), professor(B), ta(_, A, C), ta(_, _, C).  [covers 14,0/14,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 5, |OPEN| = 11.  Pruned 67 variant children.  Sending 34 items to OPEN for evaluation and possible insertion.
% Have created 34 valid-on-seeds descendants and have picked up 26 bad extensions.
%     Score = -Infinity (regressionFit = Infinity, penalties=5.060000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, C), ta(_, D, C), student(D).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.160000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, C), ta(_, D, C), tempadvisedby(D, B).  [covers 2,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.27E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, C), ta(_, D, C), tempadvisedby(D, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,165072 (regressionFit = 2,165067, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, C), ta(_, _, C), tempadvisedby(_, B).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.17E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(_, _, D), ta(C, _, D).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.17E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, C), ta(D, _, C), ta(D, _, C).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.38E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, C), ta(_, _, C), ta(_, _, C).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.17E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(_, _, D), ta(C, A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.070000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(_, E, D), ta(C, E, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.28E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(_, _, D), ta(C, _, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.17E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, C), ta(D, _, C), ta(D, A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.070000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, C), ta(D, E, C), ta(D, E, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.28E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, C), ta(D, _, C), ta(D, _, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.38E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, C), ta(_, _, C), ta(_, A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.28E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, C), ta(_, D, C), ta(_, D, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, C), ta(_, _, C), hasposition(B, _).  [covers 13,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, C), ta(_, _, C), publication(_, B).  [covers 12,0/14,0 pos, 0,0/0,0 neg]
%     Score = -1,960642 (regressionFit = 1,960637, penalties=5.27E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, C), ta(_, D, C), publication(_, D).  [covers 4,0/14,0 pos, 0,0/0,0 neg]
% Gleaner: New best node found (score = -1,960642): advisedby(A, B) :- student(A), professor(B), ta(_, A, C), ta(_, D, C), publication(_, D).  [covers 4,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, C), ta(_, _, C), inphase(A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.27E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, C), ta(_, D, C), inphase(D, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.27E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(_, _, D), courselevel(C, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.27E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, C), ta(D, _, C), courselevel(D, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, C), ta(_, _, C), yearsinprogram(A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.27E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, C), ta(_, D, C), yearsinprogram(D, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,179333 (regressionFit = 2,179328, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, C), ta(_, _, C), projectmember(_, B).  [covers 3,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.160000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(_, _, D), samecourse(C, C).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.060000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(E, _, D), samecourse(C, E).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.060000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(E, _, D), samecourse(E, C).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.160000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, C), ta(D, _, C), samecourse(D, D).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.2600000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, C), ta(_, _, C), sameperson(A, A).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.160000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, C), ta(_, D, C), sameperson(A, D).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.2600000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, C), ta(_, _, C), sameperson(B, B).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.160000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, C), ta(_, D, C), sameperson(D, A).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.160000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, C), ta(_, D, C), sameperson(D, D).  [covers 14,0/14,0 pos, 0,0/0,0 neg]

% Consider expanding [#6 of outerLoop #4, bodyLen=4] 'advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 6, |OPEN| = 10.  Pruned 32 variant children.  Sending 17 items to OPEN for evaluation and possible insertion.
% Have created 17 valid-on-seeds descendants and have picked up 15 bad extensions.
%     Score = -2,165072 (regressionFit = 2,165067, penalties=5.2600000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, A, _), tempadvisedby(_, B).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.060000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(C, A, _), ta(C, _, D).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.060000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, A, D), ta(C, _, D).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.17E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(C, A, _), ta(_, _, D).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.17E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, A, D), ta(_, _, D).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.1600000000000006E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, A, _), ta(C, A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.27E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, A, _), ta(C, _, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.27E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, A, _), ta(_, A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.2600000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, A, _), hasposition(B, _).  [covers 13,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.2600000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, A, _), publication(_, B).  [covers 12,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.2600000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, A, _), inphase(A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.2600000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, A, _), courselevel(C, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.2600000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, A, _), yearsinprogram(A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,179333 (regressionFit = 2,179328, penalties=5.2600000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, A, _), projectmember(_, B).  [covers 3,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.150000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, A, _), samecourse(C, C).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.150000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, A, _), sameperson(A, A).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.150000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, A, _), sameperson(B, B).  [covers 14,0/14,0 pos, 0,0/0,0 neg]

% Consider expanding [#7 of outerLoop #4, bodyLen=4] 'advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, _, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 7, |OPEN| = 9.  Pruned 61 variant children.  Sending 30 items to OPEN for evaluation and possible insertion.
% Have created 30 valid-on-seeds descendants and have picked up 26 bad extensions.
%     Score = -Infinity (regressionFit = Infinity, penalties=5.060000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, D, _), student(D).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.27E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, D, _), tempadvisedby(D, _).  [covers 13,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,165072 (regressionFit = 2,165067, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, _, _), tempadvisedby(_, B).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=4.96E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(C, E, _), ta(C, E, D).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.17E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(C, _, _), ta(C, _, D).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.17E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, _, D), ta(C, _, D).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.17E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, _, D), ta(_, A, D).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.070000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(C, E, _), ta(_, E, D).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.28E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(C, _, _), ta(_, _, D).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.28E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, _, D), ta(_, _, D).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.27E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, _, _), ta(C, A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.17E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, D, _), ta(C, D, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.38E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, _, _), ta(C, _, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.38E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, _, _), ta(_, A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.28E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, D, _), ta(_, D, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, _, _), hasposition(B, _).  [covers 13,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, _, _), publication(_, B).  [covers 12,0/14,0 pos, 0,0/0,0 neg]
%     Score = -1,934197 (regressionFit = 1,934192, penalties=5.27E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, D, _), publication(_, D).  [covers 3,0/14,0 pos, 0,0/0,0 neg]
% Gleaner: New best node found (score = -1,934197): advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, D, _), publication(_, D).  [covers 3,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, _, _), inphase(A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.27E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, D, _), inphase(D, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, _, _), courselevel(C, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, _, _), yearsinprogram(A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.27E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, D, _), yearsinprogram(D, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,179333 (regressionFit = 2,179328, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, _, _), projectmember(_, B).  [covers 3,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.2600000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, _, _), samecourse(C, C).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.2600000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, _, _), sameperson(A, A).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.160000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, D, _), sameperson(A, D).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.2600000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, _, _), sameperson(B, B).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.160000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, D, _), sameperson(D, A).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.160000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, D, _), sameperson(D, D).  [covers 14,0/14,0 pos, 0,0/0,0 neg]

% Consider expanding [#8 of outerLoop #4, bodyLen=4] 'advisedby(A, B) :- student(A), professor(B), ta(_, A, _), ta(_, A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 8, |OPEN| = 8.  Pruned 54 variant children.  Sending 25 items to OPEN for evaluation and possible insertion.
% Have created 25 valid-on-seeds descendants and have picked up 19 bad extensions.
%     Score = -2,165073 (regressionFit = 2,165067, penalties=5.47E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), ta(_, A, _), tempadvisedby(_, B).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.17E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), ta(_, A, _), ta(C, _, D).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.17E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(_, A, D), ta(C, _, D).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.17E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, C), ta(D, A, _), ta(D, _, C).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.17E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), ta(C, A, D), ta(C, _, D).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.38E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, C), ta(_, A, _), ta(_, _, C).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.38E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), ta(_, A, C), ta(_, _, C).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.27E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(_, A, _), ta(C, A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.38E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(_, A, _), ta(C, _, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.27E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), ta(C, A, _), ta(C, A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.38E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), ta(C, A, _), ta(C, _, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.480000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), ta(_, A, _), ta(_, A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.47E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), ta(_, A, _), hasposition(B, _).  [covers 13,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.47E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), ta(_, A, _), publication(_, B).  [covers 12,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.47E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), ta(_, A, _), inphase(A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(_, A, _), courselevel(C, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), ta(C, A, _), courselevel(C, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.47E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), ta(_, A, _), yearsinprogram(A, _).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,179333 (regressionFit = 2,179328, penalties=5.47E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), ta(_, A, _), projectmember(_, B).  [covers 3,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.2600000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(_, A, _), samecourse(C, C).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.160000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(D, A, _), samecourse(C, D).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.160000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(D, A, _), samecourse(D, C).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.2600000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), ta(C, A, _), samecourse(C, C).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.360000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), ta(_, A, _), sameperson(A, A).  [covers 14,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.360000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), ta(_, A, _), sameperson(B, B).  [covers 14,0/14,0 pos, 0,0/0,0 neg]

% Consider expanding [#9 of outerLoop #4, bodyLen=4] 'advisedby(A, B) :- student(A), professor(B), ta(_, A, _), hasposition(B, _).  [covers 13,0/14,0 pos, 0,0/0,0 neg]' score=-Infinity
%  At # nodes expanded = 9, |OPEN| = 7.  Pruned 28 variant children.  Sending 15 items to OPEN for evaluation and possible insertion.
% Have created 15 valid-on-seeds descendants and have picked up 14 bad extensions.
%     Score = -2,165073 (regressionFit = 2,165067, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), hasposition(B, _), tempadvisedby(_, B).  [covers 10,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.160000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, D), hasposition(B, _), ta(C, _, D).  [covers 13,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, C), hasposition(B, _), ta(_, _, C).  [covers 13,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.2600000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), hasposition(B, _), ta(C, A, _).  [covers 13,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.370000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), hasposition(B, _), ta(C, _, _).  [covers 13,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.47E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), hasposition(B, _), ta(_, A, _).  [covers 13,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.2600000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), hasposition(B, C), hasposition(_, C).  [covers 13,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), hasposition(B, _), publication(_, B).  [covers 12,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), hasposition(B, _), inphase(A, _).  [covers 13,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.36E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), hasposition(B, _), courselevel(C, _).  [covers 13,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), hasposition(B, _), yearsinprogram(A, _).  [covers 13,0/14,0 pos, 0,0/0,0 neg]
%     Score = -2,179333 (regressionFit = 2,179328, penalties=5.460000000000001E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), hasposition(B, _), projectmember(_, B).  [covers 3,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.2500000000000006E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(C, A, _), hasposition(B, _), samecourse(C, C).  [covers 13,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.3500000000000004E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), hasposition(B, _), sameperson(A, A).  [covers 13,0/14,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=5.3500000000000004E-6) for clause:  advisedby(A, B) :- student(A), professor(B), ta(_, A, _), hasposition(B, _), sameperson(B, B).  [covers 13,0/14,0 pos, 0,0/0,0 neg]

***** Warning: #14 TOO MANY NODES CONSIDERED (i.e., 'expanded') for 'LearnOneClause': nodesConsidered = 10 and maxNodesToConsider = 10. *****


% The best node found: advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, D, _), publication(_, D).  [covers 3,0/14,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, D, _), publication(_, D).  [covers 3,0/14,0 pos, 0,0/0,0 neg]

% Expanding node at Level 3 with score = -0,157.
% Will extend: advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, D, _), publication(_, D).  [covers 3,0/14,0 pos, 0,0/0,0 neg]
% Path: 9;true,false,true
Comparing variance: 0.010352536104237559 to score=0.0025 #egs=3.0
Comparing variance: 0.1730121931949036 to score=0.0025 #egs=11.0
%   Creating a TRUE-branch and FALSE-branch leaves because level = 3 >= 3

% Time for loop #4: 99 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #4, the best clause found is:
%      advisedby(A, B) :- student(A), professor(B), ta(C, A, _), ta(C, D, _), publication(_, D).  [covers 3,0/14,0 pos, 0,0/0,0 neg]
% This clause covers 3 positive examples, of which 3 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% ******************************************

%  Have stopped ILP's outer loop because the tree-structured queue is empty.

% ******************************************

%%%%%  WILL-Produced Tree #10 @ 17:27:16 5/29/21.  [Using 4.522.136 memory cells.]  %%%%%


% FOR advisedby(A, B):
%   if ( student(A), professor(B) )
%   then if ( publication(C, A), publication(C, B) )
%   | then return 0.13400703000801117;  // std dev = 0,000, 4,000 (wgt'ed) examples reached here.  /* #pos=4 */
%   | else if ( ta(D, A, E) )
%   | | then if ( ta(D, F, G), publication(H, F) )
%   | | | then return 0.28710008046839625;  // std dev = 0,176, 3,000 (wgt'ed) examples reached here.  /* #pos=3 */
%   | | | else return -0.04370895655270145;  // std dev = 1,380, 11,000 (wgt'ed) examples reached here.  /* #neg=6 #pos=5 */
%   | | else return 0.12416672321021587;  // std dev = 0,790, 6,000 (wgt'ed) examples reached here.  /* #neg=2 #pos=4 */
%   else return -0.0641918400820262;  // std dev = 0,000, 24,000 (wgt'ed) examples reached here.  /* #neg=24 */


% Clauses:

advisedby(A, B, 0.13400703000801117) :- 
     student(A), 
     professor(B), 
     publication(C, A), 
     publication(C, B), 
     !. // Clause #1.

advisedby(A, B, 0.28710008046839625) :- 
     student(A), 
     professor(B), 
     ta(C, A, D), 
     ta(C, E, F), 
     publication(G, E), 
     !. // Clause #2.

advisedby(A, B, -0.04370895655270145) :- 
     student(A), 
     professor(B), 
     ta(C, A, D), 
     !. // Clause #3.

advisedby(A, B, 0.12416672321021587) :- 
     student(A), 
     professor(B), 
     !. // Clause #4.

advisedby(A, B, -0.0641918400820262) :- !. // Clause #5.


% The flattened versions of these clauses:

flattened_advisedby(a, b, 0.13400703000801117) :-  /* #pos=4 */ 
   student(a),
   professor(b),
   publication(uniqueVar20, a),
   publication(uniqueVar20, b),
   !. // Flattened version of clause #1.

flattened_advisedby(a, b, 0.28710008046839625) :-  /* #pos=3 */ 
   student(a),
   professor(b),
   ta(uniqueVar21, a, underscore),
   ta(uniqueVar21, uniqueVar22, underscore),
   publication(underscore, uniqueVar22),
   !. // Flattened version of clause #2.

flattened_advisedby(a, b, -0.04370895655270145) :-  /* #neg=6 #pos=5 */ 
   student(a),
   professor(b),
   ta(underscore, a, underscore),
   !. // Flattened version of clause #3.

flattened_advisedby(a, b, 0.12416672321021587) :-  /* #neg=2 #pos=4 */ 
   student(a),
   professor(b),
   !. // Flattened version of clause #4.

flattened_advisedby(underscore, underscore, -0.0641918400820262) :-  /* #neg=24 */ 
   !. // Flattened version of clause #5.


% The unique flattened literals:
%   publication(underscore, uniqueVar22)
%   ta(uniqueVar21, a, underscore)
%   ta(underscore, a, underscore)
%   professor(b)
%   ta(uniqueVar21, uniqueVar22, underscore)
%   publication(uniqueVar20, b)
%   student(a)
%   publication(uniqueVar20, a)

% Saving model in: train/models/bRDNs/advisedby.model.ckpt
% Saving model in: train/models/bRDNs/advisedby.model


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%  Final call for computing score for advisedby.  %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

stepLength_tree1(1.0).
stepLength_tree2(1.0).
stepLength_tree3(1.0).
stepLength_tree4(1.0).
stepLength_tree5(1.0).
stepLength_tree6(1.0).
stepLength_tree7(1.0).
stepLength_tree8(1.0).
stepLength_tree9(1.0).
stepLength_tree10(1.0).

logPrior(-1.8).
advisedby(D, E, Total) :- // A general accessor. 
   advisedby(D, E, 1000000, Total), !.
advisedby(D, E, Total) :- waitHere("This should not fail", advisedby(D, E, Total)).

advisedby(D, E, TreesToUse, Total) :- // A tree-limited accessor (e.g., for tuning the number of trees to use).
   logPrior(LogPrior),
   getScore_advisedby_tree1(D, E, TreesToUse, Total1),
   getScore_advisedby_tree2(D, E, TreesToUse, Total2),
   getScore_advisedby_tree3(D, E, TreesToUse, Total3),
   getScore_advisedby_tree4(D, E, TreesToUse, Total4),
   getScore_advisedby_tree5(D, E, TreesToUse, Total5),
   getScore_advisedby_tree6(D, E, TreesToUse, Total6),
   getScore_advisedby_tree7(D, E, TreesToUse, Total7),
   getScore_advisedby_tree8(D, E, TreesToUse, Total8),
   getScore_advisedby_tree9(D, E, TreesToUse, Total9),
   getScore_advisedby_tree10(D, E, TreesToUse, Total10),
   Total is LogPrior + Total1 + Total2 + Total3 + Total4 + Total5 + Total6 + Total7 + Total8 + Total9 + Total10,
   !.
advisedby(D, E, TreesToUse, Total) :- waitHere("This should not fail", advisedby(D, E, TreesToUse, Total)).

getScore_advisedby_tree1(D, E, TreesToUse, 0.0) :- 1 > TreesToUse, !.
getScore_advisedby_tree1(D, E, TreesToUse, Total1) :- advisedby_tree1(D, E, Total), stepLength_tree1(StepLen), Total1 is Total * StepLen.

getScore_advisedby_tree2(D, E, TreesToUse, 0.0) :- 2 > TreesToUse, !.
getScore_advisedby_tree2(D, E, TreesToUse, Total2) :- advisedby_tree2(D, E, Total), stepLength_tree2(StepLen), Total2 is Total * StepLen.

getScore_advisedby_tree3(D, E, TreesToUse, 0.0) :- 3 > TreesToUse, !.
getScore_advisedby_tree3(D, E, TreesToUse, Total3) :- advisedby_tree3(D, E, Total), stepLength_tree3(StepLen), Total3 is Total * StepLen.

getScore_advisedby_tree4(D, E, TreesToUse, 0.0) :- 4 > TreesToUse, !.
getScore_advisedby_tree4(D, E, TreesToUse, Total4) :- advisedby_tree4(D, E, Total), stepLength_tree4(StepLen), Total4 is Total * StepLen.

getScore_advisedby_tree5(D, E, TreesToUse, 0.0) :- 5 > TreesToUse, !.
getScore_advisedby_tree5(D, E, TreesToUse, Total5) :- advisedby_tree5(D, E, Total), stepLength_tree5(StepLen), Total5 is Total * StepLen.

getScore_advisedby_tree6(D, E, TreesToUse, 0.0) :- 6 > TreesToUse, !.
getScore_advisedby_tree6(D, E, TreesToUse, Total6) :- advisedby_tree6(D, E, Total), stepLength_tree6(StepLen), Total6 is Total * StepLen.

getScore_advisedby_tree7(D, E, TreesToUse, 0.0) :- 7 > TreesToUse, !.
getScore_advisedby_tree7(D, E, TreesToUse, Total7) :- advisedby_tree7(D, E, Total), stepLength_tree7(StepLen), Total7 is Total * StepLen.

getScore_advisedby_tree8(D, E, TreesToUse, 0.0) :- 8 > TreesToUse, !.
getScore_advisedby_tree8(D, E, TreesToUse, Total8) :- advisedby_tree8(D, E, Total), stepLength_tree8(StepLen), Total8 is Total * StepLen.

getScore_advisedby_tree9(D, E, TreesToUse, 0.0) :- 9 > TreesToUse, !.
getScore_advisedby_tree9(D, E, TreesToUse, Total9) :- advisedby_tree9(D, E, Total), stepLength_tree9(StepLen), Total9 is Total * StepLen.

getScore_advisedby_tree10(D, E, TreesToUse, 0.0) :- 10 > TreesToUse, !.
getScore_advisedby_tree10(D, E, TreesToUse, Total10) :- advisedby_tree10(D, E, Total), stepLength_tree10(StepLen), Total10 is Total * StepLen.

flattenedLiteralsInThisSetOfTrees(advisedby, 43, [
   professor(b),
   projectmember(underscore, b),
   publication(uniqueVar6, b),
   publication(uniqueVar9, b),
   ta(uniqueVar14, a, underscore),
   publication(uniqueVar17, b),
   publication(uniqueVar16, b),
   publication(uniqueVar4, a),
   publication(uniqueVar20, a),
   publication(uniqueVar12, a),
   publication(uniqueVar5, b),
   publication(underscore, uniqueVar11),
   publication(underscore, uniqueVar19),
   publication(underscore, uniqueVar15),
   publication(underscore, uniqueVar8),
   ta(underscore, uniqueVar3, uniqueVar2),
   publication(uniqueVar12, b),
   publication(uniqueVar5, a),
   student(a),
   publication(underscore, uniqueVar3),
   ta(underscore, a, uniqueVar18),
   ta(uniqueVar21, a, underscore),
   publication(underscore, b),
   publication(uniqueVar16, a),
   publication(uniqueVar4, b),
   ta(uniqueVar14, uniqueVar15, underscore),
   publication(uniqueVar20, b),
   ta(underscore, a, uniqueVar2),
   ta(uniqueVar7, a, underscore),
   ta(underscore, uniqueVar11, uniqueVar10),
   publication(uniqueVar1, b),
   publication(uniqueVar9, a),
   publication(uniqueVar6, a),
   publication(uniqueVar17, a),
   publication(uniqueVar13, a),
   publication(underscore, uniqueVar22),
   ta(underscore, a, underscore),
   ta(uniqueVar21, uniqueVar22, underscore),
   publication(uniqueVar1, a),
   ta(uniqueVar7, uniqueVar8, underscore),
   publication(uniqueVar13, b),
   ta(underscore, a, uniqueVar10),
   ta(underscore, uniqueVar19, uniqueVar18)]).
% Time taken to learn model for 'advisedby': 3,135 seconds.
% Saving model in: train/models/bRDNs/advisedby.model
cached groundings hit: 0
Misses: 0

% Total learning time (10 trees): 3,416 seconds.
