args[0] = -i
args[1] = -model
args[3] = -test
args[5] = -target
args[7] = -trees
args[9] = -aucJarPath

% Starting an INFERENCE run of bRDN.
% Running on host: C02DX2QHML7H

% Switching to VarIndicator = uppercase.

% Unset'ing VarIndicator.

Resetting the LazyGroundNthArgumentClauseIndex.

% Calling ILPouterLoop from createRegressionOuterLooper.

% getInputArgWithDefaultValue: args=[test/test_pos.txt, test/test_neg.txt, test/test_bk.txt, test/test_facts.txt]
%  for N=0: args[N]=test/test_pos.txt

% getInputArgWithDefaultValue: args=[test/test_pos.txt, test/test_neg.txt, test/test_bk.txt, test/test_facts.txt]
%  for N=1: args[N]=test/test_neg.txt

% getInputArgWithDefaultValue: args=[test/test_pos.txt, test/test_neg.txt, test/test_bk.txt, test/test_facts.txt]
%  for N=2: args[N]=test/test_bk.txt

% getInputArgWithDefaultValue: args=[test/test_pos.txt, test/test_neg.txt, test/test_bk.txt, test/test_facts.txt]
%  for N=3: args[N]=test/test_facts.txt

% Welcome to the WILL ILP/SRL systems.


% Switching to VarIndicator = uppercase.

% Unset'ing VarIndicator.
% Reading background theory from dir: null
% Load '../background.txt'.

% Switching to VarIndicator = uppercase.

***** Warning: % Since this is the first setting of the notation for variables, will keep:
%   variableIndicator = uppercase *****


***** Warning: % Since this is the first setting of the notation for variables, will keep:
%   variableIndicator = uppercase *****

% [ LazyGroundClauseIndex ]  Building full index for mode/1 with 1 assertions.
% LoadAllModes() called.  Currently loaded modes: []
% [ LazyGroundClauseIndex ]  Building full index for sameAs/2 with 2 assertions.
% [ LazyGroundNthArgumentClauseIndex ]  Argument 1:  Building full index for exp/3.
% [ LazyGroundNthArgumentClauseIndex ]  Argument 0:  Building full index for log/3.
% LoadAllLibraries() called.  Currently loaded libraries: [listsInLogic, differentInLogic, modes_arithmeticInLogic, inlines_comparisonInLogic, modes_listsInLogic, inlines_differentInLogic, modes_differentInLogic, arithmeticInLogic, inlines_listsInLogic, modes_comparisonInLogic, comparisonInLogic, inlines_arithmeticInLogic]

%  Read the facts.
%  Have read 414 facts.
% Have read 16 examples from 'test' [test/test*].
% Have read 32 examples from 'test' [test/test*].

%  LearnOneClause initialized.

% The outer looper has been created.

% Initializing the ILP inner looper.

% NEW target:                 advisedby(D, E)
%  targetPred:                advisedby/2
%  targetArgTypes:            signature = [const, const], types = [+person, +person]
%  targets:                   [advisedby(D, E)]
%  targetPredicates:          [advisedby/2]
%  targetArgSpecs:            [[D[+person], E[+person]]]
%  variablesInTargets:        [[D, E]]

% Started collecting constants

% Collecting the types of constants.

% Looking at the training examples to see if any types of new constants can be inferred.
% Time to collect constants: 11 milliseconds
% Time to collect examples: 0 seconds

% Read 16 pos examples and 32 neg examples.
% Time to init learnOneClause: 15 milliseconds
% Old dirtrain/models/

% Have 16 'raw' positive examples and kept 16.
% Have 32 'raw' negative examples and kept 32.

% processing backup's for advisedby
%  POS EX = 16
%  NEG EX = 32

% Memory usage by WILLSetup (just counts # targets?):
%  |backupPosExamples| = 1
%  |backupNegExamples| = 1
%  |predicatesAsFacts| = 0
%  |addedToFactBase|   = 0

% Getting bRDN's target predicates.
% Did not learn a model for 'advisedby' this run.
%   loadModel (#0): train/models/bRDNs/Trees/advisedbyTree0.tree
%   loadModel (#1): train/models/bRDNs/Trees/advisedbyTree1.tree
%   loadModel (#2): train/models/bRDNs/Trees/advisedbyTree2.tree
%   loadModel (#3): train/models/bRDNs/Trees/advisedbyTree3.tree
%   loadModel (#4): train/models/bRDNs/Trees/advisedbyTree4.tree
%   loadModel (#5): train/models/bRDNs/Trees/advisedbyTree5.tree
%   loadModel (#6): train/models/bRDNs/Trees/advisedbyTree6.tree
%   loadModel (#7): train/models/bRDNs/Trees/advisedbyTree7.tree
%   loadModel (#8): train/models/bRDNs/Trees/advisedbyTree8.tree
%   loadModel (#9): train/models/bRDNs/Trees/advisedbyTree9.tree
%  Done loading 10 models.
File: test/advice.txt doesnt exist.Hence no advice loaded

% for advisedby |lookupPos| = 16
% for advisedby |lookupNeg| = 32
% getJointExamples: |pos| = 16, |neg| = 32

% Starting inference in bRDN.
% Trees = 10

% Starting getMarginalProbabilities.
% [ LazyGroundClauseIndex ]  Building full index for professor/1 with 13 assertions.
% [ LazyGroundClauseIndex ]  Building full index for student/1 with 36 assertions.
% [ LazyGroundNthArgumentClauseIndex ]  Argument 1:  Building full index for publication/2.
% [ LazyGroundNthArgumentClauseIndex ]  Argument 1:  Building full index for ta/3.
% [ LazyGroundNthArgumentClauseIndex ]  Argument 1:  Building full index for projectmember/2.
% [ LazyGroundNthArgumentClauseIndex ]  Argument 0:  Building full index for ta/3.
% [ LazyGroundClauseIndex ]  Building full index for publication/2 with 112 assertions.
% No Gibbs sampling needed during inference.
 (Arithmetic) Mean Probability Assigned to Correct Output Class: 39,117/48,00 = 0,814930

 The weighted count of positive examples = 16,000 and the weighted count of negative examples = 32,000

printExamples: Writing out predictions (for Tuffy?) on 48 examples for 'advisedby' to:
  test/results_advisedby.db
 and to:
  test/query_advisedby.db
%    No need to compress since small: test/query_advisedby.db

% Computing Area Under Curves.
%Pos=16
%Neg=32
%LL:-5.740172348913631
%LL:-11.05395099830656

% Running command: java -jar ./auc.jar test/AUC/aucTemp.txt list 0.0
% WAITING FOR command: java -jar ./auc.jar test/AUC/aucTemp.txt list 0.0
% DONE WAITING FOR command: java -jar ./auc.jar test/AUC/aucTemp.txt list 0.0
Best F1 = 1.0
% F1 = 1.0
% Threshold = 0.42831436293393393

%   AUC ROC   = 0,982422
%   AUC PR    = 0,969743
%   CLL	      = -0,230291
%   Precision = 1,000000 at threshold = 0,500
%   Recall    = 0,812500
%   F1        = 0,896552

% Total inference time (10 trees): 509 milliseconds.
