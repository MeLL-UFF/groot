args[0] = -l
args[1] = -refine
args[3] = -transfer
args[5] = -train
args[7] = -target
args[9] = -trees

% Starting a LEARNING run of bRDN.

% Calling SETUP.
% Running on host: MacBook-Air-de-Leticia

% Switching to VarIndicator = uppercase.

% Unset'ing VarIndicator.

Resetting the LazyGroundNthArgumentClauseIndex.

% Calling ILPouterLoop from createRegressionOuterLooper.

% getInputArgWithDefaultValue: args=[train/train_pos.txt, train/train_neg.txt, train/train_bk.txt, train/train_facts.txt]
%  for N=0: args[N]=train/train_pos.txt

% getInputArgWithDefaultValue: args=[train/train_pos.txt, train/train_neg.txt, train/train_bk.txt, train/train_facts.txt]
%  for N=1: args[N]=train/train_neg.txt

% getInputArgWithDefaultValue: args=[train/train_pos.txt, train/train_neg.txt, train/train_bk.txt, train/train_facts.txt]
%  for N=2: args[N]=train/train_bk.txt

% getInputArgWithDefaultValue: args=[train/train_pos.txt, train/train_neg.txt, train/train_bk.txt, train/train_facts.txt]
%  for N=3: args[N]=train/train_facts.txt

% Welcome to the WILL ILP/SRL systems.


% Switching to VarIndicator = uppercase.

% Unset'ing VarIndicator.
% Reading background theory from dir: null
% Load '../background.txt'.

% Switching to VarIndicator = uppercase.

***** Warning: % Since this is the first setting of the notation for variables, will keep:
%   variableIndicator = uppercase *****


***** Warning: % Since this is the first setting of the notation for variables, will keep:
%   variableIndicator = uppercase *****

% [ LazyGroundClauseIndex ]  Building full index for mode/1 with 1 assertions.
% LoadAllModes() called.  Currently loaded modes: []
% [ LazyGroundClauseIndex ]  Building full index for sameAs/2 with 2 assertions.
% [ LazyGroundNthArgumentClauseIndex ]  Argument 1:  Building full index for exp/3.
% [ LazyGroundNthArgumentClauseIndex ]  Argument 0:  Building full index for log/3.
% LoadAllLibraries() called.  Currently loaded libraries: [listsInLogic, differentInLogic, modes_arithmeticInLogic, inlines_comparisonInLogic, modes_listsInLogic, inlines_differentInLogic, modes_differentInLogic, arithmeticInLogic, inlines_listsInLogic, modes_comparisonInLogic, comparisonInLogic, inlines_arithmeticInLogic]

%  Read the facts.
%  Have read 2.387 facts.
% Have read 113 examples from 'train' [train/train*].
% Have read 113 examples from 'train' [train/train*].

%  LearnOneClause initialized.

% The outer looper has been created.

% Initializing the ILP inner looper.

% NEW target:                 advisedby(D, E)
%  targetPred:                advisedby/2
%  targetArgTypes:            signature = [const, const], types = [+person, +person]
%  targets:                   [advisedby(D, E)]
%  targetPredicates:          [advisedby/2]
%  targetArgSpecs:            [[D[+person], E[+person]]]
%  variablesInTargets:        [[D, E]]

% Started collecting constants

% Collecting the types of constants.

% Looking at the training examples to see if any types of new constants can be inferred.
% Time to collect constants: 90 milliseconds
% Time to collect examples: 0 seconds

% Read 113 pos examples and 113 neg examples.
% Time to init learnOneClause: 107 milliseconds
% Old dirnull
Setting model dir

% Have 113 'raw' positive examples and kept 113.
% Have 113 'raw' negative examples and kept 113.

% processing backup's for advisedby
%  POS EX = 113
%  NEG EX = 113

% Memory usage by WILLSetup (just counts # targets?):
%  |backupPosExamples| = 1
%  |backupNegExamples| = 1
%  |predicatesAsFacts| = 0
%  |addedToFactBase|   = 0
train/models/
File: train/advice.txt doesnt exist.Hence no advice loaded
% Learning 10 trees in this iteration for advisedby

% Learn model for: advisedby
% Kept 113 of the 113 positive examples.
% Kept 113 of the 113 negative examples.
%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.25
Set score:0.0025
% Dataset size: 226
Computing probabilities
prob time:2 milliseconds
No hidden examples for : advisedby
Time to build dataset: 4 milliseconds
%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.2500000000000032
Set score:0.0025
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% Have these 10 positive seeds: 8 32 127 142 152 155 163 168 189 191

% The best node found: null

% target           = advisedby(D, E)
%     Score = -Infinity (regressionFit = Infinity, penalties=2.2E-7) for clause:  advisedby(_, _).  [covers 226,0/226,0 pos, 0,0/0,0 neg]

% Finding mapping for predicates: [actor]
% Number of legal mappings: 2
% [ LazyGroundClauseIndex ]  Building full index for student/1 with 216 assertions.
%     Score = -19,110295 (regressionFit = 19,110294, penalties=1.12E-6) for clause:  advisedby(_, A) :- student(A).  [covers 90,0/226,0 pos, 0,0/0,0 neg]
% [ LazyGroundClauseIndex ]  Building full index for professor/1 with 62 assertions.
%     Score = -19,110295 (regressionFit = 19,110294, penalties=1.12E-6) for clause:  advisedby(_, A) :- professor(A).  [covers 136,0/226,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(_, A) :- student(A).  [covers 90,0/226,0 pos, 0,0/0,0 neg]

% Expanding node at Level 0 with score = 1,797693e+308.
% Will extend: advisedby(_, A) :- student(A).  [covers 90,0/226,0 pos, 0,0/0,0 neg]
% Path: 0;
Comparing variance: 7.401486830834377E-17 to score=0.0025 #egs=90.0
Comparing variance: 0.14051686851211428 to score=0.0025 #egs=136.0
%   Creating a TRUE-branch leaf because good enough fit since score < 0.0025
%   Creating a FALSE-branch interior node with wgtedCountFalseBranchPos = 136,0
%      addToQueueOfTreeStructuredLearningTasks (level=1; score=-0,140517)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 1 and with score = -0,140517) into the LAST position (#1) in the search queue.

% Time for loop #1: 67 milliseconds.
% Internal node max length = 1
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 5
% Max number of clauses    = 12

% On cycle #1, the best clause found is:
%      advisedby(_, A) :- student(A).  [covers 90,0/226,0 pos, 0,0/0,0 neg]
% This clause covers 90 positive examples, of which 90 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Have these 10 positive seeds: 3 8 27 47 54 58 66 78 101 119

% The best node found: null

% Finding mapping for predicates: [female]
% Number of legal mappings: 1
%     Score = -12,456694 (regressionFit = 12,456693, penalties=1.12E-6) for clause:  advisedby(A, _) :- professor(A).  [covers 9,0/136,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, _) :- professor(A).  [covers 9,0/136,0 pos, 0,0/0,0 neg]

% Expanding node at Level 1 with score = -0,141.
% Will extend: advisedby(A, _) :- professor(A).  [covers 9,0/136,0 pos, 0,0/0,0 neg]
% Path: 0;false
Comparing variance: -9.25185853854297E-18 to score=0.0025 #egs=9.0
Comparing variance: 0.09808419616839577 to score=0.0025 #egs=127.0
%   Creating a TRUE-branch leaf because good enough fit since score < 0.0025
%   Creating a FALSE-branch interior node with wgtedCountFalseBranchPos = 127,0
%      addToQueueOfTreeStructuredLearningTasks (level=2; score=-0,098084)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 2 and with score = -0,098084) into the LAST position (#1) in the search queue.

% Time for loop #2: 19 milliseconds.
% Internal node max length = 1
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 5
% Max number of clauses    = 12

% On cycle #2, the best clause found is:
%      advisedby(A, _) :- professor(A).  [covers 9,0/136,0 pos, 0,0/0,0 neg]
% This clause covers 9 positive examples, of which 9 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Have these 3 positive seeds: 47 49 110

% The best node found: null
%     Score = -Infinity (regressionFit = Infinity, penalties=1.12E-6) for clause:  advisedby(A, _) :- student(A).  [covers 127,0/127,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, _) :- student(A).  [covers 127,0/127,0 pos, 0,0/0,0 neg]

% Expanding node at Level 2 with score = -0,098.
% Will extend: advisedby(A, _) :- student(A).  [covers 127,0/127,0 pos, 0,0/0,0 neg]
% Path: 0;false,false
Comparing variance: 0.09808419616839577 to score=0.0025 #egs=127.0
Comparing variance: NaN to score=0.0025 #egs=0.0
%   Creating a FALSE-branch leaf because wgtedCountFalseBranchPos = 0,0 < 2.1 * minPosCov = 6,3

% Time for loop #3: 72 milliseconds.
% Internal node max length = 1
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 5
% Max number of clauses    = 12

% On cycle #3, the best clause found is:
%      advisedby(A, _) :- student(A).  [covers 127,0/127,0 pos, 0,0/0,0 neg]
% This clause covers 127 positive examples, of which 127 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% ******************************************

%  Have stopped ILP's outer loop because the tree-structured queue is empty.

% ******************************************

%%%%%  WILL-Produced Tree #1 @ 15:20:52 9/29/20.  [Using 3.680.080 memory cells.]  %%%%%


% FOR advisedby(A, B):
%   if ( student(B) )
%   then return -0.14185106490048763;  // std dev = 8,16e-08, 90,000 (wgt'ed) examples reached here.  /* #neg=90 */
%   else if ( professor(A) )
%   | then return -0.1418510649004878;  // std dev = 0,000, 9,000 (wgt'ed) examples reached here.  /* #neg=9 */
%   | else if ( student(A) )
%   | | then return 0.7479127146270694;  // std dev = 3,529, 127,000 (wgt'ed) examples reached here.  /* #neg=14 #pos=113 */
%   | | else return 0;  // std dev = 0,000, 0,000 (wgt'ed) examples reached here.


% Clauses:

advisedby(A, B, -0.14185106490048763) :- 
     student(B), 
     !. // Clause #1.

advisedby(A, B, -0.1418510649004878) :- 
     professor(A), 
     !. // Clause #2.

advisedby(A, B, 0.7479127146270694) :- 
     student(A), 
     !. // Clause #3.

advisedby(A, B, 0) :- !. // Clause #4.


% The flattened versions of these clauses:

flattened_advisedby(underscore, a, -0.14185106490048763) :-  /* #neg=90 */ 
   student(a),
   !. // Flattened version of clause #1.

flattened_advisedby(a, underscore, -0.1418510649004878) :-  /* #neg=9 */ 
   professor(a),
   !. // Flattened version of clause #2.

flattened_advisedby(a, underscore, 0.7479127146270694) :-  /* #neg=14 #pos=113 */ 
   student(a),
   !. // Flattened version of clause #3.

flattened_advisedby(underscore, underscore, 0) :- 
   !. // Flattened version of clause #4.


% The unique flattened literals:
%   professor(a)
%   student(a)

% Saving model in: train/models/bRDNs/advisedby.model.ckpt
% Time taken to learn 1 trees is 299 milliseconds.

%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.09808419616839581
Set score:0.0025
% Only 226 out of 226 converged.
% Kept 113 of the 113 positive examples.
% Kept 113 of the 113 negative examples.
% Dataset size: 226
Computing probabilities
prob time:25 milliseconds
No hidden examples for : advisedby
Time to build dataset: 34 milliseconds
%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.19595182215484114
Set score:0.0025
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% Have these 10 positive seeds: 8 15 21 29 72 73 84 111 127 142

% The best node found: null

% target           = advisedby(D, E)
%     Score = -Infinity (regressionFit = Infinity, penalties=2.2E-7) for clause:  advisedby(_, _).  [covers 226,0/226,0 pos, 0,0/0,0 neg]
%     Score = -17,264998 (regressionFit = 17,264997, penalties=1.12E-6) for clause:  advisedby(_, A) :- student(A).  [covers 90,0/226,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(_, A) :- student(A).  [covers 90,0/226,0 pos, 0,0/0,0 neg]

% Expanding node at Level 0 with score = 1,797693e+308.
% Will extend: advisedby(_, A) :- student(A).  [covers 90,0/226,0 pos, 0,0/0,0 neg]
% Path: 1;
Comparing variance: -1.7270135938613546E-17 to score=0.0025 #egs=90.0
Comparing variance: 0.12694850615553416 to score=0.0025 #egs=136.0
%   Creating a TRUE-branch leaf because good enough fit since score < 0.0025
%   Creating a FALSE-branch interior node with wgtedCountFalseBranchPos = 136,0
%      addToQueueOfTreeStructuredLearningTasks (level=1; score=-0,126949)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 1 and with score = -0,126949) into the LAST position (#1) in the search queue.

% Time for loop #1: 18 milliseconds.
% Internal node max length = 1
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 5
% Max number of clauses    = 12

% On cycle #1, the best clause found is:
%      advisedby(_, A) :- student(A).  [covers 90,0/226,0 pos, 0,0/0,0 neg]
% This clause covers 90 positive examples, of which 90 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Have these 10 positive seeds: 22 31 43 45 47 58 62 64 80 90

% The best node found: null
%     Score = -12,456694 (regressionFit = 12,456693, penalties=1.12E-6) for clause:  advisedby(A, _) :- professor(A).  [covers 9,0/136,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, _) :- professor(A).  [covers 9,0/136,0 pos, 0,0/0,0 neg]

% Expanding node at Level 1 with score = -0,127.
% Will extend: advisedby(A, _) :- professor(A).  [covers 9,0/136,0 pos, 0,0/0,0 neg]
% Path: 1;false
Comparing variance: 0.0 to score=0.0025 #egs=9.0
Comparing variance: 0.09808419616839018 to score=0.0025 #egs=127.0
%   Creating a TRUE-branch leaf because good enough fit since score < 0.0025
%   Creating a FALSE-branch interior node with wgtedCountFalseBranchPos = 127,0
%      addToQueueOfTreeStructuredLearningTasks (level=2; score=-0,098084)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 2 and with score = -0,098084) into the LAST position (#1) in the search queue.

% Time for loop #2: 15 milliseconds.
% Internal node max length = 1
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 5
% Max number of clauses    = 12

% On cycle #2, the best clause found is:
%      advisedby(A, _) :- professor(A).  [covers 9,0/136,0 pos, 0,0/0,0 neg]
% This clause covers 9 positive examples, of which 9 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Have these 10 positive seeds: 3 11 24 26 38 39 44 45 49 73

% The best node found: null
%     Score = -Infinity (regressionFit = Infinity, penalties=1.12E-6) for clause:  advisedby(A, _) :- student(A).  [covers 127,0/127,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, _) :- student(A).  [covers 127,0/127,0 pos, 0,0/0,0 neg]

% Expanding node at Level 2 with score = -0,098.
% Will extend: advisedby(A, _) :- student(A).  [covers 127,0/127,0 pos, 0,0/0,0 neg]
% Path: 1;false,false
Comparing variance: 0.09808419616839018 to score=0.0025 #egs=127.0
Comparing variance: NaN to score=0.0025 #egs=0.0
%   Creating a FALSE-branch leaf because wgtedCountFalseBranchPos = 0,0 < 2.1 * minPosCov = 6,3

% Time for loop #3: 7 milliseconds.
% Internal node max length = 1
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 5
% Max number of clauses    = 12

% On cycle #3, the best clause found is:
%      advisedby(A, _) :- student(A).  [covers 127,0/127,0 pos, 0,0/0,0 neg]
% This clause covers 127 positive examples, of which 127 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% ******************************************

%  Have stopped ILP's outer loop because the tree-structured queue is empty.

% ******************************************

%%%%%  WILL-Produced Tree #2 @ 15:20:52 9/29/20.  [Using 3.742.960 memory cells.]  %%%%%


% FOR advisedby(A, B):
%   if ( student(B) )
%   then return -0.1254446385283914;  // std dev = 0,000, 90,000 (wgt'ed) examples reached here.  /* #neg=90 */
%   else if ( professor(A) )
%   | then return -0.12544463852839138;  // std dev = 0,000, 9,000 (wgt'ed) examples reached here.  /* #neg=9 */
%   | else if ( student(A) )
%   | | then return 0.6309392933122696;  // std dev = 3,529, 127,000 (wgt'ed) examples reached here.  /* #neg=14 #pos=113 */
%   | | else return 0;  // std dev = 0,000, 0,000 (wgt'ed) examples reached here.


% Clauses:

advisedby(A, B, -0.1254446385283914) :- 
     student(B), 
     !. // Clause #1.

advisedby(A, B, -0.12544463852839138) :- 
     professor(A), 
     !. // Clause #2.

advisedby(A, B, 0.6309392933122696) :- 
     student(A), 
     !. // Clause #3.

advisedby(A, B, 0) :- !. // Clause #4.


% The flattened versions of these clauses:

flattened_advisedby(underscore, a, -0.1254446385283914) :-  /* #neg=90 */ 
   student(a),
   !. // Flattened version of clause #1.

flattened_advisedby(a, underscore, -0.12544463852839138) :-  /* #neg=9 */ 
   professor(a),
   !. // Flattened version of clause #2.

flattened_advisedby(a, underscore, 0.6309392933122696) :-  /* #neg=14 #pos=113 */ 
   student(a),
   !. // Flattened version of clause #3.

flattened_advisedby(underscore, underscore, 0) :- 
   !. // Flattened version of clause #4.


% The unique flattened literals:
%   professor(a)
%   student(a)

% Saving model in: train/models/bRDNs/advisedby.model.ckpt
% Time taken to learn 2 trees is 509 milliseconds.

%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.0980841961683902
Set score:0.0025
% Only 226 out of 226 converged.
% Kept 113 of the 113 positive examples.
% Kept 113 of the 113 negative examples.
% Dataset size: 226
Computing probabilities
prob time:12 milliseconds
No hidden examples for : advisedby
Time to build dataset: 15 milliseconds
%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.14546956950458123
Set score:0.0025
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% Have these 7 positive seeds: 70 145 164 178 180 196 221

% The best node found: null

% target           = advisedby(D, E)
%     Score = -Infinity (regressionFit = Infinity, penalties=2.2E-7) for clause:  advisedby(_, _).  [covers 226,0/226,0 pos, 0,0/0,0 neg]
%     Score = -15,541447 (regressionFit = 15,541446, penalties=1.12E-6) for clause:  advisedby(_, A) :- student(A).  [covers 90,0/226,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(_, A) :- student(A).  [covers 90,0/226,0 pos, 0,0/0,0 neg]

% Expanding node at Level 0 with score = 1,797693e+308.
% Will extend: advisedby(_, A) :- student(A).  [covers 90,0/226,0 pos, 0,0/0,0 neg]
% Path: 2;
Comparing variance: 5.921189464667501E-17 to score=0.0025 #egs=90.0
Comparing variance: 0.11427534077154791 to score=0.0025 #egs=136.0
%   Creating a TRUE-branch leaf because good enough fit since score < 0.0025
%   Creating a FALSE-branch interior node with wgtedCountFalseBranchPos = 136,0
%      addToQueueOfTreeStructuredLearningTasks (level=1; score=-0,114275)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 1 and with score = -0,114275) into the LAST position (#1) in the search queue.

% Time for loop #1: 9 milliseconds.
% Internal node max length = 1
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 5
% Max number of clauses    = 12

% On cycle #1, the best clause found is:
%      advisedby(_, A) :- student(A).  [covers 90,0/226,0 pos, 0,0/0,0 neg]
% This clause covers 90 positive examples, of which 90 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Have these 10 positive seeds: 16 37 38 42 57 59 61 65 77 87

% The best node found: null

% Finding mapping for predicates: [director]
% Number of legal mappings: 1
%     Score = -12,456694 (regressionFit = 12,456693, penalties=1.12E-6) for clause:  advisedby(A, _) :- professor(A).  [covers 9,0/136,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, _) :- professor(A).  [covers 9,0/136,0 pos, 0,0/0,0 neg]

% Expanding node at Level 1 with score = -0,114.
% Will extend: advisedby(A, _) :- professor(A).  [covers 9,0/136,0 pos, 0,0/0,0 neg]
% Path: 2;false
Comparing variance: -1.5419764230904951E-18 to score=0.0025 #egs=9.0
Comparing variance: 0.09808419616839278 to score=0.0025 #egs=127.0
%   Creating a TRUE-branch leaf because good enough fit since score < 0.0025

% Time for loop #2: 10 milliseconds.
% Internal node max length = 1
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 5
% Max number of clauses    = 12

% On cycle #2, the best clause found is:
%      advisedby(A, _) :- professor(A).  [covers 9,0/136,0 pos, 0,0/0,0 neg]
% This clause covers 9 positive examples, of which 9 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% ******************************************

%  Have stopped ILP's outer loop because the tree-structured queue is empty.

% ******************************************

%%%%%  WILL-Produced Tree #3 @ 15:20:53 9/29/20.  [Using 3.795.536 memory cells.]  %%%%%


% FOR advisedby(A, B):
%   if ( student(B) )
%   then return -0.11231637819360621;  // std dev = 7,30e-08, 90,000 (wgt'ed) examples reached here.  /* #neg=90 */
%   else if ( professor(A) )
%   | then return -0.11231637819360639;  // std dev = 0,000, 9,000 (wgt'ed) examples reached here.  /* #neg=9 */
%   | else return 0.49352170114897687;  // std dev = 3,529, 127,000 (wgt'ed) examples reached here.  /* #neg=14 #pos=113 */


% Clauses:

advisedby(A, B, -0.11231637819360621) :- 
     student(B), 
     !. // Clause #1.

advisedby(A, B, -0.11231637819360639) :- 
     professor(A), 
     !. // Clause #2.

advisedby(A, B, 0.49352170114897687) :- !. // Clause #3.


% The flattened versions of these clauses:

flattened_advisedby(underscore, a, -0.11231637819360621) :-  /* #neg=90 */ 
   student(a),
   !. // Flattened version of clause #1.

flattened_advisedby(a, underscore, -0.11231637819360639) :-  /* #neg=9 */ 
   professor(a),
   !. // Flattened version of clause #2.

flattened_advisedby(underscore, underscore, 0.49352170114897687) :-  /* #neg=14 #pos=113 */ 
   !. // Flattened version of clause #3.


% The unique flattened literals:
%   professor(a)
%   student(a)

% Saving model in: train/models/bRDNs/advisedby.model.ckpt
% Time taken to learn 3 trees is 597 milliseconds.

%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.11427534077154794
Set score:0.0025
% Only 226 out of 226 converged.
% Kept 113 of the 113 positive examples.
% Kept 113 of the 113 negative examples.
% Dataset size: 226
Computing probabilities
prob time:11 milliseconds
No hidden examples for : advisedby
Time to build dataset: 14 milliseconds
%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.11025577723599178
Set score:0.0025
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% Have these 8 positive seeds: 1 29 114 137 152 181 205 206

% The best node found: null

% target           = advisedby(D, E)
%     Score = -Infinity (regressionFit = Infinity, penalties=2.2E-7) for clause:  advisedby(_, _).  [covers 226,0/226,0 pos, 0,0/0,0 neg]
%     Score = -14,339188 (regressionFit = 14,339187, penalties=1.12E-6) for clause:  advisedby(_, A) :- student(A).  [covers 90,0/226,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(_, A) :- student(A).  [covers 90,0/226,0 pos, 0,0/0,0 neg]

% Expanding node at Level 0 with score = 1,797693e+308.
% Will extend: advisedby(_, A) :- student(A).  [covers 90,0/226,0 pos, 0,0/0,0 neg]
% Path: 3;
Comparing variance: 2.837236618486511E-17 to score=0.0025 #egs=90.0
Comparing variance: 0.10543520013224252 to score=0.0025 #egs=136.0
%   Creating a TRUE-branch leaf because good enough fit since score < 0.0025
%   Creating a FALSE-branch interior node with wgtedCountFalseBranchPos = 136,0
%      addToQueueOfTreeStructuredLearningTasks (level=1; score=-0,105435)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 1 and with score = -0,105435) into the LAST position (#1) in the search queue.

% Time for loop #1: 16 milliseconds.
% Internal node max length = 1
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 5
% Max number of clauses    = 12

% On cycle #1, the best clause found is:
%      advisedby(_, A) :- student(A).  [covers 90,0/226,0 pos, 0,0/0,0 neg]
% This clause covers 90 positive examples, of which 90 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Have these 8 positive seeds: 3 23 34 59 77 96 106 123

% The best node found: null
%     Score = -12,456694 (regressionFit = 12,456693, penalties=1.12E-6) for clause:  advisedby(A, _) :- professor(A).  [covers 9,0/136,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, _) :- professor(A).  [covers 9,0/136,0 pos, 0,0/0,0 neg]

% Expanding node at Level 1 with score = -0,105.
% Will extend: advisedby(A, _) :- professor(A).  [covers 9,0/136,0 pos, 0,0/0,0 neg]
% Path: 3;false
Comparing variance: 3.0839528461809902E-18 to score=0.0025 #egs=9.0
Comparing variance: 0.09808419616839249 to score=0.0025 #egs=127.0
%   Creating a TRUE-branch leaf because good enough fit since score < 0.0025
%   Creating a FALSE-branch interior node with wgtedCountFalseBranchPos = 127,0
%      addToQueueOfTreeStructuredLearningTasks (level=2; score=-0,098084)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 2 and with score = -0,098084) into the LAST position (#1) in the search queue.

% Time for loop #2: 8 milliseconds.
% Internal node max length = 1
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 5
% Max number of clauses    = 12

% On cycle #2, the best clause found is:
%      advisedby(A, _) :- professor(A).  [covers 9,0/136,0 pos, 0,0/0,0 neg]
% This clause covers 9 positive examples, of which 9 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Have these 10 positive seeds: 8 16 23 25 33 78 89 96 98 109

% The best node found: null
%     Score = -Infinity (regressionFit = Infinity, penalties=1.12E-6) for clause:  advisedby(A, _) :- student(A).  [covers 127,0/127,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, _) :- student(A).  [covers 127,0/127,0 pos, 0,0/0,0 neg]

% Expanding node at Level 2 with score = -0,098.
% Will extend: advisedby(A, _) :- student(A).  [covers 127,0/127,0 pos, 0,0/0,0 neg]
% Path: 3;false,false
Comparing variance: 0.09808419616839249 to score=0.0025 #egs=127.0
Comparing variance: NaN to score=0.0025 #egs=0.0
%   Creating a FALSE-branch leaf because wgtedCountFalseBranchPos = 0,0 < 2.1 * minPosCov = 6,3

% Time for loop #3: 7 milliseconds.
% Internal node max length = 1
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 5
% Max number of clauses    = 12

% On cycle #3, the best clause found is:
%      advisedby(A, _) :- student(A).  [covers 127,0/127,0 pos, 0,0/0,0 neg]
% This clause covers 127 positive examples, of which 127 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% ******************************************

%  Have stopped ILP's outer loop because the tree-structured queue is empty.

% ******************************************

%%%%%  WILL-Produced Tree #4 @ 15:20:53 9/29/20.  [Using 3.841.704 memory cells.]  %%%%%


% FOR advisedby(A, B):
%   if ( student(B) )
%   then return -0.10159632948783621;  // std dev = 5,05e-08, 90,000 (wgt'ed) examples reached here.  /* #neg=90 */
%   else if ( professor(A) )
%   | then return -0.10159632948783627;  // std dev = 5,27e-09, 9,000 (wgt'ed) examples reached here.  /* #neg=9 */
%   | else if ( student(A) )
%   | | then return 0.37167824583218206;  // std dev = 3,529, 127,000 (wgt'ed) examples reached here.  /* #neg=14 #pos=113 */
%   | | else return 0;  // std dev = 0,000, 0,000 (wgt'ed) examples reached here.


% Clauses:

advisedby(A, B, -0.10159632948783621) :- 
     student(B), 
     !. // Clause #1.

advisedby(A, B, -0.10159632948783627) :- 
     professor(A), 
     !. // Clause #2.

advisedby(A, B, 0.37167824583218206) :- 
     student(A), 
     !. // Clause #3.

advisedby(A, B, 0) :- !. // Clause #4.


% The flattened versions of these clauses:

flattened_advisedby(underscore, a, -0.10159632948783621) :-  /* #neg=90 */ 
   student(a),
   !. // Flattened version of clause #1.

flattened_advisedby(a, underscore, -0.10159632948783627) :-  /* #neg=9 */ 
   professor(a),
   !. // Flattened version of clause #2.

flattened_advisedby(a, underscore, 0.37167824583218206) :-  /* #neg=14 #pos=113 */ 
   student(a),
   !. // Flattened version of clause #3.

flattened_advisedby(underscore, underscore, 0) :- 
   !. // Flattened version of clause #4.


% The unique flattened literals:
%   professor(a)
%   student(a)

% Saving model in: train/models/bRDNs/advisedby.model.ckpt
% Time taken to learn 4 trees is 703 milliseconds.

%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.0980841961683925
Set score:0.0025
% Only 226 out of 226 converged.
% Kept 113 of the 113 positive examples.
% Kept 113 of the 113 negative examples.
% Dataset size: 226
Computing probabilities
prob time:11 milliseconds
No hidden examples for : advisedby
Time to build dataset: 12 milliseconds
%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.08940888814286987
Set score:0.0025
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% Have these 10 positive seeds: 16 37 49 60 67 97 104 134 136 190

% The best node found: null

% target           = advisedby(D, E)
%     Score = -Infinity (regressionFit = Infinity, penalties=2.2E-7) for clause:  advisedby(_, _).  [covers 226,0/226,0 pos, 0,0/0,0 neg]
%     Score = -13,627440 (regressionFit = 13,627439, penalties=1.12E-6) for clause:  advisedby(_, A) :- student(A).  [covers 90,0/226,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(_, A) :- student(A).  [covers 90,0/226,0 pos, 0,0/0,0 neg]

% Expanding node at Level 0 with score = 1,797693e+308.
% Will extend: advisedby(_, A) :- student(A).  [covers 90,0/226,0 pos, 0,0/0,0 neg]
% Path: 4;
Comparing variance: 8.635067969306773E-18 to score=0.0025 #egs=90.0
Comparing variance: 0.10020175551856536 to score=0.0025 #egs=136.0
%   Creating a TRUE-branch leaf because good enough fit since score < 0.0025
%   Creating a FALSE-branch interior node with wgtedCountFalseBranchPos = 136,0
%      addToQueueOfTreeStructuredLearningTasks (level=1; score=-0,100202)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 1 and with score = -0,100202) into the LAST position (#1) in the search queue.

% Time for loop #1: 8 milliseconds.
% Internal node max length = 1
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 5
% Max number of clauses    = 12

% On cycle #1, the best clause found is:
%      advisedby(_, A) :- student(A).  [covers 90,0/226,0 pos, 0,0/0,0 neg]
% This clause covers 90 positive examples, of which 90 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Have these 10 positive seeds: 2 13 14 20 28 42 54 69 85 86

% The best node found: null
%     Score = -12,456694 (regressionFit = 12,456693, penalties=1.12E-6) for clause:  advisedby(A, _) :- professor(A).  [covers 9,0/136,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, _) :- professor(A).  [covers 9,0/136,0 pos, 0,0/0,0 neg]

% Expanding node at Level 1 with score = -0,100.
% Will extend: advisedby(A, _) :- professor(A).  [covers 9,0/136,0 pos, 0,0/0,0 neg]
% Path: 4;false
Comparing variance: 0.0 to score=0.0025 #egs=9.0
Comparing variance: 0.09808419616839231 to score=0.0025 #egs=127.0
%   Creating a TRUE-branch leaf because good enough fit since score < 0.0025
%   Creating a FALSE-branch interior node with wgtedCountFalseBranchPos = 127,0
%      addToQueueOfTreeStructuredLearningTasks (level=2; score=-0,098084)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 2 and with score = -0,098084) into the LAST position (#1) in the search queue.

% Time for loop #2: 4 milliseconds.
% Internal node max length = 1
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 5
% Max number of clauses    = 12

% On cycle #2, the best clause found is:
%      advisedby(A, _) :- professor(A).  [covers 9,0/136,0 pos, 0,0/0,0 neg]
% This clause covers 9 positive examples, of which 9 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Have these 7 positive seeds: 17 42 68 76 78 100 118

% The best node found: null
%     Score = -Infinity (regressionFit = Infinity, penalties=1.12E-6) for clause:  advisedby(A, _) :- student(A).  [covers 127,0/127,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, _) :- student(A).  [covers 127,0/127,0 pos, 0,0/0,0 neg]

% Expanding node at Level 2 with score = -0,098.
% Will extend: advisedby(A, _) :- student(A).  [covers 127,0/127,0 pos, 0,0/0,0 neg]
% Path: 4;false,false
Comparing variance: 0.09808419616839231 to score=0.0025 #egs=127.0
Comparing variance: NaN to score=0.0025 #egs=0.0
%   Creating a FALSE-branch leaf because wgtedCountFalseBranchPos = 0,0 < 2.1 * minPosCov = 6,3

% Time for loop #3: 7 milliseconds.
% Internal node max length = 1
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 5
% Max number of clauses    = 12

% On cycle #3, the best clause found is:
%      advisedby(A, _) :- student(A).  [covers 127,0/127,0 pos, 0,0/0,0 neg]
% This clause covers 127 positive examples, of which 127 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% ******************************************

%  Have stopped ILP's outer loop because the tree-structured queue is empty.

% ******************************************

%%%%%  WILL-Produced Tree #5 @ 15:20:53 9/29/20.  [Using 3.882.072 memory cells.]  %%%%%


% FOR advisedby(A, B):
%   if ( student(B) )
%   then return -0.09269127618926104;  // std dev = 2,79e-08, 90,000 (wgt'ed) examples reached here.  /* #neg=90 */
%   else if ( professor(A) )
%   | then return -0.09269127618926097;  // std dev = 0,000, 9,000 (wgt'ed) examples reached here.  /* #neg=9 */
%   | else if ( student(A) )
%   | | then return 0.2805396736953972;  // std dev = 3,529, 127,000 (wgt'ed) examples reached here.  /* #neg=14 #pos=113 */
%   | | else return 0;  // std dev = 0,000, 0,000 (wgt'ed) examples reached here.


% Clauses:

advisedby(A, B, -0.09269127618926104) :- 
     student(B), 
     !. // Clause #1.

advisedby(A, B, -0.09269127618926097) :- 
     professor(A), 
     !. // Clause #2.

advisedby(A, B, 0.2805396736953972) :- 
     student(A), 
     !. // Clause #3.

advisedby(A, B, 0) :- !. // Clause #4.


% The flattened versions of these clauses:

flattened_advisedby(underscore, a, -0.09269127618926104) :-  /* #neg=90 */ 
   student(a),
   !. // Flattened version of clause #1.

flattened_advisedby(a, underscore, -0.09269127618926097) :-  /* #neg=9 */ 
   professor(a),
   !. // Flattened version of clause #2.

flattened_advisedby(a, underscore, 0.2805396736953972) :-  /* #neg=14 #pos=113 */ 
   student(a),
   !. // Flattened version of clause #3.

flattened_advisedby(underscore, underscore, 0) :- 
   !. // Flattened version of clause #4.


% The unique flattened literals:
%   professor(a)
%   student(a)

% Saving model in: train/models/bRDNs/advisedby.model.ckpt
% Time taken to learn 5 trees is 786 milliseconds.

%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.09808419616839233
Set score:0.0025
% Only 226 out of 226 converged.
% Kept 113 of the 113 positive examples.
% Kept 113 of the 113 negative examples.
% Dataset size: 226
Computing probabilities
prob time:15 milliseconds
No hidden examples for : advisedby
Time to build dataset: 16 milliseconds
%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.07746979499689514
Set score:0.0025
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% Have these 9 positive seeds: 1 6 10 26 82 177 198 216 225

% The best node found: null

% target           = advisedby(D, E)
%     Score = -Infinity (regressionFit = Infinity, penalties=2.2E-7) for clause:  advisedby(_, _).  [covers 226,0/226,0 pos, 0,0/0,0 neg]
%     Score = -13,219819 (regressionFit = 13,219818, penalties=1.12E-6) for clause:  advisedby(_, A) :- student(A).  [covers 90,0/226,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(_, A) :- student(A).  [covers 90,0/226,0 pos, 0,0/0,0 neg]

% Expanding node at Level 0 with score = 1,797693e+308.
% Will extend: advisedby(_, A) :- student(A).  [covers 90,0/226,0 pos, 0,0/0,0 neg]
% Path: 5;
Comparing variance: 2.960594732333751E-17 to score=0.0025 #egs=90.0
Comparing variance: 0.09720454176461446 to score=0.0025 #egs=136.0
%   Creating a TRUE-branch leaf because good enough fit since score < 0.0025
%   Creating a FALSE-branch interior node with wgtedCountFalseBranchPos = 136,0
%      addToQueueOfTreeStructuredLearningTasks (level=1; score=-0,097205)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 1 and with score = -0,097205) into the LAST position (#1) in the search queue.

% Time for loop #1: 7 milliseconds.
% Internal node max length = 1
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 5
% Max number of clauses    = 12

% On cycle #1, the best clause found is:
%      advisedby(_, A) :- student(A).  [covers 90,0/226,0 pos, 0,0/0,0 neg]
% This clause covers 90 positive examples, of which 90 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Have these 9 positive seeds: 11 30 40 44 48 80 82 85 134

% The best node found: null
%     Score = -12,456694 (regressionFit = 12,456693, penalties=1.12E-6) for clause:  advisedby(A, _) :- professor(A).  [covers 9,0/136,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, _) :- professor(A).  [covers 9,0/136,0 pos, 0,0/0,0 neg]

% Expanding node at Level 1 with score = -0,097.
% Will extend: advisedby(A, _) :- professor(A).  [covers 9,0/136,0 pos, 0,0/0,0 neg]
% Path: 5;false
Comparing variance: 1.5419764230904951E-18 to score=0.0025 #egs=9.0
Comparing variance: 0.09808419616839224 to score=0.0025 #egs=127.0
%   Creating a TRUE-branch leaf because good enough fit since score < 0.0025
%   Creating a FALSE-branch interior node with wgtedCountFalseBranchPos = 127,0
%      addToQueueOfTreeStructuredLearningTasks (level=2; score=-0,098084)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 2 and with score = -0,098084) into the LAST position (#1) in the search queue.

% Time for loop #2: 4 milliseconds.
% Internal node max length = 1
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 5
% Max number of clauses    = 12

% On cycle #2, the best clause found is:
%      advisedby(A, _) :- professor(A).  [covers 9,0/136,0 pos, 0,0/0,0 neg]
% This clause covers 9 positive examples, of which 9 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Have these 9 positive seeds: 9 12 22 33 40 42 52 81 82

% The best node found: null
%     Score = -Infinity (regressionFit = Infinity, penalties=1.12E-6) for clause:  advisedby(A, _) :- student(A).  [covers 127,0/127,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, _) :- student(A).  [covers 127,0/127,0 pos, 0,0/0,0 neg]

% Expanding node at Level 2 with score = -0,098.
% Will extend: advisedby(A, _) :- student(A).  [covers 127,0/127,0 pos, 0,0/0,0 neg]
% Path: 5;false,false
Comparing variance: 0.09808419616839224 to score=0.0025 #egs=127.0
Comparing variance: NaN to score=0.0025 #egs=0.0
%   Creating a FALSE-branch leaf because wgtedCountFalseBranchPos = 0,0 < 2.1 * minPosCov = 6,3

% Time for loop #3: 3 milliseconds.
% Internal node max length = 1
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 5
% Max number of clauses    = 12

% On cycle #3, the best clause found is:
%      advisedby(A, _) :- student(A).  [covers 127,0/127,0 pos, 0,0/0,0 neg]
% This clause covers 127 positive examples, of which 127 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% ******************************************

%  Have stopped ILP's outer loop because the tree-structured queue is empty.

% ******************************************

%%%%%  WILL-Produced Tree #6 @ 15:20:53 9/29/20.  [Using 3.939.376 memory cells.]  %%%%%


% FOR advisedby(A, B):
%   if ( student(B) )
%   then return -0.08518475138839682;  // std dev = 5,16e-08, 90,000 (wgt'ed) examples reached here.  /* #neg=90 */
%   else if ( professor(A) )
%   | then return -0.08518475138839687;  // std dev = 3,73e-09, 9,000 (wgt'ed) examples reached here.  /* #neg=9 */
%   | else if ( student(A) )
%   | | then return 0.21614645702431154;  // std dev = 3,529, 127,000 (wgt'ed) examples reached here.  /* #neg=14 #pos=113 */
%   | | else return 0;  // std dev = 0,000, 0,000 (wgt'ed) examples reached here.


% Clauses:

advisedby(A, B, -0.08518475138839682) :- 
     student(B), 
     !. // Clause #1.

advisedby(A, B, -0.08518475138839687) :- 
     professor(A), 
     !. // Clause #2.

advisedby(A, B, 0.21614645702431154) :- 
     student(A), 
     !. // Clause #3.

advisedby(A, B, 0) :- !. // Clause #4.


% The flattened versions of these clauses:

flattened_advisedby(underscore, a, -0.08518475138839682) :-  /* #neg=90 */ 
   student(a),
   !. // Flattened version of clause #1.

flattened_advisedby(a, underscore, -0.08518475138839687) :-  /* #neg=9 */ 
   professor(a),
   !. // Flattened version of clause #2.

flattened_advisedby(a, underscore, 0.21614645702431154) :-  /* #neg=14 #pos=113 */ 
   student(a),
   !. // Flattened version of clause #3.

flattened_advisedby(underscore, underscore, 0) :- 
   !. // Flattened version of clause #4.


% The unique flattened literals:
%   professor(a)
%   student(a)

% Saving model in: train/models/bRDNs/advisedby.model.ckpt
% Time taken to learn 6 trees is 862 milliseconds.

%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.09808419616839226
Set score:0.0025
% Only 226 out of 226 converged.
% Kept 113 of the 113 positive examples.
% Kept 113 of the 113 negative examples.
% Dataset size: 226
Computing probabilities
prob time:18 milliseconds
No hidden examples for : advisedby
Time to build dataset: 20 milliseconds
%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.07041623021831854
Set score:0.0025
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% Have these 7 positive seeds: 2 20 41 43 67 119 176

% The best node found: null

% target           = advisedby(D, E)
%     Score = -Infinity (regressionFit = Infinity, penalties=2.2E-7) for clause:  advisedby(_, _).  [covers 226,0/226,0 pos, 0,0/0,0 neg]
%     Score = -12,978998 (regressionFit = 12,978997, penalties=1.12E-6) for clause:  advisedby(_, A) :- student(A).  [covers 90,0/226,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(_, A) :- student(A).  [covers 90,0/226,0 pos, 0,0/0,0 neg]

% Expanding node at Level 0 with score = 1,797693e+308.
% Will extend: advisedby(_, A) :- student(A).  [covers 90,0/226,0 pos, 0,0/0,0 neg]
% Path: 6;
Comparing variance: 2.960594732333751E-17 to score=0.0025 #egs=90.0
Comparing variance: 0.09543380079540953 to score=0.0025 #egs=136.0
%   Creating a TRUE-branch leaf because good enough fit since score < 0.0025
%   Creating a FALSE-branch interior node with wgtedCountFalseBranchPos = 136,0
%      addToQueueOfTreeStructuredLearningTasks (level=1; score=-0,095434)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 1 and with score = -0,095434) into the LAST position (#1) in the search queue.

% Time for loop #1: 11 milliseconds.
% Internal node max length = 1
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 5
% Max number of clauses    = 12

% On cycle #1, the best clause found is:
%      advisedby(_, A) :- student(A).  [covers 90,0/226,0 pos, 0,0/0,0 neg]
% This clause covers 90 positive examples, of which 90 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Have these 10 positive seeds: 0 13 24 28 30 34 43 48 53 65

% The best node found: null
%     Score = -12,456694 (regressionFit = 12,456693, penalties=1.12E-6) for clause:  advisedby(A, _) :- professor(A).  [covers 9,0/136,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, _) :- professor(A).  [covers 9,0/136,0 pos, 0,0/0,0 neg]

% Expanding node at Level 1 with score = -0,095.
% Will extend: advisedby(A, _) :- professor(A).  [covers 9,0/136,0 pos, 0,0/0,0 neg]
% Path: 6;false
Comparing variance: 0.0 to score=0.0025 #egs=9.0
Comparing variance: 0.09808419616839238 to score=0.0025 #egs=127.0
%   Creating a TRUE-branch leaf because good enough fit since score < 0.0025
%   Creating a FALSE-branch interior node with wgtedCountFalseBranchPos = 127,0
%      addToQueueOfTreeStructuredLearningTasks (level=2; score=-0,098084)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 2 and with score = -0,098084) into the LAST position (#1) in the search queue.

% Time for loop #2: 8 milliseconds.
% Internal node max length = 1
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 5
% Max number of clauses    = 12

% On cycle #2, the best clause found is:
%      advisedby(A, _) :- professor(A).  [covers 9,0/136,0 pos, 0,0/0,0 neg]
% This clause covers 9 positive examples, of which 9 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Have these 10 positive seeds: 11 20 35 45 49 69 71 90 103 105

% The best node found: null
%     Score = -Infinity (regressionFit = Infinity, penalties=1.12E-6) for clause:  advisedby(A, _) :- student(A).  [covers 127,0/127,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, _) :- student(A).  [covers 127,0/127,0 pos, 0,0/0,0 neg]

% Expanding node at Level 2 with score = -0,098.
% Will extend: advisedby(A, _) :- student(A).  [covers 127,0/127,0 pos, 0,0/0,0 neg]
% Path: 6;false,false
Comparing variance: 0.09808419616839238 to score=0.0025 #egs=127.0
Comparing variance: NaN to score=0.0025 #egs=0.0
%   Creating a FALSE-branch leaf because wgtedCountFalseBranchPos = 0,0 < 2.1 * minPosCov = 6,3

% Time for loop #3: 5 milliseconds.
% Internal node max length = 1
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 5
% Max number of clauses    = 12

% On cycle #3, the best clause found is:
%      advisedby(A, _) :- student(A).  [covers 127,0/127,0 pos, 0,0/0,0 neg]
% This clause covers 127 positive examples, of which 127 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% ******************************************

%  Have stopped ILP's outer loop because the tree-structured queue is empty.

% ******************************************

%%%%%  WILL-Produced Tree #7 @ 15:20:53 9/29/20.  [Using 3.978.496 memory cells.]  %%%%%


% FOR advisedby(A, B):
%   if ( student(B) )
%   then return -0.07877675473109161;  // std dev = 5,16e-08, 90,000 (wgt'ed) examples reached here.  /* #neg=90 */
%   else if ( professor(A) )
%   | then return -0.07877675473109173;  // std dev = 0,000, 9,000 (wgt'ed) examples reached here.  /* #neg=9 */
%   | else if ( student(A) )
%   | | then return 0.17051505636407485;  // std dev = 3,529, 127,000 (wgt'ed) examples reached here.  /* #neg=14 #pos=113 */
%   | | else return 0;  // std dev = 0,000, 0,000 (wgt'ed) examples reached here.


% Clauses:

advisedby(A, B, -0.07877675473109161) :- 
     student(B), 
     !. // Clause #1.

advisedby(A, B, -0.07877675473109173) :- 
     professor(A), 
     !. // Clause #2.

advisedby(A, B, 0.17051505636407485) :- 
     student(A), 
     !. // Clause #3.

advisedby(A, B, 0) :- !. // Clause #4.


% The flattened versions of these clauses:

flattened_advisedby(underscore, a, -0.07877675473109161) :-  /* #neg=90 */ 
   student(a),
   !. // Flattened version of clause #1.

flattened_advisedby(a, underscore, -0.07877675473109173) :-  /* #neg=9 */ 
   professor(a),
   !. // Flattened version of clause #2.

flattened_advisedby(a, underscore, 0.17051505636407485) :-  /* #neg=14 #pos=113 */ 
   student(a),
   !. // Flattened version of clause #3.

flattened_advisedby(underscore, underscore, 0) :- 
   !. // Flattened version of clause #4.


% The unique flattened literals:
%   professor(a)
%   student(a)

% Saving model in: train/models/bRDNs/advisedby.model.ckpt
% Time taken to learn 7 trees is 964 milliseconds.

%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.09808419616839237
Set score:0.0025
% Only 226 out of 226 converged.
% Kept 113 of the 113 positive examples.
% Kept 113 of the 113 negative examples.
% Dataset size: 226
Computing probabilities
prob time:43 milliseconds
No hidden examples for : advisedby
Time to build dataset: 49 milliseconds
%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.06604091093430547
Set score:0.0025
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% Have these 8 positive seeds: 29 50 62 78 143 165 182 222

% The best node found: null

% target           = advisedby(D, E)
%     Score = -Infinity (regressionFit = Infinity, penalties=2.2E-7) for clause:  advisedby(_, _).  [covers 226,0/226,0 pos, 0,0/0,0 neg]
%     Score = -12,829617 (regressionFit = 12,829616, penalties=1.12E-6) for clause:  advisedby(_, A) :- student(A).  [covers 90,0/226,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(_, A) :- student(A).  [covers 90,0/226,0 pos, 0,0/0,0 neg]

% Expanding node at Level 0 with score = 1,797693e+308.
% Will extend: advisedby(_, A) :- student(A).  [covers 90,0/226,0 pos, 0,0/0,0 neg]
% Path: 7;
Comparing variance: -8.018277400070574E-18 to score=0.0025 #egs=90.0
Comparing variance: 0.09433541191648595 to score=0.0025 #egs=136.0
%   Creating a TRUE-branch leaf because good enough fit since score < 0.0025
%   Creating a FALSE-branch interior node with wgtedCountFalseBranchPos = 136,0
%      addToQueueOfTreeStructuredLearningTasks (level=1; score=-0,094335)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 1 and with score = -0,094335) into the LAST position (#1) in the search queue.

% Time for loop #1: 10 milliseconds.
% Internal node max length = 1
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 5
% Max number of clauses    = 12

% On cycle #1, the best clause found is:
%      advisedby(_, A) :- student(A).  [covers 90,0/226,0 pos, 0,0/0,0 neg]
% This clause covers 90 positive examples, of which 90 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Have these 10 positive seeds: 16 18 19 25 28 34 64 70 91 97

% The best node found: null
%     Score = -12,456694 (regressionFit = 12,456693, penalties=1.12E-6) for clause:  advisedby(A, _) :- professor(A).  [covers 9,0/136,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, _) :- professor(A).  [covers 9,0/136,0 pos, 0,0/0,0 neg]

% Expanding node at Level 1 with score = -0,094.
% Will extend: advisedby(A, _) :- professor(A).  [covers 9,0/136,0 pos, 0,0/0,0 neg]
% Path: 7;false
Comparing variance: 7.709882115452476E-19 to score=0.0025 #egs=9.0
Comparing variance: 0.09808419616839215 to score=0.0025 #egs=127.0
%   Creating a TRUE-branch leaf because good enough fit since score < 0.0025
%   Creating a FALSE-branch interior node with wgtedCountFalseBranchPos = 127,0
%      addToQueueOfTreeStructuredLearningTasks (level=2; score=-0,098084)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 2 and with score = -0,098084) into the LAST position (#1) in the search queue.

% Time for loop #2: 5 milliseconds.
% Internal node max length = 1
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 5
% Max number of clauses    = 12

% On cycle #2, the best clause found is:
%      advisedby(A, _) :- professor(A).  [covers 9,0/136,0 pos, 0,0/0,0 neg]
% This clause covers 9 positive examples, of which 9 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Have these 10 positive seeds: 3 4 7 19 21 58 59 80 84 92

% The best node found: null
%     Score = -Infinity (regressionFit = Infinity, penalties=1.12E-6) for clause:  advisedby(A, _) :- student(A).  [covers 127,0/127,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, _) :- student(A).  [covers 127,0/127,0 pos, 0,0/0,0 neg]

% Expanding node at Level 2 with score = -0,098.
% Will extend: advisedby(A, _) :- student(A).  [covers 127,0/127,0 pos, 0,0/0,0 neg]
% Path: 7;false,false
Comparing variance: 0.09808419616839215 to score=0.0025 #egs=127.0
Comparing variance: NaN to score=0.0025 #egs=0.0
%   Creating a FALSE-branch leaf because wgtedCountFalseBranchPos = 0,0 < 2.1 * minPosCov = 6,3

% Time for loop #3: 4 milliseconds.
% Internal node max length = 1
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 5
% Max number of clauses    = 12

% On cycle #3, the best clause found is:
%      advisedby(A, _) :- student(A).  [covers 127,0/127,0 pos, 0,0/0,0 neg]
% This clause covers 127 positive examples, of which 127 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% ******************************************

%  Have stopped ILP's outer loop because the tree-structured queue is empty.

% ******************************************

%%%%%  WILL-Produced Tree #8 @ 15:20:53 9/29/20.  [Using 4.024.968 memory cells.]  %%%%%


% FOR advisedby(A, B):
%   if ( student(B) )
%   then return -0.07324622576333707;  // std dev = 0,000, 90,000 (wgt'ed) examples reached here.  /* #neg=90 */
%   else if ( professor(A) )
%   | then return -0.07324622576333704;  // std dev = 2,63e-09, 9,000 (wgt'ed) examples reached here.  /* #neg=9 */
%   | else if ( student(A) )
%   | | then return 0.1374011175040191;  // std dev = 3,529, 127,000 (wgt'ed) examples reached here.  /* #neg=14 #pos=113 */
%   | | else return 0;  // std dev = 0,000, 0,000 (wgt'ed) examples reached here.


% Clauses:

advisedby(A, B, -0.07324622576333707) :- 
     student(B), 
     !. // Clause #1.

advisedby(A, B, -0.07324622576333704) :- 
     professor(A), 
     !. // Clause #2.

advisedby(A, B, 0.1374011175040191) :- 
     student(A), 
     !. // Clause #3.

advisedby(A, B, 0) :- !. // Clause #4.


% The flattened versions of these clauses:

flattened_advisedby(underscore, a, -0.07324622576333707) :-  /* #neg=90 */ 
   student(a),
   !. // Flattened version of clause #1.

flattened_advisedby(a, underscore, -0.07324622576333704) :-  /* #neg=9 */ 
   professor(a),
   !. // Flattened version of clause #2.

flattened_advisedby(a, underscore, 0.1374011175040191) :-  /* #neg=14 #pos=113 */ 
   student(a),
   !. // Flattened version of clause #3.

flattened_advisedby(underscore, underscore, 0) :- 
   !. // Flattened version of clause #4.


% The unique flattened literals:
%   professor(a)
%   student(a)

% Saving model in: train/models/bRDNs/advisedby.model.ckpt
% Time taken to learn 8 trees is 1,105 seconds.

%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.09808419616839215
Set score:0.0025
% Only 226 out of 226 converged.
% Kept 113 of the 113 positive examples.
% Kept 113 of the 113 negative examples.
% Dataset size: 226
Computing probabilities
prob time:14 milliseconds
No hidden examples for : advisedby
Time to build dataset: 16 milliseconds
%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.06319369049581476
Set score:0.0025
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% Have these 6 positive seeds: 24 27 51 102 123 165

% The best node found: null

% target           = advisedby(D, E)
%     Score = -Infinity (regressionFit = Infinity, penalties=2.2E-7) for clause:  advisedby(_, _).  [covers 226,0/226,0 pos, 0,0/0,0 neg]
%     Score = -12,732408 (regressionFit = 12,732407, penalties=1.12E-6) for clause:  advisedby(_, A) :- student(A).  [covers 90,0/226,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(_, A) :- student(A).  [covers 90,0/226,0 pos, 0,0/0,0 neg]

% Expanding node at Level 0 with score = 1,797693e+308.
% Will extend: advisedby(_, A) :- student(A).  [covers 90,0/226,0 pos, 0,0/0,0 neg]
% Path: 8;
Comparing variance: 2.0970879354030734E-17 to score=0.0025 #egs=90.0
Comparing variance: 0.09362064001928772 to score=0.0025 #egs=136.0
%   Creating a TRUE-branch leaf because good enough fit since score < 0.0025
%   Creating a FALSE-branch interior node with wgtedCountFalseBranchPos = 136,0
%      addToQueueOfTreeStructuredLearningTasks (level=1; score=-0,093621)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 1 and with score = -0,093621) into the LAST position (#1) in the search queue.

% Time for loop #1: 5 milliseconds.
% Internal node max length = 1
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 5
% Max number of clauses    = 12

% On cycle #1, the best clause found is:
%      advisedby(_, A) :- student(A).  [covers 90,0/226,0 pos, 0,0/0,0 neg]
% This clause covers 90 positive examples, of which 90 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Have these 10 positive seeds: 19 40 51 53 54 73 76 79 85 95

% The best node found: null
%     Score = -12,456694 (regressionFit = 12,456693, penalties=1.12E-6) for clause:  advisedby(A, _) :- professor(A).  [covers 9,0/136,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, _) :- professor(A).  [covers 9,0/136,0 pos, 0,0/0,0 neg]

% Expanding node at Level 1 with score = -0,094.
% Will extend: advisedby(A, _) :- professor(A).  [covers 9,0/136,0 pos, 0,0/0,0 neg]
% Path: 8;false
Comparing variance: 0.0 to score=0.0025 #egs=9.0
Comparing variance: 0.09808419616839213 to score=0.0025 #egs=127.0
%   Creating a TRUE-branch leaf because good enough fit since score < 0.0025
%   Creating a FALSE-branch interior node with wgtedCountFalseBranchPos = 127,0
%      addToQueueOfTreeStructuredLearningTasks (level=2; score=-0,098084)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 2 and with score = -0,098084) into the LAST position (#1) in the search queue.

% Time for loop #2: 3 milliseconds.
% Internal node max length = 1
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 5
% Max number of clauses    = 12

% On cycle #2, the best clause found is:
%      advisedby(A, _) :- professor(A).  [covers 9,0/136,0 pos, 0,0/0,0 neg]
% This clause covers 9 positive examples, of which 9 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Have these 8 positive seeds: 0 5 30 41 72 77 78 116

% The best node found: null
%     Score = -Infinity (regressionFit = Infinity, penalties=1.12E-6) for clause:  advisedby(A, _) :- student(A).  [covers 127,0/127,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, _) :- student(A).  [covers 127,0/127,0 pos, 0,0/0,0 neg]

% Expanding node at Level 2 with score = -0,098.
% Will extend: advisedby(A, _) :- student(A).  [covers 127,0/127,0 pos, 0,0/0,0 neg]
% Path: 8;false,false
Comparing variance: 0.09808419616839213 to score=0.0025 #egs=127.0
Comparing variance: NaN to score=0.0025 #egs=0.0
%   Creating a FALSE-branch leaf because wgtedCountFalseBranchPos = 0,0 < 2.1 * minPosCov = 6,3

% Time for loop #3: 2 milliseconds.
% Internal node max length = 1
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 5
% Max number of clauses    = 12

% On cycle #3, the best clause found is:
%      advisedby(A, _) :- student(A).  [covers 127,0/127,0 pos, 0,0/0,0 neg]
% This clause covers 127 positive examples, of which 127 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% ******************************************

%  Have stopped ILP's outer loop because the tree-structured queue is empty.

% ******************************************

%%%%%  WILL-Produced Tree #9 @ 15:20:53 9/29/20.  [Using 4.063.984 memory cells.]  %%%%%


% FOR advisedby(A, B):
%   if ( student(B) )
%   then return -0.06842697784420265;  // std dev = 4,34e-08, 90,000 (wgt'ed) examples reached here.  /* #neg=90 */
%   else if ( professor(A) )
%   | then return -0.06842697784420272;  // std dev = 0,000, 9,000 (wgt'ed) examples reached here.  /* #neg=9 */
%   | else if ( student(A) )
%   | | then return 0.11269695940364122;  // std dev = 3,529, 127,000 (wgt'ed) examples reached here.  /* #neg=14 #pos=113 */
%   | | else return 0;  // std dev = 0,000, 0,000 (wgt'ed) examples reached here.


% Clauses:

advisedby(A, B, -0.06842697784420265) :- 
     student(B), 
     !. // Clause #1.

advisedby(A, B, -0.06842697784420272) :- 
     professor(A), 
     !. // Clause #2.

advisedby(A, B, 0.11269695940364122) :- 
     student(A), 
     !. // Clause #3.

advisedby(A, B, 0) :- !. // Clause #4.


% The flattened versions of these clauses:

flattened_advisedby(underscore, a, -0.06842697784420265) :-  /* #neg=90 */ 
   student(a),
   !. // Flattened version of clause #1.

flattened_advisedby(a, underscore, -0.06842697784420272) :-  /* #neg=9 */ 
   professor(a),
   !. // Flattened version of clause #2.

flattened_advisedby(a, underscore, 0.11269695940364122) :-  /* #neg=14 #pos=113 */ 
   student(a),
   !. // Flattened version of clause #3.

flattened_advisedby(underscore, underscore, 0) :- 
   !. // Flattened version of clause #4.


% The unique flattened literals:
%   professor(a)
%   student(a)

% Saving model in: train/models/bRDNs/advisedby.model.ckpt
% Time taken to learn 9 trees is 1,185 seconds.

%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.09808419616839213
Set score:0.0025
% Only 226 out of 226 converged.
% Kept 113 of the 113 positive examples.
% Kept 113 of the 113 negative examples.
% Dataset size: 226
Computing probabilities
prob time:15 milliseconds
No hidden examples for : advisedby
Time to build dataset: 16 milliseconds
%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.06126147736129472
Set score:0.0025
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% Have these 8 positive seeds: 59 99 102 107 111 145 156 169

% The best node found: null

% target           = advisedby(D, E)
%     Score = -Infinity (regressionFit = Infinity, penalties=2.2E-7) for clause:  advisedby(_, _).  [covers 226,0/226,0 pos, 0,0/0,0 neg]
%     Score = -12,666439 (regressionFit = 12,666438, penalties=1.12E-6) for clause:  advisedby(_, A) :- student(A).  [covers 90,0/226,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(_, A) :- student(A).  [covers 90,0/226,0 pos, 0,0/0,0 neg]

% Expanding node at Level 0 with score = 1,797693e+308.
% Will extend: advisedby(_, A) :- student(A).  [covers 90,0/226,0 pos, 0,0/0,0 neg]
% Path: 9;
Comparing variance: -1.295260195396016E-17 to score=0.0025 #egs=90.0
Comparing variance: 0.09313557338051207 to score=0.0025 #egs=136.0
%   Creating a TRUE-branch leaf because good enough fit since score < 0.0025
%   Creating a FALSE-branch interior node with wgtedCountFalseBranchPos = 136,0
%      addToQueueOfTreeStructuredLearningTasks (level=1; score=-0,093136)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 1 and with score = -0,093136) into the LAST position (#1) in the search queue.

% Time for loop #1: 5 milliseconds.
% Internal node max length = 1
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 5
% Max number of clauses    = 12

% On cycle #1, the best clause found is:
%      advisedby(_, A) :- student(A).  [covers 90,0/226,0 pos, 0,0/0,0 neg]
% This clause covers 90 positive examples, of which 90 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Have these 5 positive seeds: 38 76 105 110 132

% The best node found: null
%     Score = -12,456694 (regressionFit = 12,456693, penalties=1.12E-6) for clause:  advisedby(A, _) :- professor(A).  [covers 9,0/136,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, _) :- professor(A).  [covers 9,0/136,0 pos, 0,0/0,0 neg]

% Expanding node at Level 1 with score = -0,093.
% Will extend: advisedby(A, _) :- professor(A).  [covers 9,0/136,0 pos, 0,0/0,0 neg]
% Path: 9;false
Comparing variance: 7.709882115452476E-19 to score=0.0025 #egs=9.0
Comparing variance: 0.09808419616839216 to score=0.0025 #egs=127.0
%   Creating a TRUE-branch leaf because good enough fit since score < 0.0025
%   Creating a FALSE-branch interior node with wgtedCountFalseBranchPos = 127,0
%      addToQueueOfTreeStructuredLearningTasks (level=2; score=-0,098084)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 2 and with score = -0,098084) into the LAST position (#1) in the search queue.

% Time for loop #2: 2 milliseconds.
% Internal node max length = 1
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 5
% Max number of clauses    = 12

% On cycle #2, the best clause found is:
%      advisedby(A, _) :- professor(A).  [covers 9,0/136,0 pos, 0,0/0,0 neg]
% This clause covers 9 positive examples, of which 9 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Have these 10 positive seeds: 8 13 21 25 26 34 39 43 45 60

% The best node found: null
%     Score = -Infinity (regressionFit = Infinity, penalties=1.12E-6) for clause:  advisedby(A, _) :- student(A).  [covers 127,0/127,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, _) :- student(A).  [covers 127,0/127,0 pos, 0,0/0,0 neg]

% Expanding node at Level 2 with score = -0,098.
% Will extend: advisedby(A, _) :- student(A).  [covers 127,0/127,0 pos, 0,0/0,0 neg]
% Path: 9;false,false
Comparing variance: 0.09808419616839216 to score=0.0025 #egs=127.0
Comparing variance: NaN to score=0.0025 #egs=0.0
%   Creating a FALSE-branch leaf because wgtedCountFalseBranchPos = 0,0 < 2.1 * minPosCov = 6,3

% Time for loop #3: 2 milliseconds.
% Internal node max length = 1
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 5
% Max number of clauses    = 12

% On cycle #3, the best clause found is:
%      advisedby(A, _) :- student(A).  [covers 127,0/127,0 pos, 0,0/0,0 neg]
% This clause covers 127 positive examples, of which 127 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% ******************************************

%  Have stopped ILP's outer loop because the tree-structured queue is empty.

% ******************************************

%%%%%  WILL-Produced Tree #10 @ 15:20:53 9/29/20.  [Using 4.103.616 memory cells.]  %%%%%


% FOR advisedby(A, B):
%   if ( student(B) )
%   then return -0.06419184008202626;  // std dev = 0,000, 90,000 (wgt'ed) examples reached here.  /* #neg=90 */
%   else if ( professor(A) )
%   | then return -0.0641918400820262;  // std dev = 2,63e-09, 9,000 (wgt'ed) examples reached here.  /* #neg=9 */
%   | else if ( student(A) )
%   | | then return 0.09378456109669607;  // std dev = 3,529, 127,000 (wgt'ed) examples reached here.  /* #neg=14 #pos=113 */
%   | | else return 0;  // std dev = 0,000, 0,000 (wgt'ed) examples reached here.


% Clauses:

advisedby(A, B, -0.06419184008202626) :- 
     student(B), 
     !. // Clause #1.

advisedby(A, B, -0.0641918400820262) :- 
     professor(A), 
     !. // Clause #2.

advisedby(A, B, 0.09378456109669607) :- 
     student(A), 
     !. // Clause #3.

advisedby(A, B, 0) :- !. // Clause #4.


% The flattened versions of these clauses:

flattened_advisedby(underscore, a, -0.06419184008202626) :-  /* #neg=90 */ 
   student(a),
   !. // Flattened version of clause #1.

flattened_advisedby(a, underscore, -0.0641918400820262) :-  /* #neg=9 */ 
   professor(a),
   !. // Flattened version of clause #2.

flattened_advisedby(a, underscore, 0.09378456109669607) :-  /* #neg=14 #pos=113 */ 
   student(a),
   !. // Flattened version of clause #3.

flattened_advisedby(underscore, underscore, 0) :- 
   !. // Flattened version of clause #4.


% The unique flattened literals:
%   professor(a)
%   student(a)

% Saving model in: train/models/bRDNs/advisedby.model.ckpt
% Saving model in: train/models/bRDNs/advisedby.model


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%  Final call for computing score for advisedby.  %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

stepLength_tree1(1.0).
stepLength_tree2(1.0).
stepLength_tree3(1.0).
stepLength_tree4(1.0).
stepLength_tree5(1.0).
stepLength_tree6(1.0).
stepLength_tree7(1.0).
stepLength_tree8(1.0).
stepLength_tree9(1.0).
stepLength_tree10(1.0).

logPrior(-1.8).
advisedby(D, E, Total) :- // A general accessor. 
   advisedby(D, E, 1000000, Total), !.
advisedby(D, E, Total) :- waitHere("This should not fail", advisedby(D, E, Total)).

advisedby(D, E, TreesToUse, Total) :- // A tree-limited accessor (e.g., for tuning the number of trees to use).
   logPrior(LogPrior),
   getScore_advisedby_tree1(D, E, TreesToUse, Total1),
   getScore_advisedby_tree2(D, E, TreesToUse, Total2),
   getScore_advisedby_tree3(D, E, TreesToUse, Total3),
   getScore_advisedby_tree4(D, E, TreesToUse, Total4),
   getScore_advisedby_tree5(D, E, TreesToUse, Total5),
   getScore_advisedby_tree6(D, E, TreesToUse, Total6),
   getScore_advisedby_tree7(D, E, TreesToUse, Total7),
   getScore_advisedby_tree8(D, E, TreesToUse, Total8),
   getScore_advisedby_tree9(D, E, TreesToUse, Total9),
   getScore_advisedby_tree10(D, E, TreesToUse, Total10),
   Total is LogPrior + Total1 + Total2 + Total3 + Total4 + Total5 + Total6 + Total7 + Total8 + Total9 + Total10,
   !.
advisedby(D, E, TreesToUse, Total) :- waitHere("This should not fail", advisedby(D, E, TreesToUse, Total)).

getScore_advisedby_tree1(D, E, TreesToUse, 0.0) :- 1 > TreesToUse, !.
getScore_advisedby_tree1(D, E, TreesToUse, Total1) :- advisedby_tree1(D, E, Total), stepLength_tree1(StepLen), Total1 is Total * StepLen.

getScore_advisedby_tree2(D, E, TreesToUse, 0.0) :- 2 > TreesToUse, !.
getScore_advisedby_tree2(D, E, TreesToUse, Total2) :- advisedby_tree2(D, E, Total), stepLength_tree2(StepLen), Total2 is Total * StepLen.

getScore_advisedby_tree3(D, E, TreesToUse, 0.0) :- 3 > TreesToUse, !.
getScore_advisedby_tree3(D, E, TreesToUse, Total3) :- advisedby_tree3(D, E, Total), stepLength_tree3(StepLen), Total3 is Total * StepLen.

getScore_advisedby_tree4(D, E, TreesToUse, 0.0) :- 4 > TreesToUse, !.
getScore_advisedby_tree4(D, E, TreesToUse, Total4) :- advisedby_tree4(D, E, Total), stepLength_tree4(StepLen), Total4 is Total * StepLen.

getScore_advisedby_tree5(D, E, TreesToUse, 0.0) :- 5 > TreesToUse, !.
getScore_advisedby_tree5(D, E, TreesToUse, Total5) :- advisedby_tree5(D, E, Total), stepLength_tree5(StepLen), Total5 is Total * StepLen.

getScore_advisedby_tree6(D, E, TreesToUse, 0.0) :- 6 > TreesToUse, !.
getScore_advisedby_tree6(D, E, TreesToUse, Total6) :- advisedby_tree6(D, E, Total), stepLength_tree6(StepLen), Total6 is Total * StepLen.

getScore_advisedby_tree7(D, E, TreesToUse, 0.0) :- 7 > TreesToUse, !.
getScore_advisedby_tree7(D, E, TreesToUse, Total7) :- advisedby_tree7(D, E, Total), stepLength_tree7(StepLen), Total7 is Total * StepLen.

getScore_advisedby_tree8(D, E, TreesToUse, 0.0) :- 8 > TreesToUse, !.
getScore_advisedby_tree8(D, E, TreesToUse, Total8) :- advisedby_tree8(D, E, Total), stepLength_tree8(StepLen), Total8 is Total * StepLen.

getScore_advisedby_tree9(D, E, TreesToUse, 0.0) :- 9 > TreesToUse, !.
getScore_advisedby_tree9(D, E, TreesToUse, Total9) :- advisedby_tree9(D, E, Total), stepLength_tree9(StepLen), Total9 is Total * StepLen.

getScore_advisedby_tree10(D, E, TreesToUse, 0.0) :- 10 > TreesToUse, !.
getScore_advisedby_tree10(D, E, TreesToUse, Total10) :- advisedby_tree10(D, E, Total), stepLength_tree10(StepLen), Total10 is Total * StepLen.

flattenedLiteralsInThisSetOfTrees(advisedby, 2, [
   professor(a),
   student(a)]).
% Time taken to learn model for 'advisedby': 1,280 seconds.
% Saving model in: train/models/bRDNs/advisedby.model
cached groundings hit: 0
Misses: 0

% Total learning time (10 trees): 2,008 seconds.
