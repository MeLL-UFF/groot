args[0] = -l
args[1] = -refine
args[3] = -transfer
args[5] = -train
args[7] = -target
args[9] = -trees

% Starting a LEARNING run of bRDN.

% Calling SETUP.
% Running on host: Air-de-Leticia

% Switching to VarIndicator = uppercase.

% Unset'ing VarIndicator.

Resetting the LazyGroundNthArgumentClauseIndex.

% Calling ILPouterLoop from createRegressionOuterLooper.

% getInputArgWithDefaultValue: args=[train/train_pos.txt, train/train_neg.txt, train/train_bk.txt, train/train_facts.txt]
%  for N=0: args[N]=train/train_pos.txt

% getInputArgWithDefaultValue: args=[train/train_pos.txt, train/train_neg.txt, train/train_bk.txt, train/train_facts.txt]
%  for N=1: args[N]=train/train_neg.txt

% getInputArgWithDefaultValue: args=[train/train_pos.txt, train/train_neg.txt, train/train_bk.txt, train/train_facts.txt]
%  for N=2: args[N]=train/train_bk.txt

% getInputArgWithDefaultValue: args=[train/train_pos.txt, train/train_neg.txt, train/train_bk.txt, train/train_facts.txt]
%  for N=3: args[N]=train/train_facts.txt

% Welcome to the WILL ILP/SRL systems.


% Switching to VarIndicator = uppercase.

% Unset'ing VarIndicator.
% Reading background theory from dir: null
% Load '../background.txt'.

% Switching to VarIndicator = uppercase.

***** Warning: % Since this is the first setting of the notation for variables, will keep:
%   variableIndicator = uppercase *****


***** Warning: % Since this is the first setting of the notation for variables, will keep:
%   variableIndicator = uppercase *****

% [ LazyGroundClauseIndex ]  Building full index for mode/1 with 1 assertions.
% LoadAllModes() called.  Currently loaded modes: []
% [ LazyGroundClauseIndex ]  Building full index for sameAs/2 with 2 assertions.
% [ LazyGroundNthArgumentClauseIndex ]  Argument 1:  Building full index for exp/3.
% [ LazyGroundNthArgumentClauseIndex ]  Argument 0:  Building full index for log/3.
% LoadAllLibraries() called.  Currently loaded libraries: [listsInLogic, differentInLogic, modes_arithmeticInLogic, inlines_comparisonInLogic, modes_listsInLogic, inlines_differentInLogic, modes_differentInLogic, arithmeticInLogic, inlines_listsInLogic, modes_comparisonInLogic, comparisonInLogic, inlines_arithmeticInLogic]

%  Read the facts.
%  Have read 1.679 facts.
% Have read 78 examples from 'train' [train/train*].
% Have read 78 examples from 'train' [train/train*].

%  LearnOneClause initialized.

% The outer looper has been created.

% Initializing the ILP inner looper.

% NEW target:                 advisedby(D, E)
%  targetPred:                advisedby/2
%  targetArgTypes:            signature = [const, const], types = [+person, +person]
%  targets:                   [advisedby(D, E)]
%  targetPredicates:          [advisedby/2]
%  targetArgSpecs:            [[D[+person], E[+person]]]
%  variablesInTargets:        [[D, E]]

% Started collecting constants

% Collecting the types of constants.

% Looking at the training examples to see if any types of new constants can be inferred.
% Time to collect constants: 315 milliseconds
% Time to collect examples: 0 seconds

% Read 78 pos examples and 78 neg examples.
% Time to init learnOneClause: 349 milliseconds
% Old dirnull
Setting model dir

% Have 78 'raw' positive examples and kept 78.
% Have 78 'raw' negative examples and kept 78.

% processing backup's for advisedby
%  POS EX = 78
%  NEG EX = 78

% Memory usage by WILLSetup (just counts # targets?):
%  |backupPosExamples| = 1
%  |backupNegExamples| = 1
%  |predicatesAsFacts| = 0
%  |addedToFactBase|   = 0
train/models/
File: train/advice.txt doesnt exist.Hence no advice loaded
% Learning 10 trees in this iteration for advisedby

% Learn model for: advisedby
% Kept 78 of the 78 positive examples.
% Kept 78 of the 78 negative examples.
%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.25
Set score:0.0025
% Dataset size: 156
Computing probabilities
prob time:2 milliseconds
No hidden examples for : advisedby
Time to build dataset: 3 milliseconds
%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.25000000000000017
Set score:0.0025
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% Have these 10 positive seeds: 14 23 59 65 85 91 97 104 109 117

% The best node found: null

% target           = advisedby(D, E)
%     Score = -Infinity (regressionFit = Infinity, penalties=2.2E-7) for clause:  advisedby(_, _).  [covers 156,0/156,0 pos, 0,0/0,0 neg]
% [ LazyGroundClauseIndex ]  Building full index for professor/1 with 48 assertions.
%     Score = -14,625001 (regressionFit = 14,625000, penalties=1.12E-6) for clause:  advisedby(_, A) :- professor(A).  [covers 96,0/156,0 pos, 0,0/0,0 neg]
% [ LazyGroundClauseIndex ]  Building full index for student/1 with 162 assertions.
%     Score = -8,863638 (regressionFit = 8,863636, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- professor(B), student(A).  [covers 88,0/156,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- professor(B), student(A).  [covers 88,0/156,0 pos, 0,0/0,0 neg]

% Expanding node at Level 0 with score = 1,797693e+308.
% Will extend: advisedby(A, B) :- professor(B), student(A).  [covers 88,0/156,0 pos, 0,0/0,0 neg]
% Path: 0;
Comparing variance: 0.10072314049586789 to score=0.0025 #egs=88.0
Comparing variance: 5.224578939412501E-17 to score=0.0025 #egs=68.0
%   Creating a TRUE-branch interior node with wgtedCountTrueBranchPos = 88,0
%      addToQueueOfTreeStructuredLearningTasks (level=1; score=-0,100723)
%         ILP node to extend: advisedby(A, B) :- professor(B), student(A).  [covers 88,0/156,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 1 and with score = -0,100723) into the LAST position (#1) in the search queue.
%   Creating a FALSE-branch leaf because good enough fit since score < 0.0025

% Time for loop #1: 90 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #1, the best clause found is:
%      advisedby(A, B) :- professor(B), student(A).  [covers 88,0/156,0 pos, 0,0/0,0 neg]
% This clause covers 88 positive examples, of which 88 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- professor(B), student(A).  [covers 88,0/88,0 pos, 0,0/0,0 neg]'
%     Score = -8,863638 (regressionFit = 8,863636, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- professor(B), student(A).  [covers 88,0/88,0 pos, 0,0/0,0 neg]

% Have these 10 positive seeds: 0 25 27 28 38 50 52 57 61 67

% The best node found: null
% [ LazyGroundNthArgumentClauseIndex ]  Argument 1:  Building full index for tempadvisedby/2.
%     Score = -Infinity (regressionFit = Infinity, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(_, A).  [covers 0,0/88,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.9300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), tempadvisedby(C, A), tempadvisedby(C, B).  [covers 0,0/88,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- professor(B), student(A), tempadvisedby(C, A), tempadvisedby(C, B).  [covers 0,0/88,0 pos, 0,0/0,0 neg]

***** Warning: Have a bestNode that covers no positive examples.  That shouldn't happen.  Best node = advisedby(A, B) :- professor(B), student(A), tempadvisedby(C, A), tempadvisedby(C, B).  [covers 0,0/88,0 pos, 0,0/0,0 neg] *****


% Expanding node at Level 1 with score = -0,101.
% Will extend: advisedby(A, B) :- professor(B), student(A), tempadvisedby(C, A), tempadvisedby(C, B).  [covers 0,0/88,0 pos, 0,0/0,0 neg]
% Path: 0;true
Comparing variance: NaN to score=0.0025 #egs=0.0
Comparing variance: 0.10072314049586789 to score=0.0025 #egs=88.0
%   Creating a TRUE-branch leaf because wgtedCountTrueBranchPos = 0,0 < 2.1 * minPosCov = 6,3

% Time for loop #2: 47 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #2, the best clause found is:
%      advisedby(A, B) :- professor(B), student(A), tempadvisedby(C, A), tempadvisedby(C, B).  [covers 0,0/88,0 pos, 0,0/0,0 neg]
% This clause covers 0 positive examples, of which 0 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% ******************************************

%  Have stopped ILP's outer loop because the tree-structured queue is empty.

% ******************************************

%%%%%  WILL-Produced Tree #1 @ 20:41:17 12/15/20.  [Using 3.399.936 memory cells.]  %%%%%


% FOR advisedby(A, B):
%   if ( professor(B), student(A) )
%   then if ( tempadvisedby(C, A), tempadvisedby(C, B) )
%   | then return 0;  // std dev = 0,000, 0,000 (wgt'ed) examples reached here.
%   | else return 0.7445125714631483;  // std dev = 2,977, 88,000 (wgt'ed) examples reached here.  /* #neg=10 #pos=78 */
%   else return -0.14185106490048768;  // std dev = 5,96e-08, 68,000 (wgt'ed) examples reached here.  /* #neg=68 */


% Clauses:

advisedby(A, B, 0) :- 
     professor(B), 
     student(A), 
     tempadvisedby(C, A), 
     tempadvisedby(C, B), 
     !. // Clause #1.

advisedby(A, B, 0.7445125714631483) :- 
     professor(B), 
     student(A), 
     !. // Clause #2.

advisedby(A, B, -0.14185106490048768) :- !. // Clause #3.


% The flattened versions of these clauses:

flattened_advisedby(a, b, 0) :- 
   professor(b),
   student(a),
   tempadvisedby(uniqueVar1, a),
   tempadvisedby(uniqueVar1, b),
   !. // Flattened version of clause #1.

flattened_advisedby(a, b, 0.7445125714631483) :-  /* #neg=10 #pos=78 */ 
   professor(b),
   student(a),
   !. // Flattened version of clause #2.

flattened_advisedby(underscore, underscore, -0.14185106490048768) :-  /* #neg=68 */ 
   !. // Flattened version of clause #3.


% The unique flattened literals:
%   professor(b)
%   tempadvisedby(uniqueVar1, a)
%   tempadvisedby(uniqueVar1, b)
%   student(a)

% Saving model in: train/models/bRDNs/advisedby.model.ckpt
% Time taken to learn 1 trees is 301 milliseconds.

%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.10072314049586784
Set score:0.0025
% Only 156 out of 156 converged.
% Kept 78 of the 78 positive examples.
% Kept 78 of the 78 negative examples.
% Dataset size: 156
Computing probabilities
prob time:18 milliseconds
No hidden examples for : advisedby
Time to build dataset: 42 milliseconds
%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.1964759521781141
Set score:0.0025
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% Have these 10 positive seeds: 8 28 71 83 90 92 93 117 122 127

% The best node found: null

% target           = advisedby(D, E)
%     Score = -Infinity (regressionFit = Infinity, penalties=2.2E-7) for clause:  advisedby(_, _).  [covers 156,0/156,0 pos, 0,0/0,0 neg]
%     Score = -13,028725 (regressionFit = 13,028724, penalties=1.12E-6) for clause:  advisedby(_, A) :- professor(A).  [covers 96,0/156,0 pos, 0,0/0,0 neg]
%     Score = -8,863638 (regressionFit = 8,863636, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- professor(B), student(A).  [covers 88,0/156,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- professor(B), student(A).  [covers 88,0/156,0 pos, 0,0/0,0 neg]

% Expanding node at Level 0 with score = 1,797693e+308.
% Will extend: advisedby(A, B) :- professor(B), student(A).  [covers 88,0/156,0 pos, 0,0/0,0 neg]
% Path: 1;
Comparing variance: 0.1007231404958703 to score=0.0025 #egs=88.0
Comparing variance: -3.918434204559376E-17 to score=0.0025 #egs=68.0
%   Creating a TRUE-branch interior node with wgtedCountTrueBranchPos = 88,0
%      addToQueueOfTreeStructuredLearningTasks (level=1; score=-0,100723)
%         ILP node to extend: advisedby(A, B) :- professor(B), student(A).  [covers 88,0/156,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 1 and with score = -0,100723) into the LAST position (#1) in the search queue.
%   Creating a FALSE-branch leaf because good enough fit since score < 0.0025

% Time for loop #1: 39 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #1, the best clause found is:
%      advisedby(A, B) :- professor(B), student(A).  [covers 88,0/156,0 pos, 0,0/0,0 neg]
% This clause covers 88 positive examples, of which 88 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- professor(B), student(A).  [covers 88,0/88,0 pos, 0,0/0,0 neg]'
%     Score = -8,863638 (regressionFit = 8,863636, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- professor(B), student(A).  [covers 88,0/88,0 pos, 0,0/0,0 neg]

% Have these 10 positive seeds: 2 5 8 10 11 15 18 23 30 31

% The best node found: null
%     Score = -Infinity (regressionFit = Infinity, penalties=3.0300000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), advisedby(_, A).  [covers 0,0/88,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.9300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), advisedby(C, A), tempadvisedby(C, B).  [covers 0,0/88,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- professor(B), student(A), advisedby(C, A), tempadvisedby(C, B).  [covers 0,0/88,0 pos, 0,0/0,0 neg]

***** Warning: Have a bestNode that covers no positive examples.  That shouldn't happen.  Best node = advisedby(A, B) :- professor(B), student(A), advisedby(C, A), tempadvisedby(C, B).  [covers 0,0/88,0 pos, 0,0/0,0 neg] *****


% Expanding node at Level 1 with score = -0,101.
% Will extend: advisedby(A, B) :- professor(B), student(A), advisedby(C, A), tempadvisedby(C, B).  [covers 0,0/88,0 pos, 0,0/0,0 neg]
% Path: 1;true
Comparing variance: NaN to score=0.0025 #egs=0.0
Comparing variance: 0.1007231404958703 to score=0.0025 #egs=88.0
%   Creating a TRUE-branch leaf because wgtedCountTrueBranchPos = 0,0 < 2.1 * minPosCov = 6,3

% Time for loop #2: 39 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #2, the best clause found is:
%      advisedby(A, B) :- professor(B), student(A), advisedby(C, A), tempadvisedby(C, B).  [covers 0,0/88,0 pos, 0,0/0,0 neg]
% This clause covers 0 positive examples, of which 0 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% ******************************************

%  Have stopped ILP's outer loop because the tree-structured queue is empty.

% ******************************************

%%%%%  WILL-Produced Tree #2 @ 20:41:17 12/15/20.  [Using 3.450.040 memory cells.]  %%%%%


% FOR advisedby(A, B):
%   if ( professor(B), student(A) )
%   then if ( advisedby(C, A), tempadvisedby(C, B) )
%   | then return 0;  // std dev = 0,000, 0,000 (wgt'ed) examples reached here.
%   | else return 0.6281908794091159;  // std dev = 2,977, 88,000 (wgt'ed) examples reached here.  /* #neg=10 #pos=78 */
%   else return -0.1254446385283916;  // std dev = 0,000, 68,000 (wgt'ed) examples reached here.  /* #neg=68 */


% Clauses:

advisedby(A, B, 0) :- 
     professor(B), 
     student(A), 
     advisedby(C, A), 
     tempadvisedby(C, B), 
     !. // Clause #1.

advisedby(A, B, 0.6281908794091159) :- 
     professor(B), 
     student(A), 
     !. // Clause #2.

advisedby(A, B, -0.1254446385283916) :- !. // Clause #3.


% The flattened versions of these clauses:

flattened_advisedby(a, b, 0) :- 
   professor(b),
   student(a),
   advisedby(uniqueVar2, a),
   tempadvisedby(uniqueVar2, b),
   !. // Flattened version of clause #1.

flattened_advisedby(a, b, 0.6281908794091159) :-  /* #neg=10 #pos=78 */ 
   professor(b),
   student(a),
   !. // Flattened version of clause #2.

flattened_advisedby(underscore, underscore, -0.1254446385283916) :-  /* #neg=68 */ 
   !. // Flattened version of clause #3.


% The unique flattened literals:
%   professor(b)
%   student(a)
%   advisedby(uniqueVar2, a)
%   tempadvisedby(uniqueVar2, b)

% Saving model in: train/models/bRDNs/advisedby.model.ckpt
% Time taken to learn 2 trees is 508 milliseconds.

%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.10072314049587028
Set score:0.0025
% Only 156 out of 156 converged.
% Kept 78 of the 78 positive examples.
% Kept 78 of the 78 negative examples.
% Dataset size: 156
Computing probabilities
prob time:48 milliseconds
No hidden examples for : advisedby
Time to build dataset: 115 milliseconds
%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.14649575903670897
Set score:0.0025
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% Have these 7 positive seeds: 6 12 48 62 94 107 116

% The best node found: null

% target           = advisedby(D, E)
%     Score = -Infinity (regressionFit = Infinity, penalties=2.2E-7) for clause:  advisedby(_, _).  [covers 156,0/156,0 pos, 0,0/0,0 neg]
%     Score = -11,538139 (regressionFit = 11,538138, penalties=1.12E-6) for clause:  advisedby(_, A) :- student(A).  [covers 60,0/156,0 pos, 0,0/0,0 neg]
%     Score = -19,722518 (regressionFit = 19,722516, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- student(B), professor(A).  [covers 23,0/156,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- student(B), professor(A).  [covers 23,0/156,0 pos, 0,0/0,0 neg]

% Expanding node at Level 0 with score = 1,797693e+308.
% Will extend: advisedby(A, B) :- student(B), professor(A).  [covers 23,0/156,0 pos, 0,0/0,0 neg]
% Path: 2;
Comparing variance: 4.827056628805028E-18 to score=0.0025 #egs=23.0
Comparing variance: 0.14828959476002165 to score=0.0025 #egs=133.0
%   Creating a TRUE-branch interior node with wgtedCountTrueBranchPos = 23,0
%      addToQueueOfTreeStructuredLearningTasks (level=1; score=-4,82706e-18)
%         ILP node to extend: advisedby(A, B) :- student(B), professor(A).  [covers 23,0/156,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 1 and with score = -4,82706e-18) into the LAST position (#1) in the search queue.

% Time for loop #1: 65 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #1, the best clause found is:
%      advisedby(A, B) :- student(B), professor(A).  [covers 23,0/156,0 pos, 0,0/0,0 neg]
% This clause covers 23 positive examples, of which 23 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- student(B), professor(A).  [covers 23,0/23,0 pos, 0,0/0,0 neg]'
%     Score = -19,722518 (regressionFit = 19,722516, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- student(B), professor(A).  [covers 23,0/23,0 pos, 0,0/0,0 neg]

% Have these 7 positive seeds: 1 4 6 8 9 21 22

% The best node found: null
% [ LazyGroundNthArgumentClauseIndex ]  Argument 1:  Building full index for sameperson/2.
%     Score = -Infinity (regressionFit = Infinity, penalties=3.1300000000000005E-6) for clause:  advisedby(A, B) :- student(B), professor(A), sameperson(_, A).  [covers 23,0/23,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.9300000000000005E-6) for clause:  advisedby(A, B) :- student(B), professor(A), sameperson(C, A), advisedby(C, B).  [covers 0,0/23,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- student(B), professor(A), sameperson(C, A), advisedby(C, B).  [covers 0,0/23,0 pos, 0,0/0,0 neg]

***** Warning: Have a bestNode that covers no positive examples.  That shouldn't happen.  Best node = advisedby(A, B) :- student(B), professor(A), sameperson(C, A), advisedby(C, B).  [covers 0,0/23,0 pos, 0,0/0,0 neg] *****


% Expanding node at Level 1 with score = -4,83e-18.
% Will extend: advisedby(A, B) :- student(B), professor(A), sameperson(C, A), advisedby(C, B).  [covers 0,0/23,0 pos, 0,0/0,0 neg]
% Path: 2;true
Comparing variance: NaN to score=0.0025 #egs=0.0
Comparing variance: 4.827056628805028E-18 to score=0.0025 #egs=23.0
%   Creating a TRUE-branch leaf because wgtedCountTrueBranchPos = 0,0 < 2.1 * minPosCov = 6,3
%   Creating a FALSE-branch leaf because good enough fit since score < 0.0025

% Time for loop #2: 46 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #2, the best clause found is:
%      advisedby(A, B) :- student(B), professor(A), sameperson(C, A), advisedby(C, B).  [covers 0,0/23,0 pos, 0,0/0,0 neg]
% This clause covers 0 positive examples, of which 0 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% ******************************************

%  Have stopped ILP's outer loop because the tree-structured queue is empty.

% ******************************************

%%%%%  WILL-Produced Tree #3 @ 20:41:17 12/15/20.  [Using 3.515.984 memory cells.]  %%%%%


% FOR advisedby(A, B):
%   if ( student(B), professor(A) )
%   then if ( sameperson(C, A), advisedby(C, B) )
%   | then return 0;  // std dev = 0,000, 0,000 (wgt'ed) examples reached here.
%   | else return -0.11231637819360638;  // std dev = 1,05e-08, 23,000 (wgt'ed) examples reached here.  /* #neg=23 */
%   else return 0.28726180730668105;  // std dev = 4,441, 133,000 (wgt'ed) examples reached here.  /* #neg=55 #pos=78 */


% Clauses:

advisedby(A, B, 0) :- 
     student(B), 
     professor(A), 
     sameperson(C, A), 
     advisedby(C, B), 
     !. // Clause #1.

advisedby(A, B, -0.11231637819360638) :- 
     student(B), 
     professor(A), 
     !. // Clause #2.

advisedby(A, B, 0.28726180730668105) :- !. // Clause #3.


% The flattened versions of these clauses:

flattened_advisedby(a, b, 0) :- 
   student(b),
   professor(a),
   sameperson(uniqueVar3, a),
   advisedby(uniqueVar3, b),
   !. // Flattened version of clause #1.

flattened_advisedby(a, b, -0.11231637819360638) :-  /* #neg=23 */ 
   student(b),
   professor(a),
   !. // Flattened version of clause #2.

flattened_advisedby(underscore, underscore, 0.28726180730668105) :-  /* #neg=55 #pos=78 */ 
   !. // Flattened version of clause #3.


% The unique flattened literals:
%   advisedby(uniqueVar3, b)
%   sameperson(uniqueVar3, a)
%   professor(a)
%   student(b)

% Saving model in: train/models/bRDNs/advisedby.model.ckpt
% Time taken to learn 3 trees is 907 milliseconds.

%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:5.204170427930421E-18
Set score:1.3010426069826053E-18
% Only 156 out of 156 converged.
% Kept 78 of the 78 positive examples.
% Kept 78 of the 78 negative examples.
% Dataset size: 156
Computing probabilities
prob time:35 milliseconds
No hidden examples for : advisedby
Time to build dataset: 41 milliseconds
%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.13169505538756096
Set score:1.3010426069826053E-18
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% Have these 7 positive seeds: 51 86 113 123 128 139 144

% The best node found: null

% target           = advisedby(D, E)
%     Score = -Infinity (regressionFit = Infinity, penalties=2.2E-7) for clause:  advisedby(_, _).  [covers 156,0/156,0 pos, 0,0/0,0 neg]
%     Score = -11,235577 (regressionFit = 11,235575, penalties=1.12E-6) for clause:  advisedby(_, A) :- professor(A).  [covers 96,0/156,0 pos, 0,0/0,0 neg]
%     Score = -8,891393 (regressionFit = 8,891391, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- professor(B), student(A).  [covers 88,0/156,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- professor(B), student(A).  [covers 88,0/156,0 pos, 0,0/0,0 neg]

% Expanding node at Level 0 with score = 1,797693e+308.
% Will extend: advisedby(A, B) :- professor(B), student(A).  [covers 88,0/156,0 pos, 0,0/0,0 neg]
% Path: 3;
Comparing variance: 0.10072314049586818 to score=1.3010426069826053E-18 #egs=88.0
Comparing variance: 4.081610429955891E-4 to score=1.3010426069826053E-18 #egs=68.0
%   Creating a TRUE-branch interior node with wgtedCountTrueBranchPos = 88,0
%      addToQueueOfTreeStructuredLearningTasks (level=1; score=-0,100723)
%         ILP node to extend: advisedby(A, B) :- professor(B), student(A).  [covers 88,0/156,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 1 and with score = -0,100723) into the LAST position (#1) in the search queue.

% Time for loop #1: 47 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #1, the best clause found is:
%      advisedby(A, B) :- professor(B), student(A).  [covers 88,0/156,0 pos, 0,0/0,0 neg]
% This clause covers 88 positive examples, of which 88 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- professor(B), student(A).  [covers 88,0/88,0 pos, 0,0/0,0 neg]'
%     Score = -8,891393 (regressionFit = 8,891391, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- professor(B), student(A).  [covers 88,0/88,0 pos, 0,0/0,0 neg]

% Have these 10 positive seeds: 1 18 28 44 52 68 70 75 77 81

% The best node found: null
%     Score = -Infinity (regressionFit = Infinity, penalties=3.0300000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), advisedby(_, A).  [covers 0,0/88,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.9300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), advisedby(C, A), sameperson(C, B).  [covers 0,0/88,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- professor(B), student(A), advisedby(C, A), sameperson(C, B).  [covers 0,0/88,0 pos, 0,0/0,0 neg]

***** Warning: Have a bestNode that covers no positive examples.  That shouldn't happen.  Best node = advisedby(A, B) :- professor(B), student(A), advisedby(C, A), sameperson(C, B).  [covers 0,0/88,0 pos, 0,0/0,0 neg] *****


% Expanding node at Level 1 with score = -0,101.
% Will extend: advisedby(A, B) :- professor(B), student(A), advisedby(C, A), sameperson(C, B).  [covers 0,0/88,0 pos, 0,0/0,0 neg]
% Path: 3;true
Comparing variance: NaN to score=1.3010426069826053E-18 #egs=0.0
Comparing variance: 0.10072314049586818 to score=1.3010426069826053E-18 #egs=88.0
%   Creating a TRUE-branch leaf because wgtedCountTrueBranchPos = 0,0 < 2.1 * minPosCov = 6,3

% Time for loop #2: 59 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #2, the best clause found is:
%      advisedby(A, B) :- professor(B), student(A), advisedby(C, A), sameperson(C, B).  [covers 0,0/88,0 pos, 0,0/0,0 neg]
% This clause covers 0 positive examples, of which 0 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% ******************************************

%  Have stopped ILP's outer loop because the tree-structured queue is empty.

% ******************************************

%%%%%  WILL-Produced Tree #4 @ 20:41:18 12/15/20.  [Using 3.556.624 memory cells.]  %%%%%


% FOR advisedby(A, B):
%   if ( professor(B), student(A) )
%   then if ( advisedby(C, A), sameperson(C, B) )
%   | then return 0;  // std dev = 0,000, 0,000 (wgt'ed) examples reached here.
%   | else return 0.42131522454653036;  // std dev = 2,977, 88,000 (wgt'ed) examples reached here.  /* #neg=10 #pos=78 */
%   else return -0.12985541570248574;  // std dev = 0,167, 68,000 (wgt'ed) examples reached here.  /* #neg=68 */


% Clauses:

advisedby(A, B, 0) :- 
     professor(B), 
     student(A), 
     advisedby(C, A), 
     sameperson(C, B), 
     !. // Clause #1.

advisedby(A, B, 0.42131522454653036) :- 
     professor(B), 
     student(A), 
     !. // Clause #2.

advisedby(A, B, -0.12985541570248574) :- !. // Clause #3.


% The flattened versions of these clauses:

flattened_advisedby(a, b, 0) :- 
   professor(b),
   student(a),
   advisedby(uniqueVar4, a),
   sameperson(uniqueVar4, b),
   !. // Flattened version of clause #1.

flattened_advisedby(a, b, 0.42131522454653036) :-  /* #neg=10 #pos=78 */ 
   professor(b),
   student(a),
   !. // Flattened version of clause #2.

flattened_advisedby(underscore, underscore, -0.12985541570248574) :-  /* #neg=68 */ 
   !. // Flattened version of clause #3.


% The unique flattened literals:
%   professor(b)
%   sameperson(uniqueVar4, b)
%   advisedby(uniqueVar4, a)
%   student(a)

% Saving model in: train/models/bRDNs/advisedby.model.ckpt
% Time taken to learn 4 trees is 1,168 seconds.

%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.1007231404958682
Set score:1.3010426069826053E-18
% Only 156 out of 156 converged.
% Kept 78 of the 78 positive examples.
% Kept 78 of the 78 negative examples.
% Dataset size: 156
Computing probabilities
prob time:18 milliseconds
No hidden examples for : advisedby
Time to build dataset: 19 milliseconds
%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.10294310172694998
Set score:1.3010426069826053E-18
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% Have these 10 positive seeds: 6 10 23 53 55 64 68 81 90 107

% The best node found: null

% target           = advisedby(D, E)
%     Score = -Infinity (regressionFit = Infinity, penalties=2.2E-7) for clause:  advisedby(_, _).  [covers 156,0/156,0 pos, 0,0/0,0 neg]
%     Score = -14,042184 (regressionFit = 14,042182, penalties=1.12E-6) for clause:  advisedby(A, _) :- student(A).  [covers 125,0/156,0 pos, 0,0/0,0 neg]
%     Score = -12,855360 (regressionFit = 12,855358, penalties=1.9200000000000003E-6) for clause:  advisedby(A, B) :- student(A), student(B).  [covers 37,0/156,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- student(A), student(B).  [covers 37,0/156,0 pos, 0,0/0,0 neg]

% Expanding node at Level 0 with score = 1,797693e+308.
% Will extend: advisedby(A, B) :- student(A), student(B).  [covers 37,0/156,0 pos, 0,0/0,0 neg]
% Path: 4;
Comparing variance: -2.100421938480026E-17 to score=1.3010426069826053E-18 #egs=37.0
Comparing variance: 0.10802821767492997 to score=1.3010426069826053E-18 #egs=119.0
%   Creating a TRUE-branch interior node with wgtedCountTrueBranchPos = 37,0
%      addToQueueOfTreeStructuredLearningTasks (level=1; score=2,10042e-17)
%         ILP node to extend: advisedby(A, B) :- student(A), student(B).  [covers 37,0/156,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 1 and with score = 2,10042e-17) into the LAST position (#1) in the search queue.

% Time for loop #1: 13 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #1, the best clause found is:
%      advisedby(A, B) :- student(A), student(B).  [covers 37,0/156,0 pos, 0,0/0,0 neg]
% This clause covers 37 positive examples, of which 37 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- student(A), student(B).  [covers 37,0/37,0 pos, 0,0/0,0 neg]'
%     Score = -12,855360 (regressionFit = 12,855358, penalties=1.9200000000000003E-6) for clause:  advisedby(A, B) :- student(A), student(B).  [covers 37,0/37,0 pos, 0,0/0,0 neg]

% Have these 10 positive seeds: 0 1 3 7 8 14 16 17 19 25

% The best node found: null
%     Score = -Infinity (regressionFit = Infinity, penalties=3.0300000000000002E-6) for clause:  advisedby(A, B) :- student(A), student(B), tempadvisedby(_, A).  [covers 0,0/37,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.830000000000001E-6) for clause:  advisedby(A, B) :- student(A), student(B), tempadvisedby(C, A), advisedby(C, B).  [covers 0,0/37,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- student(A), student(B), tempadvisedby(C, A), advisedby(C, B).  [covers 0,0/37,0 pos, 0,0/0,0 neg]

***** Warning: Have a bestNode that covers no positive examples.  That shouldn't happen.  Best node = advisedby(A, B) :- student(A), student(B), tempadvisedby(C, A), advisedby(C, B).  [covers 0,0/37,0 pos, 0,0/0,0 neg] *****


% Expanding node at Level 1 with score = 2,10e-17.
% Will extend: advisedby(A, B) :- student(A), student(B), tempadvisedby(C, A), advisedby(C, B).  [covers 0,0/37,0 pos, 0,0/0,0 neg]
% Path: 4;true
Comparing variance: NaN to score=1.3010426069826053E-18 #egs=0.0
Comparing variance: -2.100421938480026E-17 to score=1.3010426069826053E-18 #egs=37.0
%   Creating a TRUE-branch leaf because wgtedCountTrueBranchPos = 0,0 < 2.1 * minPosCov = 6,3
%   Creating a FALSE-branch leaf because good enough fit since score < 1.3010426069826053E-18

% Time for loop #2: 21 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #2, the best clause found is:
%      advisedby(A, B) :- student(A), student(B), tempadvisedby(C, A), advisedby(C, B).  [covers 0,0/37,0 pos, 0,0/0,0 neg]
% This clause covers 0 positive examples, of which 0 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% ******************************************

%  Have stopped ILP's outer loop because the tree-structured queue is empty.

% ******************************************

%%%%%  WILL-Produced Tree #5 @ 20:41:18 12/15/20.  [Using 3.599.528 memory cells.]  %%%%%


% FOR advisedby(A, B):
%   if ( student(A), student(B) )
%   then if ( tempadvisedby(C, A), advisedby(C, B) )
%   | then return 0;  // std dev = 0,000, 0,000 (wgt'ed) examples reached here.
%   | else return -0.12899328789695194;  // std dev = 0,000, 37,000 (wgt'ed) examples reached here.  /* #neg=37 */
%   else return 0.2079201615675733;  // std dev = 3,585, 119,000 (wgt'ed) examples reached here.  /* #neg=41 #pos=78 */


% Clauses:

advisedby(A, B, 0) :- 
     student(A), 
     student(B), 
     tempadvisedby(C, A), 
     advisedby(C, B), 
     !. // Clause #1.

advisedby(A, B, -0.12899328789695194) :- 
     student(A), 
     student(B), 
     !. // Clause #2.

advisedby(A, B, 0.2079201615675733) :- !. // Clause #3.


% The flattened versions of these clauses:

flattened_advisedby(a, b, 0) :- 
   student(a),
   student(b),
   tempadvisedby(uniqueVar5, a),
   advisedby(uniqueVar5, b),
   !. // Flattened version of clause #1.

flattened_advisedby(a, b, -0.12899328789695194) :-  /* #neg=37 */ 
   student(a),
   student(b),
   !. // Flattened version of clause #2.

flattened_advisedby(underscore, underscore, 0.2079201615675733) :-  /* #neg=41 #pos=78 */ 
   !. // Flattened version of clause #3.


% The unique flattened literals:
%   tempadvisedby(uniqueVar5, a)
%   student(a)
%   advisedby(uniqueVar5, b)
%   student(b)

% Saving model in: train/models/bRDNs/advisedby.model.ckpt
% Time taken to learn 5 trees is 1,307 seconds.

%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:-2.0816681711721685E-17
Set score:-5.204170427930421E-18
% Only 156 out of 156 converged.
% Kept 78 of the 78 positive examples.
% Kept 78 of the 78 negative examples.
% Dataset size: 156
Computing probabilities
prob time:108 milliseconds
No hidden examples for : advisedby
Time to build dataset: 114 milliseconds
%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.09317800728870262
Set score:-5.204170427930421E-18
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% Have these 9 positive seeds: 6 23 34 84 100 118 121 134 148

% The best node found: null

% target           = advisedby(D, E)
%     Score = -Infinity (regressionFit = Infinity, penalties=2.2E-7) for clause:  advisedby(_, _).  [covers 156,0/156,0 pos, 0,0/0,0 neg]
%     Score = -12,669388 (regressionFit = 12,669387, penalties=1.12E-6) for clause:  advisedby(A, _) :- student(A).  [covers 125,0/156,0 pos, 0,0/0,0 neg]
%     Score = -8,876298 (regressionFit = 8,876296, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- student(A), professor(B).  [covers 88,0/156,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- student(A), professor(B).  [covers 88,0/156,0 pos, 0,0/0,0 neg]

% Expanding node at Level 0 with score = 1,797693e+308.
% Will extend: advisedby(A, B) :- student(A), professor(B).  [covers 88,0/156,0 pos, 0,0/0,0 neg]
% Path: 5;
Comparing variance: 0.1007231404958683 to score=-5.204170427930421E-18 #egs=88.0
Comparing variance: 1.861754583142338E-4 to score=-5.204170427930421E-18 #egs=68.0
%   Creating a TRUE-branch interior node with wgtedCountTrueBranchPos = 88,0
%      addToQueueOfTreeStructuredLearningTasks (level=1; score=-0,100723)
%         ILP node to extend: advisedby(A, B) :- student(A), professor(B).  [covers 88,0/156,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 1 and with score = -0,100723) into the LAST position (#1) in the search queue.

% Time for loop #1: 36 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #1, the best clause found is:
%      advisedby(A, B) :- student(A), professor(B).  [covers 88,0/156,0 pos, 0,0/0,0 neg]
% This clause covers 88 positive examples, of which 88 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- student(A), professor(B).  [covers 88,0/88,0 pos, 0,0/0,0 neg]'
%     Score = -8,876298 (regressionFit = 8,876296, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- student(A), professor(B).  [covers 88,0/88,0 pos, 0,0/0,0 neg]

% Have these 10 positive seeds: 0 5 9 10 17 19 25 26 28 39

% The best node found: null
%     Score = -Infinity (regressionFit = Infinity, penalties=3.0300000000000002E-6) for clause:  advisedby(A, B) :- student(A), professor(B), advisedby(_, A).  [covers 0,0/88,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.9300000000000005E-6) for clause:  advisedby(A, B) :- student(A), professor(B), advisedby(C, A), tempadvisedby(C, B).  [covers 0,0/88,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- student(A), professor(B), advisedby(C, A), tempadvisedby(C, B).  [covers 0,0/88,0 pos, 0,0/0,0 neg]

***** Warning: Have a bestNode that covers no positive examples.  That shouldn't happen.  Best node = advisedby(A, B) :- student(A), professor(B), advisedby(C, A), tempadvisedby(C, B).  [covers 0,0/88,0 pos, 0,0/0,0 neg] *****


% Expanding node at Level 1 with score = -0,101.
% Will extend: advisedby(A, B) :- student(A), professor(B), advisedby(C, A), tempadvisedby(C, B).  [covers 0,0/88,0 pos, 0,0/0,0 neg]
% Path: 5;true
Comparing variance: NaN to score=-5.204170427930421E-18 #egs=0.0
Comparing variance: 0.1007231404958683 to score=-5.204170427930421E-18 #egs=88.0
%   Creating a TRUE-branch leaf because wgtedCountTrueBranchPos = 0,0 < 2.1 * minPosCov = 6,3

% Time for loop #2: 12 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #2, the best clause found is:
%      advisedby(A, B) :- student(A), professor(B), advisedby(C, A), tempadvisedby(C, B).  [covers 0,0/88,0 pos, 0,0/0,0 neg]
% This clause covers 0 positive examples, of which 0 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% ******************************************

%  Have stopped ILP's outer loop because the tree-structured queue is empty.

% ******************************************

%%%%%  WILL-Produced Tree #6 @ 20:41:18 12/15/20.  [Using 3.641.504 memory cells.]  %%%%%


% FOR advisedby(A, B):
%   if ( student(A), professor(B) )
%   then if ( advisedby(C, A), tempadvisedby(C, B) )
%   | then return 0;  // std dev = 0,000, 0,000 (wgt'ed) examples reached here.
%   | else return 0.2664455298682112;  // std dev = 2,977, 88,000 (wgt'ed) examples reached here.  /* #neg=10 #pos=78 */
%   else return -0.11766348224505459;  // std dev = 0,113, 68,000 (wgt'ed) examples reached here.  /* #neg=68 */


% Clauses:

advisedby(A, B, 0) :- 
     student(A), 
     professor(B), 
     advisedby(C, A), 
     tempadvisedby(C, B), 
     !. // Clause #1.

advisedby(A, B, 0.2664455298682112) :- 
     student(A), 
     professor(B), 
     !. // Clause #2.

advisedby(A, B, -0.11766348224505459) :- !. // Clause #3.


% The flattened versions of these clauses:

flattened_advisedby(a, b, 0) :- 
   student(a),
   professor(b),
   advisedby(uniqueVar6, a),
   tempadvisedby(uniqueVar6, b),
   !. // Flattened version of clause #1.

flattened_advisedby(a, b, 0.2664455298682112) :-  /* #neg=10 #pos=78 */ 
   student(a),
   professor(b),
   !. // Flattened version of clause #2.

flattened_advisedby(underscore, underscore, -0.11766348224505459) :-  /* #neg=68 */ 
   !. // Flattened version of clause #3.


% The unique flattened literals:
%   professor(b)
%   tempadvisedby(uniqueVar6, b)
%   student(a)
%   advisedby(uniqueVar6, a)

% Saving model in: train/models/bRDNs/advisedby.model.ckpt
% Time taken to learn 6 trees is 1,639 seconds.

%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.10072314049586831
Set score:-5.204170427930421E-18
% Only 156 out of 156 converged.
% Kept 78 of the 78 positive examples.
% Kept 78 of the 78 negative examples.
% Dataset size: 156
Computing probabilities
prob time:87 milliseconds
No hidden examples for : advisedby
Time to build dataset: 90 milliseconds
%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.08081635290138355
Set score:-5.204170427930421E-18
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% Have these 10 positive seeds: 14 23 32 37 66 84 92 100 106 146

% The best node found: null

% target           = advisedby(D, E)
%     Score = -Infinity (regressionFit = Infinity, penalties=2.2E-7) for clause:  advisedby(_, _).  [covers 156,0/156,0 pos, 0,0/0,0 neg]
%     Score = -9,739142 (regressionFit = 9,739141, penalties=1.12E-6) for clause:  advisedby(_, A) :- professor(A).  [covers 96,0/156,0 pos, 0,0/0,0 neg]
%     Score = -8,874255 (regressionFit = 8,874253, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- professor(B), student(A).  [covers 88,0/156,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- professor(B), student(A).  [covers 88,0/156,0 pos, 0,0/0,0 neg]

% Expanding node at Level 0 with score = 1,797693e+308.
% Will extend: advisedby(A, B) :- professor(B), student(A).  [covers 88,0/156,0 pos, 0,0/0,0 neg]
% Path: 6;
Comparing variance: 0.1007231404958674 to score=-5.204170427930421E-18 #egs=88.0
Comparing variance: 1.561203692432273E-4 to score=-5.204170427930421E-18 #egs=68.0
%   Creating a TRUE-branch interior node with wgtedCountTrueBranchPos = 88,0
%      addToQueueOfTreeStructuredLearningTasks (level=1; score=-0,100723)
%         ILP node to extend: advisedby(A, B) :- professor(B), student(A).  [covers 88,0/156,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 1 and with score = -0,100723) into the LAST position (#1) in the search queue.

% Time for loop #1: 13 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #1, the best clause found is:
%      advisedby(A, B) :- professor(B), student(A).  [covers 88,0/156,0 pos, 0,0/0,0 neg]
% This clause covers 88 positive examples, of which 88 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- professor(B), student(A).  [covers 88,0/88,0 pos, 0,0/0,0 neg]'
%     Score = -8,874255 (regressionFit = 8,874253, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- professor(B), student(A).  [covers 88,0/88,0 pos, 0,0/0,0 neg]

% Have these 10 positive seeds: 7 15 21 31 37 42 43 48 52 59

% The best node found: null
%     Score = -Infinity (regressionFit = Infinity, penalties=3.0300000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), advisedby(_, A).  [covers 0,0/88,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.9300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), advisedby(C, A), tempadvisedby(C, B).  [covers 0,0/88,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- professor(B), student(A), advisedby(C, A), tempadvisedby(C, B).  [covers 0,0/88,0 pos, 0,0/0,0 neg]

***** Warning: Have a bestNode that covers no positive examples.  That shouldn't happen.  Best node = advisedby(A, B) :- professor(B), student(A), advisedby(C, A), tempadvisedby(C, B).  [covers 0,0/88,0 pos, 0,0/0,0 neg] *****


% Expanding node at Level 1 with score = -0,101.
% Will extend: advisedby(A, B) :- professor(B), student(A), advisedby(C, A), tempadvisedby(C, B).  [covers 0,0/88,0 pos, 0,0/0,0 neg]
% Path: 6;true
Comparing variance: NaN to score=-5.204170427930421E-18 #egs=0.0
Comparing variance: 0.1007231404958674 to score=-5.204170427930421E-18 #egs=88.0
%   Creating a TRUE-branch leaf because wgtedCountTrueBranchPos = 0,0 < 2.1 * minPosCov = 6,3

% Time for loop #2: 16 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #2, the best clause found is:
%      advisedby(A, B) :- professor(B), student(A), advisedby(C, A), tempadvisedby(C, B).  [covers 0,0/88,0 pos, 0,0/0,0 neg]
% This clause covers 0 positive examples, of which 0 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% ******************************************

%  Have stopped ILP's outer loop because the tree-structured queue is empty.

% ******************************************

%%%%%  WILL-Produced Tree #7 @ 20:41:18 12/15/20.  [Using 3.680.328 memory cells.]  %%%%%


% FOR advisedby(A, B):
%   if ( professor(B), student(A) )
%   then if ( advisedby(C, A), tempadvisedby(C, B) )
%   | then return 0;  // std dev = 0,000, 0,000 (wgt'ed) examples reached here.
%   | else return 0.2059559107439094;  // std dev = 2,977, 88,000 (wgt'ed) examples reached here.  /* #neg=10 #pos=78 */
%   else return -0.10600575567921348;  // std dev = 0,103, 68,000 (wgt'ed) examples reached here.  /* #neg=68 */


% Clauses:

advisedby(A, B, 0) :- 
     professor(B), 
     student(A), 
     advisedby(C, A), 
     tempadvisedby(C, B), 
     !. // Clause #1.

advisedby(A, B, 0.2059559107439094) :- 
     professor(B), 
     student(A), 
     !. // Clause #2.

advisedby(A, B, -0.10600575567921348) :- !. // Clause #3.


% The flattened versions of these clauses:

flattened_advisedby(a, b, 0) :- 
   professor(b),
   student(a),
   advisedby(uniqueVar7, a),
   tempadvisedby(uniqueVar7, b),
   !. // Flattened version of clause #1.

flattened_advisedby(a, b, 0.2059559107439094) :-  /* #neg=10 #pos=78 */ 
   professor(b),
   student(a),
   !. // Flattened version of clause #2.

flattened_advisedby(underscore, underscore, -0.10600575567921348) :-  /* #neg=68 */ 
   !. // Flattened version of clause #3.


% The unique flattened literals:
%   advisedby(uniqueVar7, a)
%   tempadvisedby(uniqueVar7, b)
%   professor(b)
%   student(a)

% Saving model in: train/models/bRDNs/advisedby.model.ckpt
% Time taken to learn 7 trees is 1,894 seconds.

%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.1007231404958674
Set score:-5.204170427930421E-18
% Only 156 out of 156 converged.
% Kept 78 of the 78 positive examples.
% Kept 78 of the 78 negative examples.
% Dataset size: 156
Computing probabilities
prob time:39 milliseconds
No hidden examples for : advisedby
Time to build dataset: 41 milliseconds
%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.07340969056920632
Set score:-5.204170427930421E-18
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% Have these 10 positive seeds: 25 58 60 72 77 106 107 110 117 121

% The best node found: null

% target           = advisedby(D, E)
%     Score = -Infinity (regressionFit = Infinity, penalties=2.2E-7) for clause:  advisedby(_, _).  [covers 156,0/156,0 pos, 0,0/0,0 neg]
%     Score = -10,595324 (regressionFit = 10,595323, penalties=1.12E-6) for clause:  advisedby(A, _) :- professor(A).  [covers 31,0/156,0 pos, 0,0/0,0 neg]
%     Score = -11,187363 (regressionFit = 11,187362, penalties=1.9200000000000003E-6) for clause:  advisedby(A, B) :- professor(A), professor(B).  [covers 8,0/156,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- professor(A), professor(B).  [covers 8,0/156,0 pos, 0,0/0,0 neg]

% Expanding node at Level 0 with score = 1,797693e+308.
% Will extend: advisedby(A, B) :- professor(A), professor(B).  [covers 8,0/156,0 pos, 0,0/0,0 neg]
% Path: 7;
Comparing variance: 3.469446951953614E-18 to score=-5.204170427930421E-18 #egs=8.0
Comparing variance: 0.07559028083378787 to score=-5.204170427930421E-18 #egs=148.0
%   Creating a TRUE-branch interior node with wgtedCountTrueBranchPos = 8,0
%      addToQueueOfTreeStructuredLearningTasks (level=1; score=-3,46945e-18)
%         ILP node to extend: advisedby(A, B) :- professor(A), professor(B).  [covers 8,0/156,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 1 and with score = -3,46945e-18) into the LAST position (#1) in the search queue.

% Time for loop #1: 12 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #1, the best clause found is:
%      advisedby(A, B) :- professor(A), professor(B).  [covers 8,0/156,0 pos, 0,0/0,0 neg]
% This clause covers 8 positive examples, of which 8 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- professor(A), professor(B).  [covers 8,0/8,0 pos, 0,0/0,0 neg]'
%     Score = -11,187363 (regressionFit = 11,187362, penalties=1.9200000000000003E-6) for clause:  advisedby(A, B) :- professor(A), professor(B).  [covers 8,0/8,0 pos, 0,0/0,0 neg]

***** Warning: % Have only 8 positive examples, so cannot choose 10 of them. *****


% Have these 8 positive seeds: 0 1 2 3 4 5 6 7

% The best node found: null
%     Score = -Infinity (regressionFit = Infinity, penalties=3.0300000000000002E-6) for clause:  advisedby(A, B) :- professor(A), professor(B), tempadvisedby(_, A).  [covers 6,0/8,0 pos, 0,0/0,0 neg]
% [ LazyGroundClauseIndex ]  Building full index for tempadvisedby/2 with 26 assertions.
%     Score = -Infinity (regressionFit = Infinity, penalties=3.830000000000001E-6) for clause:  advisedby(A, B) :- professor(A), professor(B), tempadvisedby(C, A), tempadvisedby(C, B).  [covers 0,0/8,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- professor(A), professor(B), tempadvisedby(C, A), tempadvisedby(C, B).  [covers 0,0/8,0 pos, 0,0/0,0 neg]

***** Warning: Have a bestNode that covers no positive examples.  That shouldn't happen.  Best node = advisedby(A, B) :- professor(A), professor(B), tempadvisedby(C, A), tempadvisedby(C, B).  [covers 0,0/8,0 pos, 0,0/0,0 neg] *****


% Expanding node at Level 1 with score = -3,47e-18.
% Will extend: advisedby(A, B) :- professor(A), professor(B), tempadvisedby(C, A), tempadvisedby(C, B).  [covers 0,0/8,0 pos, 0,0/0,0 neg]
% Path: 7;true
Comparing variance: NaN to score=-5.204170427930421E-18 #egs=0.0
Comparing variance: 0.0 to score=-5.204170427930421E-18 #egs=8.0
%   Creating a TRUE-branch leaf because wgtedCountTrueBranchPos = 0,0 < 2.1 * minPosCov = 6,3

% Time for loop #2: 6 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #2, the best clause found is:
%      advisedby(A, B) :- professor(A), professor(B), tempadvisedby(C, A), tempadvisedby(C, B).  [covers 0,0/8,0 pos, 0,0/0,0 neg]
% This clause covers 0 positive examples, of which 0 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% ******************************************

%  Have stopped ILP's outer loop because the tree-structured queue is empty.

% ******************************************

%%%%%  WILL-Produced Tree #8 @ 20:41:19 12/15/20.  [Using 3.736.832 memory cells.]  %%%%%


% FOR advisedby(A, B):
%   if ( professor(A), professor(B) )
%   then if ( tempadvisedby(C, A), tempadvisedby(C, B) )
%   | then return 0;  // std dev = 0,000, 0,000 (wgt'ed) examples reached here.
%   | else return -0.12723413100102615;  // std dev = 0,000, 8,000 (wgt'ed) examples reached here.  /* #neg=8 */
%   else return 0.05946421337295473;  // std dev = 3,345, 148,000 (wgt'ed) examples reached here.  /* #neg=70 #pos=78 */


% Clauses:

advisedby(A, B, 0) :- 
     professor(A), 
     professor(B), 
     tempadvisedby(C, A), 
     tempadvisedby(C, B), 
     !. // Clause #1.

advisedby(A, B, -0.12723413100102615) :- 
     professor(A), 
     professor(B), 
     !. // Clause #2.

advisedby(A, B, 0.05946421337295473) :- !. // Clause #3.


% The flattened versions of these clauses:

flattened_advisedby(a, b, 0) :- 
   professor(a),
   professor(b),
   tempadvisedby(uniqueVar8, a),
   tempadvisedby(uniqueVar8, b),
   !. // Flattened version of clause #1.

flattened_advisedby(a, b, -0.12723413100102615) :-  /* #neg=8 */ 
   professor(a),
   professor(b),
   !. // Flattened version of clause #2.

flattened_advisedby(underscore, underscore, 0.05946421337295473) :-  /* #neg=70 #pos=78 */ 
   !. // Flattened version of clause #3.


% The unique flattened literals:
%   tempadvisedby(uniqueVar8, b)
%   professor(b)
%   professor(a)
%   tempadvisedby(uniqueVar8, a)

% Saving model in: train/models/bRDNs/advisedby.model.ckpt
% Time taken to learn 8 trees is 2,154 seconds.

%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:3.469446951953614E-18
Set score:-5.204170427930421E-18
% Only 156 out of 156 converged.
% Kept 78 of the 78 positive examples.
% Kept 78 of the 78 negative examples.
% Dataset size: 156
Computing probabilities
prob time:120 milliseconds
No hidden examples for : advisedby
Time to build dataset: 122 milliseconds
%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.07226109752110951
Set score:-5.204170427930421E-18
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% Have these 5 positive seeds: 13 31 57 137 152

% The best node found: null

% target           = advisedby(D, E)
%     Score = -Infinity (regressionFit = Infinity, penalties=2.2E-7) for clause:  advisedby(_, _).  [covers 156,0/156,0 pos, 0,0/0,0 neg]
%     Score = -9,378835 (regressionFit = 9,378834, penalties=1.12E-6) for clause:  advisedby(_, A) :- professor(A).  [covers 96,0/156,0 pos, 0,0/0,0 neg]
%     Score = -8,865959 (regressionFit = 8,865957, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- professor(B), student(A).  [covers 88,0/156,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- professor(B), student(A).  [covers 88,0/156,0 pos, 0,0/0,0 neg]

% Expanding node at Level 0 with score = 1,797693e+308.
% Will extend: advisedby(A, B) :- professor(B), student(A).  [covers 88,0/156,0 pos, 0,0/0,0 neg]
% Path: 8;
Comparing variance: 0.10072314049586778 to score=-5.204170427930421E-18 #egs=88.0
Comparing variance: 3.412715507489718E-5 to score=-5.204170427930421E-18 #egs=68.0
%   Creating a TRUE-branch interior node with wgtedCountTrueBranchPos = 88,0
%      addToQueueOfTreeStructuredLearningTasks (level=1; score=-0,100723)
%         ILP node to extend: advisedby(A, B) :- professor(B), student(A).  [covers 88,0/156,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 1 and with score = -0,100723) into the LAST position (#1) in the search queue.

% Time for loop #1: 13 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #1, the best clause found is:
%      advisedby(A, B) :- professor(B), student(A).  [covers 88,0/156,0 pos, 0,0/0,0 neg]
% This clause covers 88 positive examples, of which 88 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- professor(B), student(A).  [covers 88,0/88,0 pos, 0,0/0,0 neg]'
%     Score = -8,865959 (regressionFit = 8,865957, penalties=2.0200000000000006E-6) for clause:  advisedby(A, B) :- professor(B), student(A).  [covers 88,0/88,0 pos, 0,0/0,0 neg]

% Have these 6 positive seeds: 12 22 37 40 65 87

% The best node found: null
%     Score = -Infinity (regressionFit = Infinity, penalties=3.0300000000000002E-6) for clause:  advisedby(A, B) :- professor(B), student(A), advisedby(_, A).  [covers 0,0/88,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.9300000000000005E-6) for clause:  advisedby(A, B) :- professor(B), student(A), advisedby(C, A), tempadvisedby(C, B).  [covers 0,0/88,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- professor(B), student(A), advisedby(C, A), tempadvisedby(C, B).  [covers 0,0/88,0 pos, 0,0/0,0 neg]

***** Warning: Have a bestNode that covers no positive examples.  That shouldn't happen.  Best node = advisedby(A, B) :- professor(B), student(A), advisedby(C, A), tempadvisedby(C, B).  [covers 0,0/88,0 pos, 0,0/0,0 neg] *****


% Expanding node at Level 1 with score = -0,101.
% Will extend: advisedby(A, B) :- professor(B), student(A), advisedby(C, A), tempadvisedby(C, B).  [covers 0,0/88,0 pos, 0,0/0,0 neg]
% Path: 8;true
Comparing variance: NaN to score=-5.204170427930421E-18 #egs=0.0
Comparing variance: 0.10072314049586778 to score=-5.204170427930421E-18 #egs=88.0
%   Creating a TRUE-branch leaf because wgtedCountTrueBranchPos = 0,0 < 2.1 * minPosCov = 6,3

% Time for loop #2: 15 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #2, the best clause found is:
%      advisedby(A, B) :- professor(B), student(A), advisedby(C, A), tempadvisedby(C, B).  [covers 0,0/88,0 pos, 0,0/0,0 neg]
% This clause covers 0 positive examples, of which 0 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% ******************************************

%  Have stopped ILP's outer loop because the tree-structured queue is empty.

% ******************************************

%%%%%  WILL-Produced Tree #9 @ 20:41:19 12/15/20.  [Using 3.777.872 memory cells.]  %%%%%


% FOR advisedby(A, B):
%   if ( professor(B), student(A) )
%   then if ( advisedby(C, A), tempadvisedby(C, B) )
%   | then return 0;  // std dev = 0,000, 0,000 (wgt'ed) examples reached here.
%   | else return 0.15118338696528708;  // std dev = 2,977, 88,000 (wgt'ed) examples reached here.  /* #neg=10 #pos=78 */
%   else return -0.09930303010077766;  // std dev = 0,048, 68,000 (wgt'ed) examples reached here.  /* #neg=68 */


% Clauses:

advisedby(A, B, 0) :- 
     professor(B), 
     student(A), 
     advisedby(C, A), 
     tempadvisedby(C, B), 
     !. // Clause #1.

advisedby(A, B, 0.15118338696528708) :- 
     professor(B), 
     student(A), 
     !. // Clause #2.

advisedby(A, B, -0.09930303010077766) :- !. // Clause #3.


% The flattened versions of these clauses:

flattened_advisedby(a, b, 0) :- 
   professor(b),
   student(a),
   advisedby(uniqueVar9, a),
   tempadvisedby(uniqueVar9, b),
   !. // Flattened version of clause #1.

flattened_advisedby(a, b, 0.15118338696528708) :-  /* #neg=10 #pos=78 */ 
   professor(b),
   student(a),
   !. // Flattened version of clause #2.

flattened_advisedby(underscore, underscore, -0.09930303010077766) :-  /* #neg=68 */ 
   !. // Flattened version of clause #3.


% The unique flattened literals:
%   professor(b)
%   tempadvisedby(uniqueVar9, b)
%   student(a)
%   advisedby(uniqueVar9, a)

% Saving model in: train/models/bRDNs/advisedby.model.ckpt
% Time taken to learn 9 trees is 2,468 seconds.

%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.10072314049586778
Set score:-5.204170427930421E-18
% Only 156 out of 156 converged.
% Kept 78 of the 78 positive examples.
% Kept 78 of the 78 negative examples.
% Dataset size: 156
Computing probabilities
prob time:94 milliseconds
No hidden examples for : advisedby
Time to build dataset: 96 milliseconds
%      addToQueueOfTreeStructuredLearningTasks (level=0; score=1,797693135e+308)
%         ILP node to extend: null
%      Insert tree-structured search node (@ level = 0 and with score = 1,797693135e+308) into the LAST position (#1) in the search queue.
Variance:0.06804784750235707
Set score:-5.204170427930421E-18
% [AdviceProcessor]  Generated 0 clauses at relevance level STRONGLY_IRRELEVANT.

% Have these 5 positive seeds: 0 99 105 121 122

% The best node found: null

% target           = advisedby(D, E)
%     Score = -Infinity (regressionFit = Infinity, penalties=2.2E-7) for clause:  advisedby(_, _).  [covers 156,0/156,0 pos, 0,0/0,0 neg]
%     Score = -10,055583 (regressionFit = 10,055582, penalties=1.12E-6) for clause:  advisedby(A, _) :- professor(A).  [covers 31,0/156,0 pos, 0,0/0,0 neg]
%     Score = -10,464415 (regressionFit = 10,464413, penalties=1.9200000000000003E-6) for clause:  advisedby(A, B) :- professor(A), professor(B).  [covers 8,0/156,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- professor(A), professor(B).  [covers 8,0/156,0 pos, 0,0/0,0 neg]

% Expanding node at Level 0 with score = 1,797693e+308.
% Will extend: advisedby(A, B) :- professor(A), professor(B).  [covers 8,0/156,0 pos, 0,0/0,0 neg]
% Path: 9;
Comparing variance: -8.673617379884035E-18 to score=-5.204170427930421E-18 #egs=8.0
Comparing variance: 0.07070549166390724 to score=-5.204170427930421E-18 #egs=148.0
%   Creating a TRUE-branch interior node with wgtedCountTrueBranchPos = 8,0
%      addToQueueOfTreeStructuredLearningTasks (level=1; score=8,67362e-18)
%         ILP node to extend: advisedby(A, B) :- professor(A), professor(B).  [covers 8,0/156,0 pos, 0,0/0,0 neg]
%      Insert tree-structured search node (@ level = 1 and with score = 8,67362e-18) into the LAST position (#1) in the search queue.

% Time for loop #1: 13 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #1, the best clause found is:
%      advisedby(A, B) :- professor(A), professor(B).  [covers 8,0/156,0 pos, 0,0/0,0 neg]
% This clause covers 8 positive examples, of which 8 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% Working on expanding this node: 'advisedby(A, B) :- professor(A), professor(B).  [covers 8,0/8,0 pos, 0,0/0,0 neg]'
%     Score = -10,464415 (regressionFit = 10,464413, penalties=1.9200000000000003E-6) for clause:  advisedby(A, B) :- professor(A), professor(B).  [covers 8,0/8,0 pos, 0,0/0,0 neg]

% Have these 8 positive seeds: 0 1 2 3 4 5 6 7

% The best node found: null
%     Score = -Infinity (regressionFit = Infinity, penalties=3.0300000000000002E-6) for clause:  advisedby(A, B) :- professor(A), professor(B), sameperson(_, A).  [covers 8,0/8,0 pos, 0,0/0,0 neg]
%     Score = -Infinity (regressionFit = Infinity, penalties=3.9300000000000005E-6) for clause:  advisedby(A, B) :- professor(A), professor(B), sameperson(C, A), tempadvisedby(C, B).  [covers 0,0/8,0 pos, 0,0/0,0 neg]

% The best node found: advisedby(A, B) :- professor(A), professor(B), sameperson(C, A), tempadvisedby(C, B).  [covers 0,0/8,0 pos, 0,0/0,0 neg]

***** Warning: Have a bestNode that covers no positive examples.  That shouldn't happen.  Best node = advisedby(A, B) :- professor(A), professor(B), sameperson(C, A), tempadvisedby(C, B).  [covers 0,0/8,0 pos, 0,0/0,0 neg] *****


% Expanding node at Level 1 with score = 8,67e-18.
% Will extend: advisedby(A, B) :- professor(A), professor(B), sameperson(C, A), tempadvisedby(C, B).  [covers 0,0/8,0 pos, 0,0/0,0 neg]
% Path: 9;true
Comparing variance: NaN to score=-5.204170427930421E-18 #egs=0.0
Comparing variance: -8.673617379884035E-18 to score=-5.204170427930421E-18 #egs=8.0
%   Creating a TRUE-branch leaf because wgtedCountTrueBranchPos = 0,0 < 2.1 * minPosCov = 6,3
%   Creating a FALSE-branch leaf because good enough fit since score < -5.204170427930421E-18

% Time for loop #2: 23 milliseconds.
% Internal node max length = 2
% Max tree depth in lits   = 12
% Max tree depth in nodes  = 3
% Max number of clauses    = 8

% On cycle #2, the best clause found is:
%      advisedby(A, B) :- professor(A), professor(B), sameperson(C, A), tempadvisedby(C, B).  [covers 0,0/8,0 pos, 0,0/0,0 neg]
% This clause covers 0 positive examples, of which 0 are newly covered.
% It also covers 0 negative examples, of which 0 are newly covered.

% ******************************************

%  Have stopped ILP's outer loop because the tree-structured queue is empty.

% ******************************************

%%%%%  WILL-Produced Tree #10 @ 20:41:19 12/15/20.  [Using 3.817.032 memory cells.]  %%%%%


% FOR advisedby(A, B):
%   if ( professor(A), professor(B) )
%   then if ( sameperson(C, A), tempadvisedby(C, B) )
%   | then return 0;  // std dev = 0,000, 0,000 (wgt'ed) examples reached here.
%   | else return -0.10412810119108215;  // std dev = 0,000, 8,000 (wgt'ed) examples reached here.  /* #neg=8 */
%   else return 0.03694651870663026;  // std dev = 3,235, 148,000 (wgt'ed) examples reached here.  /* #neg=70 #pos=78 */


% Clauses:

advisedby(A, B, 0) :- 
     professor(A), 
     professor(B), 
     sameperson(C, A), 
     tempadvisedby(C, B), 
     !. // Clause #1.

advisedby(A, B, -0.10412810119108215) :- 
     professor(A), 
     professor(B), 
     !. // Clause #2.

advisedby(A, B, 0.03694651870663026) :- !. // Clause #3.


% The flattened versions of these clauses:

flattened_advisedby(a, b, 0) :- 
   professor(a),
   professor(b),
   sameperson(uniqueVar10, a),
   tempadvisedby(uniqueVar10, b),
   !. // Flattened version of clause #1.

flattened_advisedby(a, b, -0.10412810119108215) :-  /* #neg=8 */ 
   professor(a),
   professor(b),
   !. // Flattened version of clause #2.

flattened_advisedby(underscore, underscore, 0.03694651870663026) :-  /* #neg=70 #pos=78 */ 
   !. // Flattened version of clause #3.


% The unique flattened literals:
%   professor(b)
%   sameperson(uniqueVar10, a)
%   tempadvisedby(uniqueVar10, b)
%   professor(a)

% Saving model in: train/models/bRDNs/advisedby.model.ckpt
% Saving model in: train/models/bRDNs/advisedby.model


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%  Final call for computing score for advisedby.  %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

stepLength_tree1(1.0).
stepLength_tree2(1.0).
stepLength_tree3(1.0).
stepLength_tree4(1.0).
stepLength_tree5(1.0).
stepLength_tree6(1.0).
stepLength_tree7(1.0).
stepLength_tree8(1.0).
stepLength_tree9(1.0).
stepLength_tree10(1.0).

logPrior(-1.8).
advisedby(D, E, Total) :- // A general accessor. 
   advisedby(D, E, 1000000, Total), !.
advisedby(D, E, Total) :- waitHere("This should not fail", advisedby(D, E, Total)).

advisedby(D, E, TreesToUse, Total) :- // A tree-limited accessor (e.g., for tuning the number of trees to use).
   logPrior(LogPrior),
   getScore_advisedby_tree1(D, E, TreesToUse, Total1),
   getScore_advisedby_tree2(D, E, TreesToUse, Total2),
   getScore_advisedby_tree3(D, E, TreesToUse, Total3),
   getScore_advisedby_tree4(D, E, TreesToUse, Total4),
   getScore_advisedby_tree5(D, E, TreesToUse, Total5),
   getScore_advisedby_tree6(D, E, TreesToUse, Total6),
   getScore_advisedby_tree7(D, E, TreesToUse, Total7),
   getScore_advisedby_tree8(D, E, TreesToUse, Total8),
   getScore_advisedby_tree9(D, E, TreesToUse, Total9),
   getScore_advisedby_tree10(D, E, TreesToUse, Total10),
   Total is LogPrior + Total1 + Total2 + Total3 + Total4 + Total5 + Total6 + Total7 + Total8 + Total9 + Total10,
   !.
advisedby(D, E, TreesToUse, Total) :- waitHere("This should not fail", advisedby(D, E, TreesToUse, Total)).

getScore_advisedby_tree1(D, E, TreesToUse, 0.0) :- 1 > TreesToUse, !.
getScore_advisedby_tree1(D, E, TreesToUse, Total1) :- advisedby_tree1(D, E, Total), stepLength_tree1(StepLen), Total1 is Total * StepLen.

getScore_advisedby_tree2(D, E, TreesToUse, 0.0) :- 2 > TreesToUse, !.
getScore_advisedby_tree2(D, E, TreesToUse, Total2) :- advisedby_tree2(D, E, Total), stepLength_tree2(StepLen), Total2 is Total * StepLen.

getScore_advisedby_tree3(D, E, TreesToUse, 0.0) :- 3 > TreesToUse, !.
getScore_advisedby_tree3(D, E, TreesToUse, Total3) :- advisedby_tree3(D, E, Total), stepLength_tree3(StepLen), Total3 is Total * StepLen.

getScore_advisedby_tree4(D, E, TreesToUse, 0.0) :- 4 > TreesToUse, !.
getScore_advisedby_tree4(D, E, TreesToUse, Total4) :- advisedby_tree4(D, E, Total), stepLength_tree4(StepLen), Total4 is Total * StepLen.

getScore_advisedby_tree5(D, E, TreesToUse, 0.0) :- 5 > TreesToUse, !.
getScore_advisedby_tree5(D, E, TreesToUse, Total5) :- advisedby_tree5(D, E, Total), stepLength_tree5(StepLen), Total5 is Total * StepLen.

getScore_advisedby_tree6(D, E, TreesToUse, 0.0) :- 6 > TreesToUse, !.
getScore_advisedby_tree6(D, E, TreesToUse, Total6) :- advisedby_tree6(D, E, Total), stepLength_tree6(StepLen), Total6 is Total * StepLen.

getScore_advisedby_tree7(D, E, TreesToUse, 0.0) :- 7 > TreesToUse, !.
getScore_advisedby_tree7(D, E, TreesToUse, Total7) :- advisedby_tree7(D, E, Total), stepLength_tree7(StepLen), Total7 is Total * StepLen.

getScore_advisedby_tree8(D, E, TreesToUse, 0.0) :- 8 > TreesToUse, !.
getScore_advisedby_tree8(D, E, TreesToUse, Total8) :- advisedby_tree8(D, E, Total), stepLength_tree8(StepLen), Total8 is Total * StepLen.

getScore_advisedby_tree9(D, E, TreesToUse, 0.0) :- 9 > TreesToUse, !.
getScore_advisedby_tree9(D, E, TreesToUse, Total9) :- advisedby_tree9(D, E, Total), stepLength_tree9(StepLen), Total9 is Total * StepLen.

getScore_advisedby_tree10(D, E, TreesToUse, 0.0) :- 10 > TreesToUse, !.
getScore_advisedby_tree10(D, E, TreesToUse, Total10) :- advisedby_tree10(D, E, Total), stepLength_tree10(StepLen), Total10 is Total * StepLen.

flattenedLiteralsInThisSetOfTrees(advisedby, 24, [
   advisedby(uniqueVar7, a),
   tempadvisedby(uniqueVar1, b),
   tempadvisedby(uniqueVar8, a),
   tempadvisedby(uniqueVar9, b),
   tempadvisedby(uniqueVar1, a),
   advisedby(uniqueVar4, a),
   tempadvisedby(uniqueVar6, b),
   student(a),
   advisedby(uniqueVar9, a),
   tempadvisedby(uniqueVar10, b),
   student(b),
   tempadvisedby(uniqueVar7, b),
   sameperson(uniqueVar4, b),
   advisedby(uniqueVar2, a),
   advisedby(uniqueVar5, b),
   tempadvisedby(uniqueVar8, b),
   professor(b),
   sameperson(uniqueVar10, a),
   advisedby(uniqueVar3, b),
   tempadvisedby(uniqueVar5, a),
   sameperson(uniqueVar3, a),
   professor(a),
   tempadvisedby(uniqueVar2, b),
   advisedby(uniqueVar6, a)]).
% Time taken to learn model for 'advisedby': 2,801 seconds.
% Saving model in: train/models/bRDNs/advisedby.model
cached groundings hit: 0
Misses: 0

% Total learning time (10 trees): 3,907 seconds.
